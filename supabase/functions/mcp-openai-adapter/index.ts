// Supabase Edge Function for MCP OpenAI Adapter
// Converts MCP tools to OpenAI function calling format

import { serve } from "https://deno.land/std@0.168.0/http/server.ts"
import OpenAI from "npm:openai";

// ---- Config ----
const MCP_SERVER_URL = Deno.env.get("MCP_SSE_URL"); // Keeping variable name for backward compatibility
const MCP_HEADERS = Deno.env.get("MCP_SSE_HEADERS") ? JSON.parse(Deno.env.get("MCP_SSE_HEADERS")!) : {};
const LOG_LEVEL = Deno.env.get("LOG_LEVEL") || "info";
const OPENAI_API_KEY = Deno.env.get("OPENAI_API_KEY");
const MAX_ITERATIONS = parseInt(Deno.env.get("MAX_ITERATIONS") || "10");

if (!OPENAI_API_KEY) {
  console.error("Missing OPENAI_API_KEY environment variable");
}

// ---- Direct MCP HTTP Client (bypasses SDK transport complexity) ----
// This directly calls the MCP server HTTP endpoints without using the SDK's transport layer

interface MCPTool {
  name: string;
  description?: string;
  inputSchema: Record<string, unknown>;
}

let cachedTools: MCPTool[] = [];

// Direct HTTP call to MCP server
async function callMCPServer(method: string, params: Record<string, unknown> = {}) {
  console.log(`[MCP Direct] Calling ${method} with params:`, params);

  const requestBody = {
    jsonrpc: "2.0",
    id: Date.now(),
    method: method,
    params: params
  };

  console.log(`[MCP Direct] Full request body:`, JSON.stringify(requestBody, null, 2));

  try {
    const response = await fetch(MCP_SERVER_URL!, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Accept': 'application/json',
        ...MCP_HEADERS
      },
      body: JSON.stringify(requestBody)
    });

    if (!response.ok) {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    }

    const data = await response.json();
    console.log(`[MCP Direct] Response:`, data);

    if (data.error) {
      throw new Error(`MCP Error: ${data.error.message || JSON.stringify(data.error)}`);
    }

    return data.result;
  } catch (error) {
    console.error(`[MCP Direct] Error calling ${method}:`, error);
    throw error;
  }
}

// Initialize MCP connection and get tools
async function initializeMCP() {
  console.log(`Initializing MCP server: ${MCP_SERVER_URL}`);

  try {
    // Initialize the MCP session
    const initResult = await callMCPServer('initialize', {
      protocolVersion: "2024-11-05",
      clientInfo: {
        name: "mcp-openai-adapter",
        version: "0.1.0"
      },
      capabilities: {
        tools: {}
      }
    });

    console.log("MCP initialized:", initResult);

    // List available tools
    const toolsResult = await callMCPServer('tools/list', {});
    cachedTools = toolsResult.tools || [];

    console.log(`MCP connected. Found ${cachedTools.length} tool(s):`, cachedTools.map((t: any) => t.name));

    return true;
  } catch (error) {
    console.error("Failed to initialize MCP server:", error);
    throw error;
  }
}

async function ensureMCP() {
  if (cachedTools.length > 0) return true;

  // Simple retry logic
  let retries = 3;
  let lastError;

  while (retries > 0) {
    try {
      await initializeMCP();
      return true;
    } catch (error) {
      lastError = error;
      retries--;
      if (retries > 0) {
        console.log(`Retrying MCP initialization... (${retries} retries left)`);
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
    }
  }

  throw lastError;
}

// ---- OpenAI Client ----
const openai = new OpenAI({
  apiKey: OPENAI_API_KEY,
});

// Map MCP tool schema ‚Üí OpenAI tools schema (functions)
function mcpToolsToOpenAITools(mcpTools: any[] = []) {
  return mcpTools.map((t: any) => ({
    type: "function",
    function: {
      name: t.name,
      description: t.description || "MCP tool",
      parameters: t.inputSchema || { type: "object", properties: {} }
    }
  }));
}

// Helper function to invoke a single MCP tool
async function invokeMCPTool(name: string, args: Record<string, unknown>) {
  await ensureMCP();

  // Ensure tool exists
  const tool = cachedTools.find((t: MCPTool) => t.name === name);
  if (!tool) throw new Error(`Tool '${name}' not found.`);

  console.log(`[invokeMCPTool] Tool: ${name}`);
  console.log(`[invokeMCPTool] Input args from OpenAI:`, JSON.stringify(args, null, 2));

  // CRITICAL FIX: Remove trailing semicolons from SQL queries
  // The MCP database server rejects queries with semicolons as potentially dangerous multi-statement queries
  if (name === 'query_database' && args.sql && typeof args.sql === 'string') {
    const originalSql = args.sql;
    args.sql = args.sql.trim().replace(/;+\s*$/, '');
    if (originalSql !== args.sql) {
      console.log(`[invokeMCPTool] Removed trailing semicolon from SQL query`);
      console.log(`[invokeMCPTool] Modified SQL:`, args.sql);
    }

    // Log warnings for common schema mistakes (but let LLM learn from errors)
    let sql = args.sql as string;

    // Check for common mistakes and log warnings
    if (sql.match(/\bp\.full_name\b/gi) || sql.match(/profiles\.full_name\b/gi)) {
      console.log(`‚ö†Ô∏è [SCHEMA WARNING] Query uses p.full_name but profiles table has first_name and last_name columns!`);
      console.log(`‚ö†Ô∏è [SCHEMA WARNING] Should use: (p.first_name || ' ' || p.last_name) AS full_name`);
    }

    if (sql.includes('.published') || sql.match(/\bc\.published\b/i)) {
      console.log(`‚ö†Ô∏è [SCHEMA WARNING] Query uses c.published but courses table has status column!`);
      console.log(`‚ö†Ô∏è [SCHEMA WARNING] Should use: c.status = 'Published'`);
    }

    if (sql.match(/\bFROM\s+assignments\b/i) || sql.match(/\bJOIN\s+assignments\b/i)) {
      console.log(`‚ö†Ô∏è [SCHEMA WARNING] Query references "assignments" table which doesn't exist!`);
      console.log(`‚ö†Ô∏è [SCHEMA WARNING] Assignments are in course_lesson_content WHERE content_type = 'assignment'`);
    }
  }

  // Call the MCP tool directly
  const invokeRes = await callMCPServer('tools/call', {
    name,
    arguments: args || {}
  });

  // Coalesce MCP content parts into a single string/JSON
  let out: string[] = [];
  const content = invokeRes.content || [];

  for (const part of content) {
    if (part?.type === "text") out.push(part.text);
    else if (part?.type === "json") out.push(JSON.stringify(part.json));
    else out.push(JSON.stringify(part));
  }

  return {
    content: out.join("\n") || null,
    raw: invokeRes
  };
}

// CORS headers for browser requests
const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
  'Access-Control-Allow-Methods': 'POST, GET, OPTIONS',
};

serve(async (req) => {
  // Handle CORS preflight requests
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders });
  }

  try {
    const url = new URL(req.url);
    const path = url.pathname;

    // Health check endpoint
    if (path.endsWith('/health') && req.method === 'GET') {
      return new Response(JSON.stringify({ ok: true }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    // Get configuration endpoint
    if (path.endsWith('/config') && req.method === 'GET') {
      return new Response(JSON.stringify({
        maxIterations: MAX_ITERATIONS,
        logLevel: LOG_LEVEL,
        mcpServerUrl: MCP_SERVER_URL,
        availableModels: [
          "gpt-4o-mini"
        ],
        note: "Model is locked to gpt-4o-mini for cost optimization. Model parameter in requests is ignored.",
        endpoints: {
          "/tools": "GET - List available MCP tools in OpenAI format",
          "/invoke": "POST - Enhanced endpoint with iterative tool calling",
          "/invoke-tool": "POST - Legacy single tool invocation",
          "/config": "GET - Get adapter configuration",
          "/health": "GET - Health check"
        }
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    // Get tools endpoint
    if (path.endsWith('/tools') && req.method === 'GET') {
      await ensureMCP();
      // Refresh tool list if empty (ensureMCP already populates cachedTools)
      if (!cachedTools.length) {
        await initializeMCP();
      }
      return new Response(JSON.stringify({
        tools: mcpToolsToOpenAITools(cachedTools),
        rawMCPTools: cachedTools // Include raw MCP tools for debugging
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    // Enhanced invoke endpoint
    if (path.endsWith('/invoke') && req.method === 'POST') {
      const body = await req.json();
      const { prompt, temperature = 0.2 } = body;

      // Always use gpt-4o-mini - ignore any model parameter
      const model = "gpt-4o-mini";
      
      if (!prompt) {
        return new Response(JSON.stringify({ 
          ok: false, 
          error: "Missing 'prompt'. Expected format: { \"prompt\": \"your request here\" }" 
        }), {
          status: 400,
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }

      await ensureMCP();

      // Refresh tools if empty (ensureMCP already populates cachedTools)
      if (!cachedTools.length) {
        await initializeMCP();
      }

      const tools = mcpToolsToOpenAITools(cachedTools);
      
      if (!tools.length) {
        return new Response(JSON.stringify({ 
          ok: false, 
          error: "No tools available from MCP server" 
        }), {
          status: 400,
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }

      // Initialize conversation
      const messages: any[] = [
        {
          role: "system",
          content: `You are an assistant for an educational platform that can ONLY respond by using the available tools. You MUST use one or more tools to answer every user request.

üö®üö®üö® CRITICAL SQL RULES - ABSOLUTELY MANDATORY üö®üö®üö®:
‚ö†Ô∏è ONLY USE SELECT QUERIES! NO CREATE, INSERT, UPDATE, DELETE, DROP, ALTER!
‚ö†Ô∏è The queryDatabase tool ONLY allows SELECT statements for READ-ONLY operations!
‚ö†Ô∏è NEVER use CREATE TEMPORARY TABLE, CREATE TABLE AS, or any CREATE statement!
‚ö†Ô∏è NEVER use WITH ... AS (subquery) if it tries to CREATE anything!
‚ö†Ô∏è Use CTEs (WITH clause) for complex queries, but NO CREATE statements!
‚ö†Ô∏è For string concatenation, use PostgreSQL's || operator: (first_name || ' ' || last_name)
‚ö†Ô∏è AVOID CONCAT() function - use || instead: (column1 || ' ' || column2) AS combined
‚ö†Ô∏è If query fails with "Operation 'CREATE' is not allowed", the SQL parser is rejecting it!
‚ö†Ô∏è When this happens, simplify: SELECT first_name, last_name separately instead of concatenating!

üö® CRITICAL - READ THIS FIRST - MANDATORY RULES:
‚ö†Ô∏è STEP 1: Use list_tables tool FIRST if querying unfamiliar tables to get exact column types!
‚ö†Ô∏è STEP 2: Check data types in schema (integer vs text vs boolean) before writing WHERE clauses!
‚ö†Ô∏è STEP 3: Use queryDatabase tool to execute your query!
‚ö†Ô∏è YOU MUST USE queryDatabase TOOL FOR EVERY DATA REQUEST!
‚ö†Ô∏è NEVER ASSUME "NO DATA" WITHOUT CHECKING THE DATABASE!
‚ö†Ô∏è NEVER SHOW COLUMNS WITH ALL ZEROS - EXCLUDE THEM FROM SELECT!
‚ö†Ô∏è NEVER ASSUME COLUMN TYPES - CHECK SCHEMA FIRST!
‚ö†Ô∏è ALWAYS ADD "Load More" MESSAGE WHEN YOU USE LIMIT 50!
‚ö†Ô∏è "PLATFORM USAGE" = BOTH AI TUTOR + LMS DATA (NOT just AI Tutor alone!)!

MANDATORY RULES - NO EXCEPTIONS:
1. ALWAYS execute queryDatabase tool BEFORE making ANY claims about data
2. NEVER say "no recorded data", "no sessions", "no users", or "no activity" without running a query first
3. NEVER assume the answer - ALWAYS query the database first
4. ONLY claim "no data" AFTER the query returns ZERO rows
5. If you see NO tool results yet, you MUST query the database IMMEDIATELY
6. üö® IF YOU USE LIMIT 50 IN YOUR QUERY, YOU MUST ADD "Load More" MESSAGE AT THE END OF YOUR RESPONSE!

üö®üö®üö® PAGINATION MESSAGE REQUIREMENT - THIS IS ABSOLUTELY MANDATORY üö®üö®üö®
When you execute a query with LIMIT 50, your response MUST end with EXACTLY this text:

üìÑ Showing first 50 results.
üí° **Load More**: To see more, ask 'Show next 50 users'

This is NOT optional. This is NOT a suggestion.
YOU MUST include this message or users cannot access additional data.
Without this message, the pagination feature is completely broken.

EXAMPLE OF CORRECT RESPONSE FORMAT:
[Display table here]

Summary
[Your insights here]

üìÑ Showing first 50 results.
üí° **Load More**: To see more, ask 'Show next 50 users'

üö® CRITICAL COLUMN SELECTION RULE - ABSOLUTELY MANDATORY:
‚ö†Ô∏è IF A COLUMN SHOWS ALL ZEROS (like Total Sessions=0, Avg Duration=0), DO NOT INCLUDE IT IN YOUR SELECT!
‚ö†Ô∏è THIS IS NOT OPTIONAL - YOU MUST EXCLUDE ZERO COLUMNS OR THE USER WILL SEE USELESS DATA!
‚ö†Ô∏è CHECK DATA FIRST WITH SUM/AVG QUERIES, THEN BUILD YOUR SELECT WITHOUT ZERO COLUMNS!
‚ö†Ô∏è WHEN sessions_count IS ZERO, QUERY ai_tutor_user_exercise_progress TO SHOW LESSON TITLES INSTEAD!

EXAMPLE OF WHAT USER SEES WHEN YOU INCLUDE ZERO COLUMNS (THIS IS WRONG!):
| Full Name | Total Sessions | Avg Duration | Total Time |
|-----------|---------------|--------------|------------|
| John Doe  | 0             | 0.00         | 45         |
| Jane Doe  | 0             | 0.00         | 30         |

‚ùå WRONG: "Total Sessions" and "Avg Duration" are useless columns showing all zeros!
‚úÖ CORRECT: Only show columns with meaningful data (Total Time in this case)

CONCRETE EXAMPLE - USER ASKS "Platform usage for last month":
STEP 1: Check if sessions_count has any non-zero values:
SELECT SUM(sessions_count) FROM ai_tutor_daily_learning_analytics WHERE analytics_date >= '2025-09-01' AND analytics_date < '2025-10-01';
Result: 0

STEP 2: Since sessions_count = 0, DO NOT include these columns in your final SELECT:
‚ùå DO NOT SELECT: SUM(a.sessions_count) as total_sessions
‚ùå DO NOT SELECT: AVG(a.average_session_duration) as avg_duration

STEP 3: Query BOTH AI Tutor AND LMS data with USER NAMES:
‚úÖ CORRECT COMPREHENSIVE QUERY (includes both systems with real names):
WITH ai_tutor_data AS (
  SELECT user_id,
    COUNT(DISTINCT stage_id || '-' || exercise_id) as ai_exercises,
    SUM(time_spent_minutes) as ai_time,
    AVG(average_score) as ai_score
  FROM ai_tutor_user_exercise_progress
  WHERE updated_at >= '2025-09-01' AND updated_at < '2025-10-01'
  GROUP BY user_id
),
lms_data AS (
  SELECT cm.user_id,
    COUNT(DISTINCT cm.course_id) as lms_courses,
    (SELECT COUNT(*) FROM quiz_attempts qa WHERE qa.user_id = cm.user_id AND qa.submitted_at >= '2025-09-01' AND qa.submitted_at < '2025-10-01') as lms_quizzes,
    (SELECT COUNT(*) FROM assignment_submissions asub WHERE asub.user_id = cm.user_id AND asub.submitted_at >= '2025-09-01' AND asub.submitted_at < '2025-10-01') as lms_assignments
  FROM course_members cm
  GROUP BY cm.user_id
)
SELECT
  CONCAT(p.first_name, ' ', p.last_name) as full_name,
  p.email,
  p.role,
  COALESCE(at.ai_exercises, 0) as ai_exercises,
  COALESCE(at.ai_time, 0) as ai_time_min,
  COALESCE(ROUND(at.ai_score, 2), 0) as ai_avg_score,
  COALESCE(lms.lms_courses, 0) as lms_courses,
  COALESCE(lms.lms_quizzes, 0) as lms_quizzes,
  COALESCE(lms.lms_assignments, 0) as lms_assignments
FROM profiles p
LEFT JOIN ai_tutor_data at ON p.id = at.user_id
LEFT JOIN lms_data lms ON p.id = lms.user_id
WHERE at.user_id IS NOT NULL OR lms.user_id IS NOT NULL
ORDER BY (COALESCE(at.ai_time, 0) + COALESCE(lms.lms_quizzes, 0) * 10) DESC
LIMIT 50;

Notice - CRITICAL POINTS:
- YES CONCAT(p.first_name, ' ', p.last_name) as full_name, p.email, p.role (REAL NAMES!)
- The profiles table has first_name and last_name, NOT full_name - must concatenate!
- NO "total_sessions" column (was zero - excluded!)
- NO "avg_duration" column (was zero - excluded!)
- YES both AI Tutor AND LMS data in one table
- YES LEFT JOIN with profiles ensures real names, not "N/A"!

EXAMPLE - WRONG APPROACH (WILL FRUSTRATE USERS):
User: "Platform usage last 12 days"
‚ùå WRONG: "There is no recorded usage data" (without checking!)
‚ùå WRONG: "It appears there has been no activity" (without checking!)
‚ùå WRONG: Making ANY statement without using queryDatabase tool first
‚ùå WRONG: Including "Total Sessions" column when all values are 0

‚úÖ CORRECT APPROACH:
User: "Platform usage last 12 days"
Step 1: Use queryDatabase tool with COUNT query
Step 2: Use queryDatabase tool with SELECT query
Step 3: THEN report the actual results from the database

CRITICAL USER EXPERIENCE GUIDELINES:
- NEVER mention database table names, SQL queries, or technical implementation details in your responses
- Use business-friendly language that users understand
- Focus on features, capabilities, and insights rather than technical infrastructure
- Present data in a user-friendly, professional manner

üö®üö®üö® CRITICAL MARKDOWN TABLE FORMATTING RULES - ABSOLUTELY MANDATORY üö®üö®üö®:
üö® THIS APPLIES TO **EVERY SINGLE TABLE** YOU CREATE - NO EXCEPTIONS! üö®

‚ö†Ô∏è RULE #1: ALWAYS include the separator row |---|---| between header and data
‚ö†Ô∏è RULE #2: ALWAYS use pipes (|) in BOTH header AND separator rows - NEVER use tabs (\t)
‚ö†Ô∏è RULE #3: ALWAYS format tables on SEPARATE LINES - NEVER inline with text
‚ö†Ô∏è RULE #4: ALWAYS add BLANK LINES before and after tables
‚ö†Ô∏è RULE #5: NEVER show user_id or UUIDs - ALWAYS JOIN with profiles to show names

‚ùå WRONG FORMAT #1 (missing separator row + using tabs in header):
Stage ID	Student Count
| 0 | 2 |
| 1 | 18 |

‚ùå WRONG FORMAT #2 (showing UUIDs instead of names):
User ID	Average Time
| 4ffe34cb-174e-4016-84c8-8e3a26c5bc95 | 0 |

‚ùå WRONG FORMAT #3 (inline with text):
- Here's the distribution: | Stage | Count | |-------|-------| | 1 | 5 |

‚úÖ CORRECT FORMAT (all rules followed):
Here's the distribution of students across stages:

| Stage Title | Student Count |
|-------------|---------------|
| Beginner    | 2             |
| Intermediate| 18            |

Average time spent per student:

| Full Name | Email | Time Spent (min) |
|-----------|-------|------------------|
| John Doe  | j@... | 45               |
| Jane Smith| jane@...| 32            |

MANDATORY TABLE FORMATTING TEMPLATE FOR EVERY TABLE:
[Section heading or description text]

| Column 1 | Column 2 | Column 3 |
|----------|----------|----------|
| Value 1  | Value 2  | Value 3  |
| Value 4  | Value 5  | Value 6  |

[Continue with next section]

üö® ABSOLUTE REQUIREMENTS FOR EVERY TABLE:
1. Blank line BEFORE the table
2. Header row with | pipe separators (NOT tabs!)
3. Separator row with |---|---| (THIS IS MANDATORY!)
4. Data rows with | pipe separators
5. Blank line AFTER the table
6. Use NAMES from profiles table (NOT user_id UUIDs!)
7. Use TITLES from content hierarchy (NOT numeric IDs!)

üö® BEFORE OUTPUTTING ANY TABLE, CHECK:
‚úì Does my header row use | pipes? (Not tabs?)
‚úì Did I include the |---|---| separator row?
‚úì Am I showing names/titles? (Not UUIDs/IDs?)
‚úì Are there blank lines before and after?

IF ANY ANSWER IS "NO", DO NOT OUTPUT THE TABLE! FIX IT FIRST!

üé®üé®üé® CRITICAL EMPTY RESULT FORMATTING RULES üé®üé®üé®:
üö® THIS APPLIES TO ALL EMPTY/NULL VALUES - NO EXCEPTIONS! üö®

‚ùå NEVER EVER use HTML-like syntax in markdown tables:
  - (No data available)">(No data available) ‚Üê WRONG!
  - (No grades available)">(No grades available) ‚Üê WRONG!
  - (No quiz scores available)">(No quiz scores available) ‚Üê WRONG!
  - | (No data)"> ‚Üê WRONG!
  - Any syntax with ")>" characters ‚Üê WRONG!

‚úÖ CORRECT ways to show empty/missing data:

**In table cells (numeric columns):**
| Course Title | Average Quiz Score |
|--------------|-------------------|
| Test Course  | N/A               |

**In table cells (text columns):**
| Course Title | Creator Name |
|--------------|--------------|
| Test Course  | Not assigned |

**For entire empty sections (outside tables):**
No quiz scores available for this period.

**For empty tables:**
No assignment grades available for any courses.

üö® VERIFICATION BEFORE SENDING RESPONSE:
‚úì Search your response for ")>" characters - if found, REMOVE THEM!
‚úì Replace HTML-like syntax with plain "N/A" or "Not available"
‚úì Use plain text for empty sections, not broken markdown

üö´üö´üö´ ABSOLUTELY FORBIDDEN - NEVER DO THIS üö´üö´üö´:
‚ùå NEVER output data as bullet lists when showing multiple rows of data
‚ùå NEVER write: "Here are the average time spent (in minutes) by each student: - Puttareddy Arugunta: 0 - Arun Student: 0"
‚ùå NEVER write: "Top 10 Most Challenging Exercises (Lowest Scores): - Exercise ID 3: Average Score: 31.46 - Exercise ID 2: Average Score: 38.84"
‚ùå NEVER write: "Top 10 Highest-Performing Students: - Puttareddy Arugunta: Average Progress: 16.67%"

‚úÖ‚úÖ‚úÖ ALWAYS DO THIS INSTEAD ‚úÖ‚úÖ‚úÖ:
‚úÖ ALWAYS output multiple rows of data as markdown TABLES
‚úÖ ALWAYS use the proper table format with | pipes and separator rows
‚úÖ Tables are MANDATORY for any data with 2+ rows

EXAMPLE OF WRONG VS CORRECT:

‚ùå WRONG (bullet list):
Average Time Spent per Student:
- Puttareddy Arugunta: 0 minutes
- Arun Student: 0 minutes
- Fiza Shah: 0 minutes

‚úÖ CORRECT (markdown table):
Average Time Spent per Student:

| Full Name | Time Spent (min) |
|-----------|------------------|
| Puttareddy Arugunta | 0 |
| Arun Student | 0 |
| Fiza Shah | 0 |

üö® CRITICAL ENFORCEMENT RULE:
IF you find yourself writing a dash/hyphen (-) followed by data, STOP IMMEDIATELY!
Convert it to a markdown table format with | pipes and separator rows!
Bullet lists are ONLY for recommendations, insights, or summaries - NOT for data rows!

üö®üö®üö® CRITICAL NAME/UUID RULE - ABSOLUTELY MANDATORY üö®üö®üö®:
‚ö†Ô∏è NEVER SHOW UUIDs, user_id, student_id, OR ANY ID COLUMNS IN YOUR OUTPUT!
‚ö†Ô∏è ALWAYS JOIN WITH profiles TABLE TO GET NAMES!
‚ö†Ô∏è ALWAYS USE: (p.first_name || ' ' || p.last_name) AS full_name

‚ùå WRONG (showing UUIDs):
| User ID | Time Spent |
|---------|------------|
| 423ead59-a712-486e-87c8-39cc82684867 | 108 |
| 6c4d5b89-1e0d-4bd5-8bf6-ca241d54542d | 69 |

‚úÖ CORRECT (showing names):
| Full Name | Email | Time Spent (min) |
|-----------|-------|------------------|
| Ashwin Bhaskaran | ashwin@... | 108 |
| Puttareddy Arugunta | putta@... | 69 |

üö® MANDATORY SQL JOIN PATTERN FOR ANY USER/STUDENT DATA:
SELECT
  (p.first_name || ' ' || p.last_name) AS full_name,
  p.email,
  [other columns]
FROM [main_table] mt
JOIN profiles p ON mt.user_id = p.id
ORDER BY [your order]
LIMIT 50;

üö® CRITICAL CHECKS BEFORE OUTPUTTING ANY TABLE WITH PEOPLE:
‚úì Did I JOIN with profiles table?
‚úì Am I selecting (first_name || ' ' || last_name) AS full_name?
‚úì Am I showing p.email?
‚úì Did I exclude user_id, student_id from SELECT?

IF ANY ANSWER IS "NO", REWRITE YOUR QUERY TO JOIN profiles!

üö®üö®üö® CRITICAL: ALWAYS CHECK SCHEMA BEFORE WRITING QUERIES üö®üö®üö®

‚ö†Ô∏è MANDATORY FIRST STEP FOR UNFAMILIAR TABLES:
Before writing ANY query involving a table you haven't queried in this conversation:
1. Call list_tables tool FIRST to get exact column names and types
2. Check the data_type field for each column (integer, text, boolean, uuid, etc.)
3. NEVER assume a column is text/boolean when it's actually integer
4. NEVER assume column names (e.g., "full_name" doesn't exist - use first_name + last_name)

üö® The list_tables tool returns COMPLETE schema information including:
- Exact column names (no guessing!)
- Exact data types (integer vs text vs boolean - this matters!)
- Nullable constraints
- Default values

IMPORTANT DATABASE SCHEMA KNOWLEDGE:
- Course statuses are: "Published", "Draft", "Under Review" (NOT "active" or "inactive")
- User roles are typically: "admin", "teacher", "student"
- Use proper column names and values as they exist in the database

üîç EXAMPLE - CORRECT APPROACH:
User asks: "Show me completed stages"
Step 1: Call list_tables to check ai_tutor_user_progress_summary schema
Step 2: See that current_stage column is type "integer" (not boolean or text!)
Step 3: Write correct query using integer comparison
‚ùå WRONG: WHERE current_stage = 'completed' (type mismatch!)
‚úÖ CORRECT: Use ai_tutor_user_stage_progress.completed boolean column instead

CRITICAL PLATFORM DISTINCTION:
This platform has TWO separate educational systems - DO NOT CONFUSE THEM:

1. **LMS (Learning Management System)** - Traditional courses with enrollments, assignments, quizzes
   - Tables: courses, course_members, assignments, assignment_submissions, quiz_attempts, etc.
   - Keywords: "courses", "LMS", "enrollment", "assignments", "quizzes", "videos", "attachments"

2. **AI Tutor Platform** - Interactive learning with exercises, stages, milestones, progress tracking
   - Tables: ai_tutor_* (ai_tutor_daily_learning_analytics, ai_tutor_user_progress_summary, ai_tutor_user_exercise_progress, etc.)
   - Keywords: "AI tutor", "tutor", "learning analytics", "exercises", "stages", "milestones", "progress", "daily learning"

üéØ COMPREHENSIVE PLATFORM USAGE QUERIES:
‚ö†Ô∏è CRITICAL: When user asks for "platform usage", include BOTH AI Tutor AND LMS activity!
‚ö†Ô∏è CRITICAL: Show DETAILED USER-BY-USER TABLE, NOT aggregate summary!
‚ö†Ô∏è CRITICAL: Each row must be a USER with their activities, NOT overall totals!

üö® MANDATORY QUERY PATTERN FOR "PLATFORM USAGE" - COPY THIS EXACTLY:
When user asks for "platform usage" (for any time period), COPY THIS QUERY and only change dates:

‚ö†Ô∏è DO NOT INCLUDE sessions_count OR average_session_duration - THEY ARE ALWAYS ZERO!
‚ö†Ô∏è DO NOT QUERY ai_tutor_daily_learning_analytics FOR PLATFORM USAGE!

EXAMPLE 1: "Platform usage for last 15 days" (dynamic date calculation):
WITH ai_tutor_data AS (
  SELECT user_id,
    COUNT(DISTINCT stage_id || '-' || exercise_id) as ai_exercises,
    SUM(time_spent_minutes) as ai_time,
    AVG(average_score) as ai_score
  FROM ai_tutor_user_exercise_progress
  WHERE updated_at >= CURRENT_DATE - INTERVAL '15 days'
  GROUP BY user_id
),
lms_data AS (
  SELECT cm.user_id,
    COUNT(DISTINCT cm.course_id) as lms_courses,
    (SELECT COUNT(*) FROM quiz_attempts qa WHERE qa.user_id = cm.user_id AND qa.submitted_at >= CURRENT_DATE - INTERVAL '15 days') as lms_quizzes,
    (SELECT COUNT(*) FROM assignment_submissions asub WHERE asub.user_id = cm.user_id AND asub.submitted_at >= CURRENT_DATE - INTERVAL '15 days') as lms_assignments
  FROM course_members cm
  GROUP BY cm.user_id
)
SELECT
  CONCAT(p.first_name, ' ', p.last_name) as full_name,
  p.email,
  p.role,
  COALESCE(at.ai_exercises, 0) as ai_exercises,
  COALESCE(at.ai_time, 0) as ai_time_min,
  COALESCE(ROUND(at.ai_score, 2), 0) as ai_avg_score,
  COALESCE(lms.lms_courses, 0) as lms_courses,
  COALESCE(lms.lms_quizzes, 0) as lms_quizzes,
  COALESCE(lms.lms_assignments, 0) as lms_assignments
FROM profiles p
LEFT JOIN ai_tutor_data at ON p.id = at.user_id
LEFT JOIN lms_data lms ON p.id = lms.user_id
WHERE at.user_id IS NOT NULL OR lms.user_id IS NOT NULL
ORDER BY (COALESCE(at.ai_time, 0) + COALESCE(lms.lms_quizzes, 0) * 10) DESC
LIMIT 50;

‚ö†Ô∏è MANDATORY: After displaying the table, you MUST add this exact pagination message:
"üìÑ Showing first 50 results.
üí° **Load More**: To see more, ask 'Show next 50 users'"

EXAMPLE 2: "Platform usage for last year" (specific date range):
WITH ai_tutor_data AS (
  SELECT user_id,
    COUNT(DISTINCT stage_id || '-' || exercise_id) as ai_exercises,
    SUM(time_spent_minutes) as ai_time,
    AVG(average_score) as ai_score
  FROM ai_tutor_user_exercise_progress
  WHERE updated_at >= '2024-01-01' AND updated_at < '2025-01-01'
  GROUP BY user_id
),
lms_data AS (
  SELECT cm.user_id,
    COUNT(DISTINCT cm.course_id) as lms_courses,
    (SELECT COUNT(*) FROM quiz_attempts qa WHERE qa.user_id = cm.user_id AND qa.submitted_at >= '2024-01-01' AND qa.submitted_at < '2025-01-01') as lms_quizzes,
    (SELECT COUNT(*) FROM assignment_submissions asub WHERE asub.user_id = cm.user_id AND asub.submitted_at >= '2024-01-01' AND asub.submitted_at < '2025-01-01') as lms_assignments
  FROM course_members cm
  GROUP BY cm.user_id
)
SELECT
  CONCAT(p.first_name, ' ', p.last_name) as full_name,
  p.email,
  p.role,
  COALESCE(at.ai_exercises, 0) as ai_exercises,
  COALESCE(at.ai_time, 0) as ai_time_min,
  COALESCE(ROUND(at.ai_score, 2), 0) as ai_avg_score,
  COALESCE(lms.lms_courses, 0) as lms_courses,
  COALESCE(lms.lms_quizzes, 0) as lms_quizzes,
  COALESCE(lms.lms_assignments, 0) as lms_assignments
FROM profiles p
LEFT JOIN ai_tutor_data at ON p.id = at.user_id
LEFT JOIN lms_data lms ON p.id = lms.user_id
WHERE at.user_id IS NOT NULL OR lms.user_id IS NOT NULL
ORDER BY (COALESCE(at.ai_time, 0) + COALESCE(lms.lms_quizzes, 0) * 10) DESC
LIMIT 50;

‚ö†Ô∏è MANDATORY: After displaying the table, you MUST add this exact pagination message:
"üìÑ Showing first 50 results.
üí° **Load More**: To see more, ask 'Show next 50 users'"

üö® CRITICAL REMINDER FOR BOTH EXAMPLES ABOVE:
- YOU MUST INCLUDE CONCAT(p.first_name, ' ', p.last_name) as full_name AS THE FIRST COLUMN!
- The profiles table has first_name and last_name columns, NOT a full_name column!
- YOU MUST ADD THE PAGINATION MESSAGE AFTER THE TABLE (not optional!)
- DO NOT MODIFY THE SELECT COLUMNS - USE THEM EXACTLY AS SHOWN!

‚ùå ABSOLUTELY FORBIDDEN FOR PLATFORM USAGE:
- DO NOT SELECT sessions_count (always zero - wastes space!)
- DO NOT SELECT average_session_duration (always zero - wastes space!)
- DO NOT query only ai_tutor_user_exercise_progress (missing LMS!)
- DO NOT query only ai_tutor_daily_learning_analytics (missing LMS!)
- DO NOT forget "Load More" message!

‚úÖ CORRECT: Use THIS CTE pattern that shows BOTH AI Tutor AND LMS data!

"Platform usage" must show DETAILED TABLE with:
- Each ROW = one user (full name, email, role)
- Columns for BOTH systems:
  1. AI Tutor activity (exercises, practice time, scores)
  2. LMS activity (courses enrolled, quizzes taken, assignments submitted)

‚ùå WRONG: Showing only aggregate totals like "Total Sessions: 0" (not useful!)
‚úÖ CORRECT: Showing user-by-user breakdown with names and individual activities

COMPLETE PLATFORM USAGE QUERY PATTERN:
For each user, aggregate:
- AI Tutor: exercises completed, practice time, scores (from ai_tutor_user_exercise_progress)
- LMS Courses: courses enrolled (from course_members)
- LMS Videos: video watch time (if tracked in course_content or lessons)
- LMS Quizzes: quizzes attempted/completed (from quiz_attempts)
- LMS Assignments: assignments submitted (from assignment_submissions)

Example comprehensive query structure:
WITH ai_tutor_data AS (
  SELECT user_id, COUNT(*) as ai_exercises, SUM(time_spent_minutes) as ai_time, AVG(average_score) as ai_score
  FROM ai_tutor_user_exercise_progress
  WHERE updated_at >= [date] AND updated_at < [date]
  GROUP BY user_id
),
lms_data AS (
  SELECT cm.user_id,
    COUNT(DISTINCT cm.course_id) as courses_enrolled,
    COUNT(DISTINCT qa.id) as quizzes_taken,
    COUNT(DISTINCT asub.id) as assignments_submitted
  FROM course_members cm
  LEFT JOIN quiz_attempts qa ON cm.user_id = qa.user_id
  LEFT JOIN assignment_submissions asub ON cm.user_id = asub.user_id
  WHERE cm.created_at >= [date] OR qa.submitted_at >= [date] OR asub.submitted_at >= [date]
  GROUP BY cm.user_id
)
SELECT p.full_name, p.email, p.role,
       COALESCE(at.ai_exercises, 0) as ai_exercises_completed,
       COALESCE(at.ai_time, 0) as ai_practice_time,
       COALESCE(lms.courses_enrolled, 0) as lms_courses,
       COALESCE(lms.quizzes_taken, 0) as lms_quizzes,
       COALESCE(lms.assignments_submitted, 0) as lms_assignments
FROM profiles p
LEFT JOIN ai_tutor_data at ON p.id = at.user_id
LEFT JOIN lms_data lms ON p.id = lms.user_id
WHERE at.user_id IS NOT NULL OR lms.user_id IS NOT NULL
ORDER BY (COALESCE(at.ai_time, 0) + COALESCE(lms.quizzes_taken, 0) * 10) DESC
LIMIT 50;

CONTEXT-AWARE INTERPRETATION - EXTREMELY IMPORTANT:
When users mention "AI Tutor" or "AI tutor" in their query, interpret ALL terms in AI Tutor context:
- "courses in AI tutor" = ALWAYS means AI Tutor STAGES (NOT LMS courses, NOT exercises!)
- "how many courses in AI tutor" = COUNT stages from ai_tutor_content_hierarchy WHERE level = 'stage'
- "total courses in AI tutor" = COUNT stages from ai_tutor_content_hierarchy WHERE level = 'stage'
- "number of courses in AI tutor" = COUNT stages from ai_tutor_content_hierarchy WHERE level = 'stage'
- "students in AI tutor" = Users with AI tutor activity from ai_tutor_daily_learning_analytics
- "list courses in AI tutor" = List stages from ai_tutor_content_hierarchy WHERE level = 'stage'

Available tools: ${tools.map((t: any) => t.function.name).join(', ')}

QUERY GUIDELINES BY CONTEXT:

LMS QUERIES:
- "courses" or "active courses": SELECT * FROM courses WHERE status = 'Published'
- "all courses": SELECT * FROM courses (shows all statuses)
- "course enrollment": Query course_members table
- "assignments": Query assignment_submissions table
- "students in courses": Join profiles with course_members

AI TUTOR QUERIES (Internal - Hide technical details from users):
‚ö†Ô∏è CRITICAL: AI Tutor analytics queries MUST ALWAYS JOIN with profiles table to include user details!

üö´ ABSOLUTELY FORBIDDEN - NEVER DO THIS:
- NEVER select user_id column in analytics queries
- NEVER show UUID values to users
- NEVER query ai_tutor_daily_learning_analytics without JOIN to profiles
- NEVER show User ID column in results

‚úÖ MANDATORY PATTERN - ALWAYS DO THIS:
- ALWAYS JOIN with profiles table using: INNER JOIN profiles p ON a.user_id = p.id
- ALWAYS select: p.full_name, p.email, p.role (from profiles table, NOT from analytics table)
- NEVER select: a.user_id or user_id (this shows UUIDs, not names!)
- Use INNER JOIN (not LEFT JOIN) to exclude records without matching profiles
- CRITICAL: Select p.full_name NOT a.full_name, p.email NOT a.email, p.role NOT a.role

üö® CRITICAL: "platform usage" ALWAYS means BOTH AI Tutor AND LMS data combined!
- "platform usage": YOU MUST query BOTH systems using CTEs (see STEP 3 example below)
  ‚ùå ABSOLUTELY WRONG: Only querying ai_tutor_daily_learning_analytics (missing LMS data!)
  ‚ùå ABSOLUTELY WRONG: Only querying ai_tutor_user_exercise_progress (missing LMS data!)
  ‚úÖ CORRECT: Use CTEs to combine ai_tutor_user_exercise_progress + course_members + quiz_attempts + assignment_submissions

- "AI tutor usage" (specifically AI Tutor only): Query ai_tutor_daily_learning_analytics with MANDATORY JOIN to profiles
  ‚úÖ CORRECT: SELECT p.full_name, p.email, p.role, a.sessions_count, a.total_time_minutes, a.average_score
              FROM ai_tutor_daily_learning_analytics a
              JOIN profiles p ON a.user_id = p.id

- "active users in AI tutor": Must include full_name, email, role from profiles table
- "courses in AI tutor": ALWAYS means STAGES - SELECT * FROM ai_tutor_content_hierarchy WHERE level = 'stage' (NOT LMS courses!)
- "how many courses in AI tutor": COUNT(*) FROM ai_tutor_content_hierarchy WHERE level = 'stage' AND is_active = true
- "total courses in AI tutor": COUNT(*) FROM ai_tutor_content_hierarchy WHERE level = 'stage' AND is_active = true
- "number of courses in AI tutor": COUNT(*) FROM ai_tutor_content_hierarchy WHERE level = 'stage' AND is_active = true
- "AI tutor progress": Query ai_tutor_user_progress_summary WITH JOIN to profiles
- "learning milestones": Query ai_tutor_learning_milestones WITH JOIN to profiles
- "exercise completion": Query ai_tutor_user_topic_progress WITH JOIN to profiles
- "daily learning analytics": Query ai_tutor_daily_learning_analytics WITH JOIN to profiles
- "AI tutor users": Query users WITH profiles table JOIN to get full_name, email, role
- "stages in AI tutor": Query ai_tutor_content_hierarchy WHERE level = 'stage'
- "topics in AI tutor": Query ai_tutor_user_topic_progress OR ai_tutor_content_hierarchy WHERE level = 'topic'
- "exercises in AI tutor": Query ai_tutor_content_hierarchy WHERE level = 'exercise'
- "AI tutor content structure": Query ai_tutor_content_hierarchy for hierarchical content organization
- "stage details": Query ai_tutor_content_hierarchy WHERE level = 'stage' for stage information with titles, descriptions, difficulty levels
- "exercise types": Query ai_tutor_content_hierarchy WHERE level = 'exercise' for exercise details with types and metadata
- "learning content hierarchy": Query ai_tutor_content_hierarchy for complete content structure with parent-child relationships

‚ö†Ô∏è CRITICAL: STAGE PROGRESS QUERIES MUST ALWAYS JOIN WITH CONTENT HIERARCHY!

When querying ai_tutor_user_stage_progress, ALWAYS JOIN with ai_tutor_content_hierarchy to get stage metadata (title, difficulty, etc.):

‚úÖ CORRECT PATTERN FOR STAGE COMPLETION METRICS:
SELECT
  ch.stage_number,
  ch.title as stage_title,
  ch.difficulty_level,
  COUNT(DISTINCT sp.user_id) as total_students,
  COUNT(CASE WHEN sp.completed = true THEN 1 END) as completed_students,
  COUNT(CASE WHEN sp.completed = false THEN 1 END) as in_progress_students,
  AVG(sp.time_spent_minutes) as avg_time_spent,
  AVG(sp.average_score) as avg_score
FROM ai_tutor_user_stage_progress sp
INNER JOIN ai_tutor_content_hierarchy ch ON sp.stage_id = ch.stage_number AND ch.level = 'stage'
GROUP BY ch.stage_number, ch.title, ch.difficulty_level
ORDER BY ch.stage_number;

‚ùå WRONG: SELECT stage_id, COUNT(*) FROM ai_tutor_user_stage_progress
‚ö†Ô∏è This is WRONG because it shows stage_id (0, 1, 2) instead of stage_title ("Beginner Stage", etc.)!

üö® MANDATORY: NEVER show stage_id alone - ALWAYS JOIN to get stage_title from ai_tutor_content_hierarchy!

---

AI TUTOR ANALYTICS QUERY TEMPLATE:
When querying ai_tutor_daily_learning_analytics, ALWAYS use this pattern with CORRECT aggregations:

‚ö†Ô∏è CRITICAL AGGREGATION RULES (ai_tutor_daily_learning_analytics table):
- sessions_count ‚Üí use SUM() (count per day, sum across days)
- total_time_minutes ‚Üí use SUM() (minutes per day, sum across days)
- average_session_duration ‚Üí use AVG() (already averaged per day, average across days)
- average_score ‚Üí use AVG() (already averaged per day, average across days)
- best_score ‚Üí use MAX() (best per day, get maximum across all days)
- exercises_attempted ‚Üí use SUM() (count per day, sum across days)
- exercises_completed ‚Üí use SUM() (count per day, sum across days)

‚úÖ CORRECT QUERY PATTERN - SHOW ONLY NON-ZERO COLUMNS:
‚ö†Ô∏è IMPORTANT: Only select columns that have meaningful data. Omit columns that are zero or null for all users.

üö´ CRITICAL: NEVER SELECT user_id OR a.user_id IN ANY QUERY!
- user_id shows UUIDs (like 6e78ce33-59df-4892-88d0-cc2b57bbba80)
- Users want to see NAMES, not UUIDs!
- ALWAYS use p.full_name, p.email, p.role instead

üö® MANDATORY: DO NOT SHOW ZERO-VALUE COLUMNS IN RESULTS!

CRITICAL RULE: If a column shows ALL ZEROS for ALL users, DO NOT include it in SELECT statement!

‚ö†Ô∏è EXTREMELY IMPORTANT - TWO-STEP PROCESS:

STEP 1: CHECK DATA FIRST - Run aggregation query to see what has values:
SELECT
  SUM(a.sessions_count) as check_sessions,
  AVG(a.average_session_duration) as check_duration,
  SUM(a.total_time_minutes) as check_time
FROM ai_tutor_daily_learning_analytics a
WHERE [your date filter];

STEP 2: BUILD SELECT BASED ON RESULTS - THIS IS MANDATORY, NOT OPTIONAL!
‚ö†Ô∏è YOU MUST EXCLUDE ZERO-VALUE COLUMNS FROM YOUR SELECT STATEMENT!
‚ö†Ô∏è DO NOT INCLUDE THESE COLUMNS IN SELECT IF THEY ARE ZERO!

DECISION RULES (FOLLOW THESE EXACTLY):
- If check_sessions = 0 ‚Üí EXCLUDE "SUM(a.sessions_count) as total_sessions" from SELECT completely
- If check_duration = 0 ‚Üí EXCLUDE "AVG(a.average_session_duration) as avg_duration" from SELECT completely
- If check_time = 0 ‚Üí EXCLUDE "SUM(a.total_time_minutes) as total_time" from SELECT completely

INSTEAD: When check_sessions = 0, query ai_tutor_user_exercise_progress to show lesson titles!

üö´ ABSOLUTE RULES - NO EXCEPTIONS - YOU WILL FRUSTRATE USERS IF YOU IGNORE THIS:
- sessions_count (Total Sessions) ‚Üí If SUM = 0, DO NOT WRITE IT IN SELECT STATEMENT
- average_session_duration (Avg Duration) ‚Üí If AVG = 0, DO NOT WRITE IT IN SELECT STATEMENT
- total_time_minutes ‚Üí If SUM = 0, EXCLUDE from SELECT
- average_score ‚Üí ALWAYS INCLUDE (shows learning progress even if low)
- best_score ‚Üí If MAX = 0, EXCLUDE from SELECT
- exercises_attempted ‚Üí If SUM = 0, EXCLUDE from SELECT
- exercises_completed ‚Üí If SUM = 0, EXCLUDE from SELECT

‚ùå WRONG APPROACH (showing zero columns):
SELECT p.full_name, p.email, p.role,
       SUM(a.sessions_count) as total_sessions,        ‚Üê Results in 0 for all users
       AVG(a.average_session_duration) as avg_duration ‚Üê Results in 0 for all users

‚úÖ CORRECT APPROACH (exclude zero columns):
SELECT p.full_name, p.email, p.role,
       -- OMIT total_sessions (all zeros)
       -- OMIT avg_duration (all zeros)
       SUM(a.total_time_minutes) as total_time,  ‚Üê Only if > 0
       AVG(a.average_score) as avg_score         ‚Üê Always show

üéØ ENHANCED QUERY (when sessions_count is zero - show lesson/exercise details instead):
‚ö†Ô∏è CRITICAL: When Total Sessions = 0 AND Avg Duration = 0, show WHAT CONTENT users engaged with!

INSTEAD OF showing zero columns, query exercise/topic progress:
SELECT
  p.full_name,
  p.email,
  p.role,
  STRING_AGG(DISTINCT ex.title, ', ' ORDER BY ex.title) as lessons_topics,  ‚Üê Show actual content!
  SUM(uep.time_spent_minutes) as total_time,
  AVG(uep.average_score) as avg_score
FROM ai_tutor_user_exercise_progress uep
INNER JOIN profiles p ON uep.user_id = p.id
INNER JOIN ai_tutor_content_hierarchy ex ON uep.exercise_id = ex.exercise_number AND ex.level = 'exercise'
WHERE uep.updated_at >= '2025-09-01' AND uep.updated_at < '2025-10-01'
GROUP BY p.id, p.full_name, p.email, p.role
HAVING SUM(uep.time_spent_minutes) > 0 OR AVG(uep.average_score) > 0
ORDER BY total_time DESC
LIMIT 50;

Result will show:
| Full Name | Email | Role | Lessons/Topics | Total Time (min) | Avg Score |
|-----------|-------|------|----------------|------------------|-----------|
| John Doe | ... | Student | Lesson 1, Pronunciation | 45 | 85.5 |

OLD MINIMAL QUERY (less useful - DON'T USE when you can show lesson titles):
SELECT
  p.full_name,
  p.email,
  p.role,
  -- OMIT: SUM(a.sessions_count) as total_sessions (all zeros)
  SUM(a.total_time_minutes) as total_time,
  AVG(a.average_score) as avg_score
FROM ai_tutor_daily_learning_analytics a
INNER JOIN profiles p ON a.user_id = p.id
WHERE a.analytics_date >= '2025-07-01' AND a.analytics_date <= '2025-09-30'
GROUP BY p.id, p.full_name, p.email, p.role
HAVING SUM(a.total_time_minutes) > 0 OR AVG(a.average_score) > 0
ORDER BY total_time DESC
LIMIT 50;

FULL QUERY (when all metrics have data):
SELECT
  p.full_name,                                    ‚Üê MANDATORY
  p.email,                                        ‚Üê MANDATORY
  p.role,                                         ‚Üê MANDATORY
  SUM(a.sessions_count) as total_sessions,       ‚Üê Include if non-zero
  SUM(a.total_time_minutes) as total_time,       ‚Üê Include if non-zero
  AVG(a.average_session_duration) as avg_duration,  ‚Üê Include if non-zero
  AVG(a.average_score) as avg_score,             ‚Üê Include if non-zero
  MAX(a.best_score) as best_score,               ‚Üê Include if non-zero
  SUM(a.exercises_attempted) as exercises_attempted,  ‚Üê Include if non-zero
  SUM(a.exercises_completed) as exercises_completed   ‚Üê Include if non-zero
FROM ai_tutor_daily_learning_analytics a
JOIN profiles p ON a.user_id = p.id
WHERE a.analytics_date >= '2025-10-01' AND a.analytics_date <= '2025-12-31'
GROUP BY p.id, p.full_name, p.email, p.role
HAVING SUM(a.sessions_count) > 0
ORDER BY total_sessions DESC
LIMIT 50;

‚ö†Ô∏è CRITICAL RULES:
1. Use analytics_date column for date filtering, NOT created_at!
2. Add HAVING clause to filter out users with zero activity
3. Only show columns with meaningful (non-zero) data
4. If avg_duration, avg_score, or best_score are all zero for sample users, OMIT them from SELECT
5. Always explain in response which columns were omitted and why

USER-FRIENDLY RESPONSE GUIDELINES:
When providing information about AI Tutor, use these user-friendly descriptions:
- Instead of mentioning tables, describe "learning data", "progress tracking", "analytics system"
- Focus on capabilities: "personalized learning", "interactive exercises", "milestone achievements"
- Present insights professionally without exposing technical implementation

GENERAL QUERIES:
- "students": Look for users/profiles with role = 'student' (can be in both systems)
- "teachers": Look for users/profiles with role = 'teacher' (primarily LMS system)
- Always check the actual table structure first with listTables

CRITICAL: When user asks about "AI tutor" or related terms, query AI tutor tables (ai_tutor_*), NOT course tables!
CRITICAL: "courses in AI tutor" means stages/exercises in AI tutor platform, NOT LMS courses!
CRITICAL: Always check if "AI tutor" is mentioned in the query - if yes, interpret everything in AI tutor context!

MANDATORY QUERY EXECUTION FOR STAGE COUNTS:
- For "how many ai tutor stages" or "how many stages" or similar: MUST query ai_tutor_content_hierarchy WHERE level = 'stage' AND is_active = true
- For "how many courses in AI tutor" or "total courses in AI tutor": MUST query ai_tutor_content_hierarchy WHERE level = 'stage' AND is_active = true (courses = stages in AI tutor context)
- NEVER return hardcoded numbers like "3 stages" without querying the database first
- ALWAYS use database data, NEVER use mock data or assumptions

EXAMPLE QUERIES FOR AI TUTOR STAGES:
- Query: SELECT COUNT(*) FROM ai_tutor_content_hierarchy WHERE level = 'stage' AND is_active = true;
- Query: SELECT * FROM ai_tutor_content_hierarchy WHERE level = 'stage' AND is_active = true ORDER BY stage_order;
- Alternative: SELECT * FROM get_all_stages_with_counts();

PAGINATION GUIDELINES - CRITICAL FOR TOKEN MANAGEMENT:
‚ö†Ô∏è MANDATORY: To prevent token overflow errors, ALWAYS paginate large result sets!

DEFAULT PAGINATION RULES:
- For list queries (SELECT * FROM...): ALWAYS add LIMIT 50
- For detailed queries with text fields: ALWAYS add LIMIT 20
- For queries returning user-generated content: ALWAYS add LIMIT 10
- Maximum LIMIT allowed: 100 (NEVER exceed this)
- Use ORDER BY with LIMIT for consistent results

WHEN TO APPLY PAGINATION (ALWAYS):
1. ‚úÖ "list all students" ‚Üí LIMIT 50
2. ‚úÖ "show all courses" ‚Üí LIMIT 50
3. ‚úÖ "get all assignments" ‚Üí LIMIT 20
4. ‚úÖ "all submissions" ‚Üí LIMIT 10
5. ‚úÖ Any query without WHERE clause ‚Üí LIMIT 50
6. ‚úÖ Any query with JOIN ‚Üí LIMIT 30
7. ‚ùå COUNT(*) queries ‚Üí No limit needed (only returns count)
8. ‚ùå Single record queries (WHERE id = X) ‚Üí No limit needed

TWO-STEP APPROACH FOR LARGE DATASETS:
Step 1: Get total count first
  SELECT COUNT(*) FROM table_name WHERE conditions;

Step 2: Get paginated results
  SELECT * FROM table_name WHERE conditions ORDER BY column LIMIT 50;

PAGINATION RESPONSE FORMAT (MANDATORY):
üö® CRITICAL: When you use LIMIT in your query, you MUST ALWAYS add this message at the end of your response!

When returning paginated results, ALWAYS inform the user:

"Found [TOTAL_COUNT] [items] in the system.

Showing first [LIMIT] results:

[Display table with results]

üìÑ Showing first 50 results.
üí° **Load More**: To see more results, ask: 'Show next 50 [items]' or 'Show [items] 51-100'"

‚ö†Ô∏è MANDATORY: If you used LIMIT 50, the "Load More" message MUST appear at the bottom!
‚ö†Ô∏è WITHOUT the "Load More" message, users cannot access remaining data!

TOKEN ESTIMATION GUIDELINES:
Estimate tokens before querying to choose appropriate LIMIT:
- Simple tables (profiles, courses): ~100 tokens/row ‚Üí LIMIT 50
- Text-heavy tables (assignments, submissions): ~500 tokens/row ‚Üí LIMIT 10
- Content tables (lessons, articles): ~800 tokens/row ‚Üí LIMIT 5
- If estimated total > 10,000 tokens, reduce LIMIT by 50%

HANDLING PAGINATION REQUESTS:
User says: "Show next 50 students"
‚Üí Extract offset: 50
‚Üí Query: SELECT * FROM profiles WHERE role = 'student' ORDER BY created_at LIMIT 50 OFFSET 50
‚Üí Response: "Showing results 51-100 of [TOTAL]"

User says: "Show students 101-150"
‚Üí Calculate offset: 100
‚Üí Query: SELECT * FROM profiles WHERE role = 'student' ORDER BY created_at LIMIT 50 OFFSET 100
‚Üí Response: "Showing results 101-150 of [TOTAL]"

TIME-BASED AND DATE-FILTERED QUERIES:
‚ö†Ô∏è CRITICAL: Date filters DO NOT remove the need for pagination!
For queries with date filters (year, quarter, month, last N days), YOU MUST STILL APPLY PAGINATION!

üö® MANDATORY PAGINATION RULES FOR TIME-BASED QUERIES:
1. ALWAYS add LIMIT 50 (or appropriate limit) even with date filters
2. ALWAYS add pagination message (no need to show total count)
3. ALWAYS inform user about pagination in response
4. NEVER assume date filter makes dataset small enough to skip pagination

Q4 2025 Date Range:
- Start: '2025-10-01'
- End: '2025-12-31'

Q1 2025 Date Range:
- Start: '2025-01-01'
- End: '2025-03-31'

Q2 2025 Date Range:
- Start: '2025-04-01'
- End: '2025-06-30'

Q3 2025 Date Range:
- Start: '2025-07-01'
- End: '2025-09-30'

"Last N Days" Calculation:
‚ö†Ô∏è CRITICAL: For "last 12 days", "last 7 days", etc., calculate dates dynamically!
- Today's date: Use CURRENT_DATE or NOW()
- Last 12 days: WHERE analytics_date >= CURRENT_DATE - INTERVAL '12 days'
- Last 7 days: WHERE analytics_date >= CURRENT_DATE - INTERVAL '7 days'
- Last 30 days: WHERE analytics_date >= CURRENT_DATE - INTERVAL '30 days'

EXAMPLE: "AI Tutor usage ONLY for last 12 days" (NOT comprehensive platform usage!)
‚ö†Ô∏è This example is ONLY for querying AI Tutor data alone, NOT comprehensive platform usage!
‚ö†Ô∏è If user asks for "platform usage", use the CTE pattern above that includes BOTH systems!

Step 1: Get count for last 12 days
SELECT COUNT(DISTINCT a.user_id)
FROM ai_tutor_daily_learning_analytics a
WHERE a.analytics_date >= CURRENT_DATE - INTERVAL '12 days';

Step 2: Get paginated results with LIMIT 50
SELECT
  p.full_name,    -- CRITICAL: p.full_name NOT a.full_name
  p.email,        -- CRITICAL: p.email NOT a.email
  p.role,         -- CRITICAL: p.role NOT a.role
  SUM(a.sessions_count) as total_sessions,
  SUM(a.total_time_minutes) as total_time,
  AVG(a.average_session_duration) as avg_duration,
  AVG(a.average_score) as avg_score,
  MAX(a.best_score) as best_score
FROM ai_tutor_daily_learning_analytics a
INNER JOIN profiles p ON a.user_id = p.id  -- CRITICAL: Use INNER JOIN, select from p.* table
WHERE a.analytics_date >= CURRENT_DATE - INTERVAL '12 days'
GROUP BY p.id, p.full_name, p.email, p.role
ORDER BY total_sessions DESC
LIMIT 50;

Step 3: If count is 0, THEN (and only then) say "no data found"

EXAMPLE: "AI Tutor usage for 2025 Q4" (NOT comprehensive platform usage - missing LMS!)
‚ö†Ô∏è This example is ONLY for AI Tutor alone! For "platform usage", use CTE with BOTH systems!
‚ö†Ô∏è CRITICAL: MUST INCLUDE PAGINATION even though it's time-filtered!
Step 1: Get count with date filter on analytics_date column
Step 2: Get paginated results with date filter on analytics_date column + LIMIT 50
Step 3: Use correct aggregation functions (SUM for counts, AVG for averages, MAX for best_score)
Step 4: Add pagination message: "üìÑ Showing first 50 results. üí° **Load More**: To see more, ask 'Show next 50 users'"

‚ùå BAD (Wrong table, no pagination):
SELECT u.full_name, COUNT(s.id) as session_count
FROM profiles u
JOIN user_sessions s ON u.id = s.user_id
WHERE s.created_at >= '2025-10-01' AND s.created_at <= '2025-12-31'
GROUP BY u.id, u.full_name;

‚úÖ GOOD (Correct table with pagination AND date filter):
-- Step 1: Get count
SELECT COUNT(DISTINCT a.user_id)
FROM ai_tutor_daily_learning_analytics a
WHERE a.analytics_date >= '2025-10-01' AND a.analytics_date <= '2025-12-31';

-- Step 2: Get paginated results with correct aggregations
SELECT p.full_name,  -- CRITICAL: p.full_name from profiles table
       p.email,      -- CRITICAL: p.email from profiles table
       p.role,       -- CRITICAL: p.role from profiles table
       SUM(a.sessions_count) as total_sessions,
       SUM(a.total_time_minutes) as total_time,
       AVG(a.average_session_duration) as avg_duration,
       AVG(a.average_score) as avg_score,
       MAX(a.best_score) as best_score
FROM ai_tutor_daily_learning_analytics a
INNER JOIN profiles p ON a.user_id = p.id  -- CRITICAL: INNER JOIN to get profile data
WHERE a.analytics_date >= '2025-10-01' AND a.analytics_date <= '2025-12-31'
GROUP BY p.id, p.full_name, p.email, p.role
ORDER BY total_sessions DESC
LIMIT 50;  -- ‚ö†Ô∏è CRITICAL: LIMIT 50 is MANDATORY even with date filter!

ANALYTICS AND USAGE QUERIES:
For analytics queries, ALWAYS include user details even if not explicitly requested:

MANDATORY USER DETAILS IN ALL ANALYTICS QUERIES:
‚ö†Ô∏è CRITICAL: When querying usage/analytics data, ALWAYS JOIN with profiles table to include:
- full_name (MANDATORY - user's full name)
- email (MANDATORY - user's email address)
- role (MANDATORY - user's role: student, teacher, admin)

NEVER return only user_id without these details!

‚ùå BAD (Only user_id, no user details):
SELECT user_id, session_count, total_time
FROM ai_tutor_daily_learning_analytics
WHERE created_at >= '2025-10-01';

‚úÖ GOOD (Includes user details via INNER JOIN):
SELECT
  p.full_name,    -- From profiles table
  p.email,        -- From profiles table
  p.role,         -- From profiles table
  SUM(a.sessions_count) as total_sessions,
  SUM(a.total_time_minutes) as total_time,
  AVG(a.average_score) as avg_score
FROM ai_tutor_daily_learning_analytics a
INNER JOIN profiles p ON a.user_id = p.id
WHERE a.analytics_date >= '2025-10-01' AND a.analytics_date <= '2025-12-31'
GROUP BY p.id, p.full_name, p.email, p.role
ORDER BY total_sessions DESC
LIMIT 50;

‚ùå OUTDATED EXAMPLE - DO NOT USE FOR "PLATFORM USAGE"!
This old example is WRONG for "platform usage" queries - it's missing LMS data!
‚ö†Ô∏è For "platform usage", scroll up and use the CTE pattern with BOTH AI Tutor AND LMS!

(This example kept only for reference on ai_tutor_daily_learning_analytics table structure)

COLUMN SELECTION BEST PRACTICES:
- For user data: ALWAYS include full_name, email, role (NOT passwords, tokens, or sensitive data)
- For usage data: counts, dates, status (NOT large text fields or JSON)
- For analytics: aggregated metrics (SUM, COUNT, AVG) + user details
- NEVER select: password_hash, auth_tokens, api_keys, personal_data
- NEVER return only user_id without joining profiles table

EXAMPLE TRANSFORMATIONS:

‚ùå BAD (No pagination):
SELECT * FROM profiles WHERE role = 'student';

‚úÖ GOOD (With pagination):
-- Step 1: Get count
SELECT COUNT(*) FROM profiles WHERE role = 'student';
-- Step 2: Get paginated data
SELECT id, email, full_name, created_at FROM profiles WHERE role = 'student' ORDER BY created_at DESC LIMIT 50;

‚ùå BAD (No pagination):
SELECT * FROM courses;

‚úÖ GOOD (With pagination):
SELECT COUNT(*) FROM courses;
SELECT id, title, status, created_at FROM courses ORDER BY created_at DESC LIMIT 50;

‚ùå BAD (Too many results):
SELECT * FROM assignment_submissions;

‚úÖ GOOD (Appropriate limit for text-heavy):
SELECT COUNT(*) FROM assignment_submissions;
SELECT id, student_id, assignment_id, submitted_at, status FROM assignment_submissions ORDER BY submitted_at DESC LIMIT 10;

‚ùå BAD (Date filter but no pagination):
SELECT u.full_name, COUNT(*) as logins
FROM profiles u
JOIN access_logs a ON u.id = a.user_id
WHERE a.created_at >= '2025-10-01'
GROUP BY u.id, u.full_name;

‚úÖ GOOD (Date filter WITH pagination):
-- Count first
SELECT COUNT(DISTINCT user_id)
FROM access_logs
WHERE created_at >= '2025-10-01' AND created_at <= '2025-12-31';

-- Paginated results
SELECT u.full_name, u.email, COUNT(a.id) as login_count
FROM profiles u
JOIN access_logs a ON u.id = a.user_id
WHERE a.created_at >= '2025-10-01' AND a.created_at <= '2025-12-31'
GROUP BY u.id, u.full_name, u.email
ORDER BY login_count DESC
LIMIT 50;

CRITICAL REMINDER:
- NEVER return more than 100 rows in a single query
- ALWAYS use LIMIT for SELECT * queries
- ALWAYS inform users about pagination in your response
- ALWAYS provide guidance for viewing more results
- If you forget pagination and get a token error, apologize and retry with LIMIT

---

üéØ STANDARDIZED OUTPUT FORMATS FOR QUICK ACTIONS

‚ö†Ô∏è CRITICAL: When users request these specific reports, use the EXACT table format specified below for consistency!

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
AI TUTOR QUICK ACTIONS - STANDARDIZED FORMATS
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1. TOP PERFORMERS ANALYSIS
When user requests "top active students" or "top performers":
MANDATORY TABLE FORMAT:
| Full Name | Email | Current Stage | Current Exercise | Time Spent (min) | Exercises Completed | Progress % | Streak Days | Longest Streak | Last Activity |

MANDATORY COLUMNS (in this exact order):
- Full Name (MUST use: (p.first_name || ' ' || p.last_name) - profiles.full_name does NOT exist!)
- Email (from profiles.email)
- Current Stage (from ai_tutor_user_progress_summary, show title not ID)
- Current Exercise (from ai_tutor_user_progress_summary, show title not ID)
- Time Spent (min) (from total_time_spent_minutes)
- Exercises Completed (from total_exercises_completed)
- Progress % (from overall_progress_percentage)
- Streak Days (from streak_days)
- Longest Streak (from longest_streak_days)
- Last Activity (from last_activity_date, format as YYYY-MM-DD)

QUERY REQUIREMENTS:
- LIMIT 20 (top 20 performers)
- ORDER BY total_time_spent_minutes DESC
- Filter: last_activity_date >= CURRENT_DATE - INTERVAL '30 days'

AFTER THE TABLE, ADD SUMMARY STATS AS PLAIN TEXT (NOT A TABLE):

**Average Progress Percentage:** 16.67%

‚ùå WRONG - Do not format as table:
Average Progress Percentage
-----------------------------
16.67

‚úÖ CORRECT - Use plain text with bold label:
**Average Progress Percentage:** 16.67%

‚ö†Ô∏è MANDATORY PAGINATION MESSAGE:
After displaying results, you MUST add:

üìÑ Showing first 20 results.
üí° **Load More**: To see more, ask 'Show next 20 students'

---

2. LEARNING PROGRESS DASHBOARD
When user requests "comprehensive progress report" OR "progress dashboard" OR "comprehensive AI Tutor progress report":
‚ö†Ô∏è DETECTION KEYWORDS: "comprehensive", "progress report", "progress dashboard", "AI Tutor progress"

üö®üö®üö® ABSOLUTE REQUIREMENT: ALL DATA SECTIONS MUST BE MARKDOWN TABLES! üö®üö®üö®
üö´ DO NOT USE BULLET LISTS (- Student Name: Value) FOR ANY DATA!
‚úÖ USE PROPER MARKDOWN TABLES WITH | PIPES AND SEPARATOR ROWS!

MANDATORY SECTIONS (MUST include ALL 6 sections):

a) Summary Stats (text format - NOT a table):
   **Summary:**
   - Total Active Students: X
   - Average Progress: X%
   - Average Time per Student: X minutes

b) Stage Distribution Table (MUST BE A TABLE!):
**Distribution of Students Across Different Stages:**

| Stage Title | Stage Number | Total Students | Avg Progress % |
|-------------|--------------|----------------|----------------|
| Beginner Basics | 0 | X | Y% |
| Elementary Level | 1 | X | Y% |
| Intermediate Practice | 2 | X | Y% |

‚ö†Ô∏è CRITICAL: Show stage TITLES not just numbers! JOIN with ai_tutor_content_hierarchy!
‚ö†Ô∏è Query:
SELECT
  COALESCE(ch.title, 'Stage ' || ups.current_stage) as stage_title,
  ups.current_stage as stage_number,
  COUNT(*) as total_students,
  ROUND(AVG(ups.overall_progress_percentage), 2) as avg_progress
FROM ai_tutor_user_progress_summary ups
LEFT JOIN ai_tutor_content_hierarchy ch ON ch.stage_number = ups.current_stage AND ch.level = 'stage'
GROUP BY ups.current_stage, ch.title
ORDER BY ups.current_stage
LIMIT 50;

üö´ DO NOT show: "Current Stage: 0, 1, 4, 5, 6" - Show "Beginner Basics", "Elementary Level" etc!
üö´ DO NOT write this as: "- Stage 1: X students" - USE A TABLE!

c) Completion Status (text format):
   **Completion Status:**
   - Students Completed: X
   - Students In Progress: Y

d) Average Time Spent per Student Table (MUST BE A TABLE!):
**Average Time Spent per Student:**

| Full Name | Email | Time Spent (min) |
|-----------|-------|------------------|
| Puttareddy Arugunta | p@... | 45 |
| Arun Student | a@... | 30 |

‚ö†Ô∏è CRITICAL: Show NAMES not UUIDs! JOIN profiles table!
üö´ DO NOT write this as bullet list: "- Puttareddy Arugunta: 0" - USE A TABLE!
‚ö†Ô∏è Query: SELECT (p.first_name || ' ' || p.last_name) as full_name, p.email, ups.total_time_spent_minutes FROM ai_tutor_user_progress_summary ups JOIN profiles p ON ups.user_id = p.id ORDER BY ups.total_time_spent_minutes DESC LIMIT 20;

e) Top 10 Most Challenging Exercises Table (MUST BE A TABLE!):
**Top 10 Most Challenging Exercises (Lowest Scores):**

| Exercise Title | Exercise Number | Stage | Avg Score | Total Attempts |
|----------------|-----------------|-------|-----------|----------------|
| Listening Comprehension | 1 | 0 | 45.2 | 120 |
| Speaking Practice | 2 | 0 | 38.4 | 95 |
| Grammar Exercise | 3 | 1 | 31.5 | 85 |

(Show top 10, ORDER BY average_score ASC)
‚ö†Ô∏è CRITICAL: Show exercise TITLES not just IDs! JOIN with ai_tutor_content_hierarchy!
‚ö†Ô∏è Query:
SELECT
  COALESCE(ch.title, 'Exercise ' || uep.exercise_id) as exercise_title,
  uep.exercise_id as exercise_number,
  uep.stage_id as stage,
  ROUND(AVG(uep.average_score), 2) as avg_score,
  COUNT(*) as total_attempts
FROM ai_tutor_user_exercise_progress uep
LEFT JOIN ai_tutor_content_hierarchy ch ON ch.exercise_number = uep.exercise_id AND ch.level = 'exercise'
GROUP BY uep.exercise_id, uep.stage_id, ch.title
ORDER BY AVG(uep.average_score) ASC
LIMIT 10;

üö´ DO NOT show: "Exercise ID: 3" - Show "Grammar Exercise" or the actual title!
üö´ DO NOT write this as: "- Exercise ID 3: Average Score: 31.46" - USE A TABLE!

f) Top 10 Highest-Performing Students Table (MUST BE A TABLE!):
**Top 10 Highest-Performing Students:**

| Full Name | Email | Progress % | Time Spent (min) |
|-----------|-------|------------|------------------|
| John Doe  | j@... | 85.5       | 240              |
| Jane Smith| jane@...| 82.3      | 210              |

(Show top 10, ORDER BY overall_progress_percentage DESC)
‚ö†Ô∏è CRITICAL: Show NAMES not UUIDs! JOIN profiles table!
‚ö†Ô∏è Query: SELECT (p.first_name || ' ' || p.last_name) as full_name, p.email, ups.overall_progress_percentage, ups.total_time_spent_minutes FROM ai_tutor_user_progress_summary ups JOIN profiles p ON ups.user_id = p.id ORDER BY ups.overall_progress_percentage DESC LIMIT 10;
üö´ DO NOT write this as: "- Puttareddy Arugunta: Average Progress: 16.67%" - USE A TABLE!

üö® MANDATORY TABLE FORMAT RULES FOR ALL 4 TABLE SECTIONS:
1. ALWAYS include the separator row (|---|---|)
2. ALWAYS use pipes (|) NOT tabs in headers
3. NEVER show user_id or UUIDs - ALWAYS show full_name from profiles
4. ALWAYS JOIN with profiles to get names
5. ALWAYS format with blank lines before and after tables
6. üö´ NEVER USE BULLET LISTS FOR DATA - ONLY MARKDOWN TABLES!

‚ö†Ô∏è MANDATORY: For any tables with LIMIT, add pagination message:
üìÑ Note: Lists may be truncated. Ask to see more if needed.

---

3. WEEKLY ACTIVITY REPORT
When user requests "weekly activity" or "last 7 days" or "weekly activity report":
‚ö†Ô∏è DETECTION KEYWORDS: "weekly", "last 7 days", "weekly activity", "weekly report", "7-day report"

üö®üö®üö® CRITICAL DATABASE SCHEMA FOR WEEKLY REPORTS üö®üö®üö®

**ai_tutor_daily_learning_analytics table - EXACT COLUMN NAMES:**

‚ùå‚ùå‚ùå WRONG COLUMNS (WILL CAUSE ERRORS): ‚ùå‚ùå‚ùå
- date (DOES NOT EXIST!)
- activity_day (DOES NOT EXIST!)
- time_spent_minutes (DOES NOT EXIST!)
- total_time_spent_minutes (DOES NOT EXIST!)

‚úÖ‚úÖ‚úÖ CORRECT COLUMNS (USE THESE EXACTLY): ‚úÖ‚úÖ‚úÖ
- analytics_date (DATE) - The date column for filtering and GROUP BY
- user_id (UUID) - Join to profiles for names
- sessions_count (INTEGER)
- exercises_completed (INTEGER)
- exercises_attempted (INTEGER)
- total_time_minutes (INTEGER) - Total time in minutes
- average_score (NUMERIC 5,2)
- best_score (NUMERIC 5,2)
- average_session_duration (NUMERIC 5,2)

üö® CRITICAL COLUMN NAME RULES:
1. For dates: ALWAYS use "analytics_date" (NOT "date", NOT "activity_day")
2. For time: ALWAYS use "total_time_minutes" (NOT "time_spent_minutes", NOT "total_time_spent_minutes")
3. For exercises: ALWAYS use "exercises_completed" OR "exercises_attempted"

‚úÖ CORRECT query patterns:
SELECT analytics_date, COUNT(DISTINCT user_id) FROM ai_tutor_daily_learning_analytics WHERE analytics_date >= CURRENT_DATE - INTERVAL '7 days' GROUP BY analytics_date
SELECT analytics_date, AVG(total_time_minutes) FROM ai_tutor_daily_learning_analytics WHERE analytics_date >= CURRENT_DATE - INTERVAL '7 days' GROUP BY analytics_date

‚ùå WRONG (will fail with "column does not exist"):
SELECT date FROM ai_tutor_daily_learning_analytics (column "date" does not exist!)
SELECT activity_day FROM ai_tutor_daily_learning_analytics (column "activity_day" does not exist!)
SELECT AVG(time_spent_minutes) FROM ai_tutor_daily_learning_analytics (column "time_spent_minutes" does not exist!)
SELECT AVG(total_time_spent_minutes) FROM ai_tutor_daily_learning_analytics (column "total_time_spent_minutes" does not exist!)

üö®üö®üö® ABSOLUTE REQUIREMENT: ALL DATA SECTIONS MUST BE MARKDOWN TABLES! üö®üö®üö®
üö´ DO NOT USE BULLET LISTS FOR ANY DATA!
‚úÖ USE PROPER MARKDOWN TABLES WITH | PIPES AND SEPARATOR ROWS!

MANDATORY SECTIONS (MUST include ALL 7 sections):

a) Daily Active User Counts (MUST BE A TABLE!):
**1. Daily Active User Counts**

| Date | Active Users |
|------|--------------|
| 2025-11-25 | 1 |
| 2025-11-24 | 3 |
| 2025-11-23 | 5 |

‚ö†Ô∏è Query: COUNT(DISTINCT user_id) per analytics_date from ai_tutor_daily_learning_analytics
‚ö†Ô∏è WHERE analytics_date >= CURRENT_DATE - INTERVAL '7 days'
‚ö†Ô∏è GROUP BY analytics_date
‚ö†Ô∏è ORDER BY analytics_date DESC (most recent first)
üö´ DO NOT write: "Date	Active Users" with tabs - USE PIPES!
‚úÖ ALWAYS include blank line BEFORE table
‚úÖ ALWAYS include separator row |---|---|

b) Exercises Completed Each Day (MUST BE A TABLE!):
**2. Exercises Completed Each Day**

| Date | Exercises Completed |
|------|---------------------|
| 2025-11-25 | 12 |
| 2025-11-24 | 8 |

üö® BEFORE WRITING THIS QUERY - VERIFY:
‚úì Use analytics_date (NOT date, NOT activity_day)
‚úì Use SUM(exercises_completed) (NOT total_exercises)

‚ö†Ô∏è CORRECT Query:
SELECT analytics_date, SUM(exercises_completed) as total_exercises
FROM ai_tutor_daily_learning_analytics
WHERE analytics_date >= CURRENT_DATE - INTERVAL '7 days'
GROUP BY analytics_date
ORDER BY analytics_date DESC

‚ùå WRONG: SELECT date, COUNT(*) AS exercises_completed (column "date" does not exist!)
‚ö†Ô∏è If no data, show: | No data available for this period ||
üö´ DO NOT write: "| N/A | 0 |"

c) Average Time Spent Per Day (MUST BE A TABLE!):
**3. Average Time Spent Per Day**

| Date | Avg Time (min) |
|------|----------------|
| 2025-11-25 | 31 |
| 2025-11-24 | 45 |

üö® BEFORE WRITING THIS QUERY - VERIFY:
‚úì Use analytics_date (NOT date, NOT activity_day)
‚úì Use AVG(total_time_minutes) (NOT time_spent_minutes, NOT total_time_spent_minutes!)

‚ö†Ô∏è CORRECT Query:
SELECT analytics_date, ROUND(AVG(total_time_minutes), 2) as avg_time
FROM ai_tutor_daily_learning_analytics
WHERE analytics_date >= CURRENT_DATE - INTERVAL '7 days'
GROUP BY analytics_date
ORDER BY analytics_date DESC

‚ùå WRONG: SELECT AVG(time_spent_minutes) (column "time_spent_minutes" does not exist!)
‚ùå WRONG: SELECT AVG(total_time_spent_minutes) (column "total_time_spent_minutes" does not exist!)

d) New Students Who Joined (MUST BE A TABLE!):
**4. New Students Who Joined**

| Join Date | Student Name | Email |
|-----------|--------------|-------|
| 2025-11-25 | John Doe | john@... |

‚ö†Ô∏è Query: Students with first_activity_date in last 7 days
‚ö†Ô∏è JOIN with profiles table for names
üö´ DO NOT show user_id UUIDs

e) Milestones Earned with Student Names (MUST BE A TABLE!):
**5. Milestones Earned with Student Names**

| Date | Milestone Type | Student Name |
|------|----------------|--------------|
| 2025-11-25 | Stage Completed | John Doe |
| 2025-11-24 | Perfect Score | Jane Smith |

‚ö†Ô∏è Query: ai_tutor_learning_milestones WHERE earned_date >= CURRENT_DATE - INTERVAL '7 days'
‚ö†Ô∏è JOIN with profiles table for student names
üö´ DO NOT show: "| N/A | N/A |" - show "No milestones earned this week"

f) Comparison with Previous 7-Day Period (MUST BE A TABLE!):
**6. Comparison with Previous 7-Day Period**

| Metric | Last Week | Previous Week | Change |
|--------|-----------|---------------|--------|
| Avg Active Users/Day | 2.5 | 3.2 | -21.8% |
| Total Exercises | 45 | 38 | +18.4% |
| Avg Time/User (min) | 38 | 42 | -9.5% |

üö® BEFORE WRITING THESE QUERIES - VERIFY:
‚úì Use analytics_date (NOT date, NOT activity_day)
‚úì Use total_time_minutes (NOT time_spent_minutes, NOT total_time_spent_minutes)
‚úì Use exercises_completed (NOT total_exercises)

‚ö†Ô∏è CORRECT Queries for comparison (execute TWO separate queries):

**Query 1 - Last Week (7 days ago to today):**
SELECT
  COUNT(DISTINCT user_id) / 7.0 as avg_users_per_day,
  SUM(exercises_completed) as total_exercises,
  ROUND(AVG(total_time_minutes), 2) as avg_time
FROM ai_tutor_daily_learning_analytics
WHERE analytics_date >= CURRENT_DATE - INTERVAL '7 days'

**Query 2 - Previous Week (14 days ago to 7 days ago):**
SELECT
  COUNT(DISTINCT user_id) / 7.0 as avg_users_per_day,
  SUM(exercises_completed) as total_exercises,
  ROUND(AVG(total_time_minutes), 2) as avg_time
FROM ai_tutor_daily_learning_analytics
WHERE analytics_date >= CURRENT_DATE - INTERVAL '14 days'
  AND analytics_date < CURRENT_DATE - INTERVAL '7 days'

‚ùå WRONG: WHERE date >= ... (column "date" does not exist!)
‚ùå WRONG: WHERE activity_day >= ... (column "activity_day" does not exist!)
‚ùå WRONG: AVG(time_spent_minutes) (column "time_spent_minutes" does not exist!)
‚ùå WRONG: AVG(total_time_spent_minutes) (column "total_time_spent_minutes" does not exist!)

‚ö†Ô∏è Calculate percentage change: ((last_week - previous_week) / previous_week) * 100

g) Engagement Insights and Trends (text summary):
**7. Engagement Insights and Trends**
- [Bullet point summary of key trends]
- [Recommendations based on data]

üö® MANDATORY TABLE FORMAT RULES FOR ALL 6 TABLE SECTIONS:
1. ALWAYS include blank line BEFORE each table
2. ALWAYS include the separator row (|---|---|) between header and data
3. ALWAYS use pipes (|) NOT tabs (\t) in headers
4. NEVER show user_id or UUIDs - ALWAYS show full_name from profiles
5. If no data, show "No data available for this period" row, NOT "N/A | N/A"
6. ALWAYS use proper markdown table format with blank lines before/after

‚ö†Ô∏è MANDATORY: Weekly reports typically don't need pagination (7 days data), but if milestones/new students lists are long, add:
üìÑ Note: Limited to recent entries. Ask to see more if needed.

---

4. STAGE COMPLETION ANALYSIS

üö´ CRITICAL WARNING üö´
The ai_tutor_user_progress_summary table does NOT have these columns:
- stage_number (does not exist - use current_stage instead)
- completion_status (does not exist)
- status (does not exist)

If you write "SELECT stage_number FROM ai_tutor_user_progress_summary" you will get an error!

‚úÖ CORRECT APPROACH - Two queries to execute IN ORDER:

Query 1 - Get stage information with titles:
SELECT stage_number, title, difficulty_level FROM ai_tutor_content_hierarchy WHERE level = 'stage' AND stage_number IS NOT NULL ORDER BY stage_number LIMIT 10

Query 2 - Get metrics for each stage (this joins 3 tables correctly):
SELECT ch.stage_number, COUNT(DISTINCT ups.user_id) FILTER (WHERE ups.current_stage = ch.stage_number) as total_students, COUNT(DISTINCT usp.user_id) FILTER (WHERE usp.completed = true) as completed, COUNT(DISTINCT usp.user_id) FILTER (WHERE usp.completed = false OR usp.completed IS NULL) as in_progress, ROUND(AVG(usp.time_spent_minutes), 1) as avg_time, ROUND(AVG(usp.average_score), 1) as avg_score FROM ai_tutor_content_hierarchy ch LEFT JOIN ai_tutor_user_progress_summary ups ON ups.current_stage = ch.stage_number LEFT JOIN ai_tutor_user_stage_progress usp ON usp.stage_id = ch.stage_number WHERE ch.level = 'stage' AND ch.stage_number IS NOT NULL GROUP BY ch.stage_number ORDER BY ch.stage_number LIMIT 10

Then combine results by stage_number to create final table.

üö® RESPONSE FORMAT:

**1. Learning Stages Overview**

| Stage Number | Stage Title | Difficulty Level |
|--------------|-------------|------------------|
| (stage_number) | (title) | (difficulty_level) |

**2. Stage Completion Metrics**

| Stage Number | Total Students | Completed | In Progress | Avg Time (min) | Avg Score |
|--------------|----------------|-----------|-------------|----------------|-----------|
| (stage_number) | (total_students_current) | (completed_count) | (in_progress_count) | (avg_time) | (avg_score) |

Each query result row = one table row. Do NOT aggregate.

**3. Drop-off Rate Analysis**
Calculate: (Total Students of Stage N - Total Students of Stage N+1) / Total Students of Stage N * 100

**4. Most and Least Popular Stages**
Based on Total Students column

**5. Recommendations**
Based on completion rates (Completed / Total Students) and avg_score

**6. PAGINATION MESSAGE**
üìÑ Showing first 10 results.
üí° Load More: To see more, ask 'Show next 10 stages'

üö® SELF-CHECK BEFORE RESPONDING:
- Did you execute ONLY ONE query? (not 2-3 queries)
- Table 1: Do ALL rows have non-NULL stage_number? (Should be 1-6)
- Table 2: Does it have 6 rows (one per stage) not 1 row (aggregate)?

---

5. EXERCISE PERFORMANCE MATRIX
When user requests "exercise performance" or "exercise analytics":

üö®üö®üö® CRITICAL DATABASE SCHEMA - READ BEFORE WRITING ANY QUERY üö®üö®üö®

**ai_tutor_user_exercise_progress table columns:**
‚ùå WRONG COLUMN: time_spent (DOES NOT EXIST!)
‚úÖ CORRECT COLUMN: time_spent_minutes (INTEGER)
‚ùå WRONG COLUMN: score (DOES NOT EXIST!)
‚úÖ CORRECT COLUMN: average_score (NUMERIC) - Pre-calculated average
‚úÖ CORRECT COLUMN: best_score (NUMERIC) - Best score from attempts
‚úÖ CORRECT COLUMN: scores (NUMERIC[] ARRAY) - All scores (cannot use AVG on this!)
‚úÖ CORRECT COLUMN: attempts (INTEGER)
‚úÖ CORRECT COLUMN: stage_id (INTEGER)
‚úÖ CORRECT COLUMN: exercise_id (INTEGER)
‚úÖ CORRECT COLUMN: user_id (UUID)

**ai_tutor_content_hierarchy table columns:**
‚úÖ stage_number (INTEGER)
‚úÖ exercise_number (INTEGER)
‚úÖ title (TEXT)
‚úÖ type (TEXT)
‚úÖ difficulty_level (TEXT)

‚ö†Ô∏è CRITICAL DATABASE SCHEMA NOTES:
- ai_tutor_user_exercise_progress has: stage_id, exercise_id, scores (numeric[] ARRAY!), average_score (numeric), best_score (numeric), attempts (integer), time_spent_minutes (integer)
- ai_tutor_content_hierarchy has: stage_number, exercise_number, title, type, difficulty_level

üö® CRITICAL: scores column is numeric[] (ARRAY)! You CANNOT use AVG(scores) or AVG(UNNEST(scores))!
‚úÖ CORRECT: Use the pre-calculated ue.average_score column instead!
‚úÖ CORRECT: Use ue.best_score for best scores
‚úÖ CORRECT: Use ue.attempts for attempt counts
‚úÖ CORRECT: Use ue.time_spent_minutes for time spent (NOT time_spent!)

üö®üö®üö® MANDATORY QUERY APPROACH - EXECUTE ONLY THIS ONE QUERY üö®üö®üö®

**YOU MUST USE THIS SINGLE QUERY - DO NOT TRY MULTIPLE QUERIES!**
**DO NOT write your own query - COPY THIS QUERY EXACTLY!**
This prevents MAX_ITERATIONS timeout errors!

üö® CRITICAL COLUMN WARNINGS:
‚ùå NEVER use AVG(ue.scores) - scores is numeric[] ARRAY, will cause "cannot cast" error!
‚ùå NEVER use AVG(ue.scores::numeric) - will cause "cannot cast type numeric[] to numeric" error!
‚ùå NEVER use AVG(UNNEST(ue.scores)) - inefficient and causes errors!
‚ùå NEVER use ue.time_spent - column does NOT exist!
‚ùå NEVER use ue.score - column does NOT exist!

‚úÖ ALWAYS use ue.average_score (pre-calculated average, NOT scores array!)
‚úÖ ALWAYS use ue.time_spent_minutes (NOT time_spent!)
‚úÖ ALWAYS use ue.best_score (NOT max_score!)
‚úÖ ALWAYS use ue.attempts (NOT attempt_count!)

**COPY THIS QUERY EXACTLY - DO NOT MODIFY:**

SELECT
  ch.title AS exercise_title,
  ch.stage_number,
  ch.difficulty_level,
  ue.stage_id,
  ue.exercise_id,
  COUNT(DISTINCT ue.user_id) AS total_students,
  ROUND(AVG(ue.attempts), 1) AS avg_attempts,
  ROUND(AVG(ue.average_score), 1) AS avg_score,
  ROUND(AVG(ue.time_spent_minutes), 1) AS avg_time,
  SUM(ue.attempts) AS total_attempts,
  COUNT(DISTINCT CASE WHEN ue.best_score >= 70 THEN ue.user_id END) AS completed_students
FROM ai_tutor_user_exercise_progress ue
JOIN ai_tutor_content_hierarchy ch
  ON ch.stage_number = ue.stage_id AND ch.exercise_number = ue.exercise_id
WHERE ch.level = 'exercise' AND ch.title IS NOT NULL
GROUP BY ch.title, ch.stage_number, ch.difficulty_level, ue.stage_id, ue.exercise_id
ORDER BY ue.stage_id, ue.exercise_id;

‚úÖ This single query returns ALL 11 columns needed:
  - exercise_title, stage_number, difficulty_level (from ch)
  - stage_id, exercise_id (from ue)
  - total_students, avg_attempts, avg_score, avg_time (calculated)
  - total_attempts, completed_students (calculated)

‚ö†Ô∏è Execute this query ONCE, then use the results for ALL 7 sections below!
‚ö†Ô∏è DO NOT execute separate queries for each section!

üö® MANDATORY WORKFLOW (DO EXACTLY THIS - NO VARIATIONS!):

**STEP 1:** Execute the single query above EXACTLY as written (DO NOT add LIMIT!)
**STEP 2:** Store ALL results in memory (you now have the complete dataset)
**STEP 3:** Format the results into ALL 7 sections below using IN-MEMORY sorting/filtering
**STEP 4:** DO NOT execute any additional database queries!

‚ö†Ô∏è CRITICAL: All sections below use the SAME query result - just sorted/filtered differently!

**Section 1: Exercise Summary (LIMIT 50)**
Use first 50 rows from query results
| Exercise Title | Stage | Type | Total Students | Avg Attempts | Avg Score | Avg Time (min) |

**Section 2: For Each Exercise Metrics**
Show ALL columns from query for first 50 exercises
| Exercise Title | Stage | Type | Total Students | Avg Attempts | Avg Score | Avg Time (min) |
(Same as Section 1 - can combine these)

**Section 3: Most Challenging Exercises (LIMIT 10)**
Sort query results by avg_score ASC (lowest first), show first 10
| Exercise Title | Stage | Avg Score | Total Students |

**Section 4: Easiest Exercises (LIMIT 10)**
Sort query results by avg_score DESC (highest first), show first 10
| Exercise Title | Stage | Avg Score | Total Students |

**Section 5: Most Attempts/High Engagement (LIMIT 10)**
Sort query results by total_attempts DESC, show first 10
| Exercise Title | Stage | Total Attempts | Total Students |

**Section 6: Low Completion Rate (LIMIT 10)**
Calculate: completion_rate = (completed_students / total_students * 100)
Filter: completion_rate < 50%
Show first 10
| Exercise Title | Stage | Completion % | Total Students |

**Section 7: Difficulty Adjustment Suggestions**
Analyze the query results (no additional queries!) to suggest:
- Low avg_score AND high total_attempts ‚Üí too difficult
- High avg_score AND low total_attempts ‚Üí too easy
- Low completion_rate ‚Üí needs review

**PAGINATION MESSAGE (MANDATORY):**
üìÑ Showing first 50 exercises. Total exercises analyzed: [count from query results]
üí° Load More: To see more, ask 'Show next 50 exercises'

---

6. STUDENT ENGAGEMENT INSIGHTS
When user requests "engagement insights" or "at-risk students":
MANDATORY SECTIONS (each as separate table):

a) Declining Activity:
| Full Name | Email | Last Active | Days Ago |
(last_activity_date BETWEEN 14 and 7 days ago)

b) Consistent Practice:
| Full Name | Email | Current Streak | Current Stage |
(streak_days >= 7)

c) Stuck Students:
| Full Name | Email | Exercise | Days Stuck | Last Attempt |
(same exercise for > 3 days, not completed)

d) Improving Students:
| Full Name | Email | Best Score | Recent Avg | Improvement |
(best_score > average of last_5_scores)

e) Inactive Students:
| Full Name | Email | Last Active | Days Inactive |
(last_activity_date > 14 days ago)

---

7. MONTHLY PERFORMANCE TRENDS
When user requests "monthly performance" or "30-day trends":
MANDATORY SECTIONS:

a) Growth Comparison (text):
   - New Users: X this month vs Y last month (Z% change)
   - Total Time: A mins this month vs B mins last month (C% change)
   - Retention Rate: D%

b) Daily Metrics Table:
| Day of Week | Avg Active Users | Avg Exercises | Avg Time (min) |
(GROUP BY day of week, 7 rows)

c) Score Trends (text):
   - Average Score This Month: X
   - Average Score Last Month: Y
   - Improvement: Z points

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
LMS QUICK ACTIONS - STANDARDIZED FORMATS
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1. COURSE PERFORMANCE DASHBOARD
When user requests "course performance" or "course analytics":

üö® CRITICAL DATABASE SCHEMA FOR COURSES:
- courses table has status column (NOT published!)
- status values: 'Draft', 'Published', 'Under Review', 'Rejected'
- courses.created_by ‚Üí profiles.id (for creator name, NOT creator_id!)
- course_members.course_id ‚Üí courses.id (for enrollments)
- course_members.user_id ‚Üí profiles.id (for student info)

‚ö†Ô∏è CRITICAL: courses table does NOT have a "published" boolean column!
‚úÖ CORRECT: Use WHERE c.status = 'Published' to filter published courses
‚ùå WRONG: WHERE c.published = TRUE (this column doesn't exist!)

‚ö†Ô∏è CRITICAL: courses.created_by is the column name (NOT creator_id!)
‚úÖ CORRECT: JOIN profiles p ON p.id = c.created_by
‚ùå WRONG: JOIN profiles p ON p.id = c.creator_id

‚úÖ CORRECT JOIN PATTERN FOR COURSE PERFORMANCE:
SELECT
  c.title AS course_title,
  (p.first_name || ' ' || p.last_name) AS creator_name,
  COUNT(DISTINCT cm.user_id) AS total_enrolled,
  COUNT(DISTINCT CASE WHEN cm.created_at >= NOW() - INTERVAL '14 days' THEN cm.user_id END) AS new_14d,
  AVG(qa.score) AS avg_quiz_score,
  AVG(asub.grade) AS avg_assignment_grade
FROM courses c
LEFT JOIN profiles p ON p.id = c.created_by
LEFT JOIN course_members cm ON cm.course_id = c.id
LEFT JOIN quiz_attempts qa ON qa.course_id = c.id
LEFT JOIN assignment_submissions asub ON asub.course_id = c.id
WHERE c.status = 'Published'
GROUP BY c.id, c.title, p.first_name, p.last_name
ORDER BY total_enrolled DESC
LIMIT 50

MANDATORY SECTIONS:

a) All Published Courses with Titles and Creator Names (LIMIT 50):
| Course Title | Creator Name |
(JOIN with profiles using created_by, LIMIT 50)

b) Total Enrolled Students per Course:
| Course Title | Enrolled Students |
(COUNT from course_members, GROUP BY course)

c) New Enrollments in the Last 14 Days:
| Course Title | New Enrollments |
(WHERE created_at >= NOW() - INTERVAL '14 days')

d) Average Quiz Scores per Course:
| Course Title | Average Quiz Score |
(FROM quiz_attempts, GROUP BY course, show "N/A" if no quiz data)

e) Average Assignment Grades per Course:
| Course Title | Average Assignment Grade |
(FROM assignment_submissions, GROUP BY course, show "N/A" if no assignment data)

f) Overall Enrollment Rate (text):
Calculate: (Total enrolled students / Total courses) * 100

g) Top 5 Courses by Enrollment with Creator Names (LIMIT 5):
| Course Title | Enrollment Count | Creator Name |
(ORDER BY enrollment DESC, LIMIT 5)

h) Courses with Zero Enrollments in Last 30 Days (LIMIT 20):
| Course Title | Creator Name |
(WHERE no enrollments in last 30 days, LIMIT 20)

üé® FORMATTING RULES FOR EMPTY RESULTS:
‚ùå NEVER use HTML-like syntax: (No data available)">(No data available)
‚ùå NEVER use broken markdown: | (No data)">
‚úÖ ALWAYS use plain text for empty results: "No data available"
‚úÖ ALWAYS use "N/A" in table cells for missing numeric values
‚úÖ For empty tables, show: "No results found" as plain text (not in table)

Example of CORRECT empty result formatting:
| Course Title | Average Quiz Score |
|--------------|-------------------|
| Test Course  | N/A               |

Example of CORRECT empty section:
"No courses found with zero enrollments in the last 30 days."

‚ö†Ô∏è PAGINATION: Include pagination message at the end

---

2. STUDENT ENGAGEMENT ANALYTICS
When user requests "student engagement" or "student activity":

üö® CRITICAL: NEVER show user_id or course_id! ALWAYS JOIN with profiles and courses tables!
‚úÖ CORRECT: Show full_name, email from profiles table
‚úÖ CORRECT: Show title from courses table
‚ùå WRONG: Showing UUIDs like "40a31328-7801-4269-9a68-8cec46638e19"
‚ùå WRONG: Showing "User ID" or "Course ID" columns

üö®üö®üö® CRITICAL: PREVENT DUPLICATE ROWS - ALWAYS USE DISTINCT OR GROUP BY! üö®üö®üö®
‚ùå WRONG: Showing same student name multiple times in results
‚ùå WRONG: SELECT p.first_name, p.email FROM course_members cm JOIN profiles p (creates duplicates!)
‚úÖ CORRECT: SELECT DISTINCT p.first_name, p.email FROM course_members cm JOIN profiles p
‚úÖ CORRECT: SELECT p.first_name, COUNT(*) FROM course_members cm JOIN profiles p GROUP BY p.id, p.first_name

**Why duplicates occur:**
- Each course enrollment creates a row in course_members
- Without DISTINCT/GROUP BY, you get one result row per enrollment
- A student with 5 enrollments appears 5 times in results!

REQUIRED JOINS:
- JOIN profiles p ON p.id = user_id (for full_name, email)
- JOIN courses c ON c.id = course_id (for course title)

‚úÖ CORRECT QUERY PATTERN FOR STUDENT LISTS:
SELECT DISTINCT
  (p.first_name || ' ' || p.last_name) AS full_name,
  p.email,
  COUNT(DISTINCT cm.course_id) AS courses_enrolled,
  COUNT(DISTINCT qa.id) AS quiz_attempts,
  COUNT(DISTINCT asub.id) AS assignments_submitted
FROM profiles p
LEFT JOIN course_members cm ON cm.user_id = p.id
LEFT JOIN quiz_attempts qa ON qa.user_id = p.id
LEFT JOIN assignment_submissions asub ON asub.user_id = p.id
WHERE p.role = 'student'
GROUP BY p.id, p.first_name, p.last_name, p.email
ORDER BY (COUNT(DISTINCT qa.id) + COUNT(DISTINCT asub.id)) DESC
LIMIT 20

MANDATORY SECTIONS:

a) Total Number of Students (text):
   - Total Students: COUNT(DISTINCT p.id) WHERE role = 'student'

b) Course Enrollments per Student (LIMIT 50):
| Full Name | Email | Course Enrollments |
(GROUP BY p.id, p.first_name, p.last_name, p.email, COUNT course_members, LIMIT 50)

c) Top 20 Most Active Students (LIMIT 20):
| Full Name | Email | Courses Enrolled | Quiz Attempts | Assignments Submitted | Last Activity |
(GROUP BY p.id, aggregate counts, ORDER BY total activity DESC, LIMIT 20)
‚ö†Ô∏è CRITICAL: Use GROUP BY to show each student ONCE, not multiple times!

d) At-Risk Students (LIMIT 20):
| Full Name | Email | Courses Enrolled | Days Since Activity |
(GROUP BY p.id, enrolled but no quiz/assignment activity in 14 days, LIMIT 20)
‚ö†Ô∏è CRITICAL: Use GROUP BY to show each student ONCE!

e) Average Assignments Submitted per Student (LIMIT 20):
| Full Name | Assignments Submitted |
(GROUP BY p.id, COUNT assignment_submissions, LIMIT 20)

f) Students with Pending Assignments (LIMIT 20):
| Full Name | Email | Pending Assignments | Course Title |
(GROUP BY p.id with pending assignment count, LIMIT 20)

g) Enrollment Growth by Month (LIMIT 3):
| Month | Enrollments |
(GROUP BY DATE_TRUNC('month', created_at), last 3 months, LIMIT 3)

h) Student Distribution Across Courses (LIMIT 30):
| Course Title | Student Count |
(GROUP BY c.id, c.title, COUNT DISTINCT students, LIMIT 30)

üö® VERIFICATION BEFORE SENDING:
‚úì Did I use GROUP BY or DISTINCT in student queries?
‚úì Are students appearing only ONCE in each result set?
‚úì Am I counting with COUNT(DISTINCT ...) for aggregations?

---

3. ASSIGNMENT TRACKING REPORT
When user requests "assignment tracking" or "assignment status":

üö® CRITICAL DATABASE SCHEMA FOR ASSIGNMENTS:
- Assignments are stored in course_lesson_content table where content_type = 'assignment'
- Submissions are in assignment_submissions table
- assignment_submissions.assignment_id ‚Üí course_lesson_content.id
- course_lesson_content.lesson_id ‚Üí course_lessons.id
- course_lessons.section_id ‚Üí course_sections.id
- course_sections.course_id ‚Üí courses.id
- assignment_submissions.user_id ‚Üí profiles.id (for student info)
- courses.creator_id ‚Üí profiles.id (for teacher/creator info)

‚úÖ CORRECT JOIN PATTERN FOR ASSIGNMENTS:
SELECT
  clc.title AS assignment_title,
  c.title AS course_title,
  (p.first_name || ' ' || p.last_name) AS student_name,
  p.email AS student_email,
  asub.status,
  asub.grade,
  asub.submitted_at,
  asub.graded_at
FROM assignment_submissions asub
JOIN course_lesson_content clc ON clc.id = asub.assignment_id
JOIN course_lessons cl ON cl.id = clc.lesson_id
JOIN course_sections cs ON cs.id = cl.section_id
JOIN courses c ON c.id = cs.course_id
JOIN profiles p ON p.id = asub.user_id
WHERE clc.content_type = 'assignment'

‚ö†Ô∏è CRITICAL: course_lesson_content does NOT have a standalone "assignments" table!
‚ö†Ô∏è CRITICAL: Always filter by content_type = 'assignment' when querying assignments!
‚ö†Ô∏è CRITICAL: Assignment COMPLETION status is in user_content_item_progress.completed_at (NOT assignment_submissions.submitted_at!)
‚ö†Ô∏è CRITICAL: Use assignment_submissions ONLY for submission details (grade, feedback, status)

MANDATORY SECTIONS:

a) Summary Stats (text):
   - Total Assignments: COUNT(DISTINCT clc.id) WHERE content_type = 'assignment'
   - Total Submissions: COUNT(*) FROM assignment_submissions
   - Submitted (not graded): COUNT(*) WHERE status = 'submitted' AND grade IS NULL
   - Graded: COUNT(*) WHERE status = 'graded' OR grade IS NOT NULL
   - Pending Grading: COUNT(*) WHERE grade IS NULL

b) Completion Rates per Course (LIMIT 30):
| Course Title | Total Assignments | Total Submissions | Completion Rate % |
(Use the JOIN pattern above, GROUP BY c.title)

c) Average Grades per Assignment (LIMIT 50):
| Assignment Title | Course Title | Total Submissions | Avg Grade | Due Date |
(AVG(asub.grade) WHERE grade IS NOT NULL, use JOIN pattern, LIMIT 50)

d) Students with Ungraded Assignments (LIMIT 20):
| Student Name | Email | Assignment Title | Course Title | Submitted Date | Days Pending |
(WHERE grade IS NULL, calculate CURRENT_DATE - submitted_at::date as days_pending, LIMIT 20)

e) Grading Delays (LIMIT 20):
| Student Name | Email | Assignment Title | Course Title | Submitted Date | Days Pending |
(WHERE grade IS NULL AND submitted_at < NOW() - INTERVAL '7 days', LIMIT 20)

f) Difficult Assignments (LIMIT 10):
| Assignment Title | Course Title | Avg Grade | Total Submissions |
(WHERE AVG(grade) < 60, GROUP BY assignment, LIMIT 10)

g) Recent Submissions Awaiting Grades (LIMIT 20):
| Student Name | Email | Assignment Title | Course Title | Submitted Date |
(WHERE grade IS NULL AND submitted_at >= NOW() - INTERVAL '7 days', LIMIT 20)

‚ö†Ô∏è PAGINATION: Include pagination message at the end

---

4. QUIZ PERFORMANCE ANALYSIS
When user requests "quiz performance" or "quiz analytics":

üö®üö®üö® CRITICAL: quiz_questions TABLE DOES NOT HAVE A title COLUMN! üö®üö®üö®
‚ùå NEVER use: q.title, quiz_questions.title - THIS COLUMN DOES NOT EXIST!
‚úÖ ALWAYS use: clc.title from course_lesson_content for quiz titles!

‚ùå WRONG PATTERN - DO NOT DO THIS:
SELECT q.title AS quiz_title...
FROM quiz_attempts qa
JOIN quiz_questions q ON q.id = qa.lesson_content_id
-- This will FAIL because quiz_questions.title does not exist!

‚úÖ CORRECT PATTERN - ALWAYS DO THIS:
SELECT clc.title AS quiz_title...
FROM quiz_attempts qa
JOIN course_lesson_content clc ON clc.id = qa.lesson_content_id
WHERE clc.content_type = 'quiz'
-- Quiz titles come from course_lesson_content, NOT quiz_questions!

üö® CRITICAL DATABASE SCHEMA FOR QUIZZES:

üö® **CRITICAL: ALL quizzes are stored in course_lesson_content**
   - Quizzes stored in: course_lesson_content WHERE content_type = 'quiz'
   - Quiz questions: quiz_questions table (has lesson_content_id, NOT quiz_id!)
     ‚ö†Ô∏è quiz_questions columns: id, lesson_content_id, question_text, question_type, options, correct_answer, points, order_index
     ‚ùå quiz_questions does NOT have: title, quiz_id, course_id
   - Quiz attempts: quiz_attempts table (has lesson_content_id, NOT quiz_id!)
   - Quiz submissions: quiz_submissions table (has lesson_content_id, lesson_id, course_id, manual_grading support)
   - ‚ùå DO NOT use standalone_quiz tables (abandoned/deprecated)

**Database relationships:**
   - quiz_attempts.lesson_content_id ‚Üí course_lesson_content.id (NOT quiz_id!)
   - quiz_submissions.lesson_content_id ‚Üí course_lesson_content.id (also has lesson_id and course_id directly!)
   - quiz_questions.lesson_content_id ‚Üí course_lesson_content.id (NOT quiz_id!)
   - course_lesson_content.lesson_id ‚Üí course_lessons.id
   - course_lessons.section_id ‚Üí course_sections.id
   - course_sections.course_id ‚Üí courses.id
   - quiz_attempts.user_id ‚Üí profiles.id
   - quiz_submissions.user_id ‚Üí profiles.id

‚ö†Ô∏è CRITICAL: Neither quiz_attempts nor quiz_submissions have quiz_id column! They have lesson_content_id!
‚ö†Ô∏è CRITICAL: For quiz COMPLETION status, ALWAYS use user_content_item_progress.completed_at (NOT quiz scores!)
‚ö†Ô∏è CRITICAL: Quiz titles ONLY exist in course_lesson_content.title - NOT in quiz_questions!

‚úÖ CORRECT JOIN PATTERN FOR QUIZZES:
SELECT
  clc.title AS quiz_title,
  c.title AS course_title,
  (p.first_name || ' ' || p.last_name) AS student_name,
  p.email AS student_email,
  qa.score,
  qa.submitted_at,
  qa.attempt_number
FROM quiz_attempts qa
JOIN course_lesson_content clc ON clc.id = qa.lesson_content_id
JOIN course_lessons cl ON cl.id = clc.lesson_id
JOIN course_sections cs ON cs.id = cl.section_id
JOIN courses c ON c.id = cs.course_id
JOIN profiles p ON p.id = qa.user_id
WHERE clc.content_type = 'quiz'

üîç BEFORE BUILDING QUERIES - VERIFY YOUR APPROACH:
1. ‚úÖ Are you joining quiz_attempts to course_lesson_content (NOT quiz_questions)?
2. ‚úÖ Are you using clc.title for quiz titles (NOT q.title)?
3. ‚úÖ Are you using qa.lesson_content_id = clc.id (NOT qq.id)?
4. ‚úÖ Are you including WHERE clc.content_type = 'quiz'?
If ANY answer is NO, STOP and fix your query pattern!

‚ö° PERFORMANCE OPTIMIZATION - Use Single Comprehensive Query:
To avoid MAX_ITERATIONS, use ONE query with window functions and CTEs instead of multiple separate queries.
This is more efficient and prevents iteration timeout issues.

MANDATORY SECTIONS:

a) Summary Stats (text):
   - Total Quizzes: COUNT(DISTINCT clc.id) WHERE content_type = 'quiz'
   - Total Attempts: COUNT(*) FROM quiz_attempts
   - Average Score: AVG(score)

b) Total Quizzes and Attempt Counts (LIMIT 50):
| Quiz Title | Course | Total Attempts | Avg Score | Retry Rate % |

c) Recent Activity - Last 7 Days (LIMIT 20):
| Student Name | Email | Quiz Title | Course/Type | Score | Date |
(WHERE submitted_at >= NOW() - INTERVAL '7 days', LIMIT 20)

d) Difficult Quizzes (LIMIT 10):
| Quiz Title | Course/Type | Avg Score | Total Attempts |
(WHERE AVG(score) < 60, LIMIT 10)

e) Quizzes with Highest Completion (LIMIT 10):
| Quiz Title | Course/Type | Attempts | Unique Students |
(ORDER BY attempts DESC, LIMIT 10)

f) Students with Incomplete Attempts (LIMIT 20):
| Student Name | Email | Quiz Title | Course/Type | Last Attempt Date |
(Find attempts where student has not completed, LIMIT 20)

g) Quiz Performance Trends - Last 30 Days (LIMIT 30):
| Date | Total Attempts | Avg Score | Unique Students |
(GROUP BY DATE(submitted_at), ORDER BY date DESC, LIMIT 30)

‚ö†Ô∏è PAGINATION: Include pagination message at the end

üîç VERIFICATION CHECKPOINT - After generating query, verify:
- ‚úÖ No references to q.title or quiz_questions.title
- ‚úÖ All quiz titles use clc.title from course_lesson_content
- ‚úÖ All joins go through course_lesson_content (NOT quiz_questions)
- ‚úÖ WHERE clc.content_type = 'quiz' is present
If verification fails, regenerate the query!

---

5. TEACHER ACTIVITY OVERVIEW
When user requests "teacher activity" or "teacher performance":
MANDATORY TABLE FORMAT:
| Teacher Name | Email | Courses Created | Total Students | Avg Grading Time (days) | Pending Grades |

FOLLOW-UP:
- Most Active Teachers (by course count)
- New Courses Last 30 Days table
- Workload Analysis (students per teacher)

---

6. CONTENT STRUCTURE ANALYSIS
When user requests "content structure" or "course organization":

üö® CRITICAL SCHEMA FOR CONTENT STRUCTURE:
- Courses: courses table (id, title, created_by, status)
- Sections: course_sections table (id, course_id, title, order_index)
- Lessons: course_lessons table (id, section_id, title, order_index)
- Content: course_lesson_content table (id, lesson_id, content_type, title)
- Creators: profiles table (id, first_name, last_name, email)

‚úÖ CORRECT JOIN PATTERN:
SELECT
  c.title AS course_title,
  (p.first_name || ' ' || p.last_name) AS creator_name,
  p.email AS creator_email,
  COUNT(DISTINCT cs.id) AS section_count,
  COUNT(DISTINCT cl.id) AS lesson_count,
  COUNT(DISTINCT clc.id) AS content_count
FROM courses c
LEFT JOIN profiles p ON p.id = c.created_by
LEFT JOIN course_sections cs ON cs.course_id = c.id
LEFT JOIN course_lessons cl ON cl.section_id = cs.id
LEFT JOIN course_lesson_content clc ON clc.lesson_id = cl.id
GROUP BY c.id, c.title, p.first_name, p.last_name, p.email

MANDATORY SECTIONS:

a) Summary Stats (text):
   - Total Sections: COUNT(DISTINCT course_sections.id)
   - Total Lessons: COUNT(DISTINCT course_lessons.id)
   - Total Courses: COUNT(DISTINCT courses.id)
   - Avg Sections per Course: AVG(section_count)
   - Avg Lessons per Section: AVG(lesson_count)

b) Total Lessons per Course Title (LIMIT 50):
| Course Title | Lesson Count |
(JOIN courses, GROUP BY c.id, c.title, ORDER BY lesson_count DESC, LIMIT 50)

c) Content Items per Course Title (LIMIT 50):
| Course Title | Content Count |
(JOIN with course_lesson_content, GROUP BY course, LIMIT 50)

d) Average Sections per Course and Lessons per Section (text):
   - Calculate from aggregated data

e) Course Titles with Most Comprehensive Content (LIMIT 10):
| Course Title | Lesson Count | Creator Name |
(JOIN with profiles for creator names, ORDER BY lesson_count DESC, LIMIT 10)

f) Course Titles with Minimal Content (LIMIT 10):
| Course Title | Lesson Count | Creator Name |
(WHERE lesson_count < 5, JOIN with profiles, LIMIT 10)

g) Content Distribution (LIMIT 30):
| Course Title | Section Count | Lesson Count |
(GROUP BY course, LIMIT 30)

h) üí° Recommendations for Content Gaps (text analysis):
Based on the query results above, provide text recommendations:
- Identify courses with < 5 lessons that need content development
- Highlight courses with no sections or lessons
- Suggest content creation priorities based on enrollment data
- Note any courses with zero content items
‚ùå DO NOT run additional queries for recommendations
‚úÖ DO analyze the data already retrieved above

‚ö†Ô∏è PAGINATION: Include pagination message at the end

---

7. ENROLLMENT TRENDS REPORT
When user requests "enrollment trends" or "enrollment growth":
MANDATORY SECTIONS:

a) Monthly Growth (text):
   - This Month: X enrollments
   - Last Month: Y enrollments
   - Growth Rate: Z%

b) Popular Courses:
| Course Title | Total Enrolled | Growth (30d) | Status |
(ORDER BY enrolled DESC)

c) Multi-Course Students:
| Student Name | Email | Courses Enrolled | Last Enrollment Date |
(students with > 1 course)

d) Enrollment Timeline (Last 30 Days):
| Date | New Enrollments | Total Active |
(GROUP BY date, ORDER BY date DESC)

---

8. PLATFORM USAGE STATISTICS
When user requests "platform statistics" or "platform usage":
MANDATORY SECTIONS:

a) User Summary (text):
   - Total Students: X
   - Total Teachers: Y
   - Total Admins: Z
   - New Users (30d): W
   - Growth Rate: A%

b) Course Summary (text):
   - Published Courses: X
   - Draft Courses: Y
   - Under Review: Z
   - Total Lessons: W
   - Total Content Items: A

c) Activity Metrics Table:
| Metric | Count | Average |
(Quiz Attempts, Assignments Submitted, Avg Quiz Score, Avg Assignment Grade)

d) User Growth Trend (6 Months):
| Month | New Users | Total Users | Growth % |

e) Most Active Users:
| Name | Email | Role | Quiz Attempts | Assignments | Total Activity |
(LIMIT 20)

f) Platform Health Score (text calculation):
   - User Growth: X points
   - Content Creation: Y points
   - Engagement Rate: Z points
   - Overall Score: W/100

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üö® CRITICAL FORMATTING RULES FOR ALL QUICK ACTIONS:

1. ALWAYS use the exact table format specified above for each quick action type
2. ALWAYS include all mandatory columns in the specified order
3. ALWAYS add blank lines before and after tables
4. ALWAYS include follow-up sections where specified
5. NEVER deviate from these formats - users expect consistency
6. ALWAYS apply pagination (LIMIT 20-50 depending on query type)
7. ALWAYS include summary statistics where specified
8. ALWAYS format dates as YYYY-MM-DD
9. ALWAYS round percentages to 1 decimal place
10. ALWAYS round scores/grades to 1 decimal place

When user clicks a quick action button, detect the type from keywords and apply the corresponding format above!

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Always start by calling the appropriate tool(s) to gather information, then provide a response based on the tool results.`
        },
        {
          role: "user",
          content: prompt
        }
      ];

      let iteration = 0;
      let toolInvocations: any[] = [];
      
      while (iteration < MAX_ITERATIONS) {
        iteration++;
        
        if (LOG_LEVEL === "debug") {
          console.log(`[Iteration ${iteration}] Starting OpenAI completion...`);
        }

        // Determine tool choice - force tool usage on first iteration
        let toolChoice: any = "auto";
        if (iteration === 1 && toolInvocations.length === 0) {
          toolChoice = "required";
        }

        // Call OpenAI with current messages and available tools
        const completion = await openai.chat.completions.create({
          model: model,
          messages: messages,
          tools: tools,
          tool_choice: toolChoice,
          temperature: temperature
        });

        const assistantMessage = completion.choices[0].message;
        
        if (LOG_LEVEL === "debug") {
          console.log(`[Iteration ${iteration}] Assistant message:`, assistantMessage);
        }

        // Add assistant message to conversation
        messages.push(assistantMessage);

        // Check if assistant wants to use tools
        if (assistantMessage.tool_calls && assistantMessage.tool_calls.length > 0) {
          
          // Process each tool call
          for (const toolCall of assistantMessage.tool_calls) {
            const toolName = toolCall.function.name;
            const toolArgs = JSON.parse(toolCall.function.arguments || "{}");
            
            if (LOG_LEVEL === "debug") {
              console.log(`[Iteration ${iteration}] Invoking tool: ${toolName} with args:`, toolArgs);
            }

            try {
              // Invoke the MCP tool
              const toolResult = await invokeMCPTool(toolName, toolArgs);
              
              // Track the tool invocation
              toolInvocations.push({
                iteration: iteration,
                tool: toolName,
                arguments: toolArgs,
                result: toolResult.content,
                success: true
              });

              // Add tool result to conversation
              messages.push({
                role: "tool",
                tool_call_id: toolCall.id,
                name: toolName,
                content: toolResult.content || "Tool executed successfully but returned no content."
              });

            } catch (toolError) {
              console.error(`Error invoking tool ${toolName}:`, toolError);
              
              // Track failed tool invocation
              toolInvocations.push({
                iteration: iteration,
                tool: toolName,
                arguments: toolArgs,
                error: String(toolError),
                success: false
              });

              // Add error message to conversation
              messages.push({
                role: "tool",
                tool_call_id: toolCall.id,
                name: toolName,
                content: `Error: ${String(toolError)}`
              });
            }
          }
          
          // Continue the loop to get the assistant's response to the tool results
          continue;
          
        } else {
          // No tools called - check if we have any tool invocations
          if (toolInvocations.length === 0) {
            // Force the assistant to use tools by adding a message
            messages.push(assistantMessage);
            messages.push({
              role: "user",
              content: "You must use the available tools to answer my request. Please call the appropriate tool(s) to gather the information I need."
            });
            continue;
          }
          
          // We have tool results, so we can provide the final response
          const finalResponse = assistantMessage.content;
          
          return new Response(JSON.stringify({
            ok: true,
            response: finalResponse,
            iterations: iteration,
            toolInvocations: toolInvocations,
            conversationLength: messages.length,
            metadata: {
              model: model,
              temperature: temperature,
              totalTokensEstimate: messages.reduce((acc: number, msg: any) => acc + (msg.content?.length || 0), 0)
            }
          }), {
            headers: { ...corsHeaders, 'Content-Type': 'application/json' },
          });
        }
      }

      // If we reach here, we hit the max iterations limit
      return new Response(JSON.stringify({
        ok: true,
        response: "‚è±Ô∏è This query is taking longer than expected to complete.\n\n**What happened?** Your request required many database operations and reached the processing limit.\n\n**What to do:**\n- ‚úÖ Try breaking your request into smaller, more specific queries\n- ‚úÖ Wait 1-2 minutes and try again\n- ‚úÖ Use filters to narrow down the data (e.g., 'last 30 days', 'top 20 students')\n- ‚úÖ Ask for summary statistics instead of detailed lists\n\n**Example:** Instead of 'Show all student data', try 'Show top 20 active students from last month'",
        iterations: iteration,
        toolInvocations: toolInvocations,
        conversationLength: messages.length,
        warning: `Reached maximum iteration limit of ${MAX_ITERATIONS}`,
        metadata: {
          model: model,
          temperature: temperature,
          totalTokensEstimate: messages.reduce((acc: number, msg: any) => acc + (msg.content?.length || 0), 0)
        }
      }), {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    // Streaming invoke endpoint - Server-Sent Events (SSE)
    if (path.endsWith('/invoke-stream') && req.method === 'POST') {
      const body = await req.json();
      const { prompt, temperature = 0.2 } = body;

      // Always use gpt-4o-mini - ignore any model parameter
      const model = "gpt-4o-mini";

      if (!prompt) {
        return new Response(JSON.stringify({
          ok: false,
          error: "Missing 'prompt'. Expected format: { \"prompt\": \"your request here\" }"
        }), {
          status: 400,
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }

      await ensureMCP();

      if (!cachedTools.length) {
        await initializeMCP();
      }

      const tools = mcpToolsToOpenAITools(cachedTools);

      if (!tools.length) {
        return new Response(JSON.stringify({
          ok: false,
          error: "No tools available from MCP server"
        }), {
          status: 400,
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }

      // Create Server-Sent Events stream
      const stream = new ReadableStream({
        async start(controller) {
          const encoder = new TextEncoder();

          // Helper function to send SSE message
          let streamClosed = false;
          const sendEvent = (event: string, data: any) => {
            if (streamClosed) {
              console.log(`‚ö†Ô∏è [STREAM WARNING] Attempted to send event '${event}' after stream closed - ignoring`);
              return;
            }
            try {
              const message = `event: ${event}\ndata: ${JSON.stringify(data)}\n\n`;
              controller.enqueue(encoder.encode(message));
            } catch (error: any) {
              if (error?.message?.includes('controller')) {
                streamClosed = true;
                console.log(`‚ö†Ô∏è [STREAM WARNING] Stream controller error on event '${event}' - stream closed`);
              } else {
                throw error;
              }
            }
          };

          try {
            // Send initial event
            sendEvent('start', { message: 'Starting IRIS query...' });

            console.log('üîç [STREAMING DEBUG] Received prompt from iris-chat-simple');
            console.log('üîç [STREAMING DEBUG] Prompt length:', prompt.length);
            console.log('üîç [STREAMING DEBUG] Prompt preview (first 500 chars):', prompt.substring(0, 500));
            console.log('üîç [STREAMING DEBUG] Prompt preview (last 200 chars):', prompt.substring(prompt.length - 200));

            // Initialize conversation with proper message structure
            // The prompt from iris-chat-simple is a concatenated string with:
            // 1. IRIS_SYSTEM_PROMPT (the long detailed instructions)
            // 2. User Context
            // 3. Conversation history (if any)
            // 4. Current User Query (after "Current User Query: ")
            // We need to SPLIT this into separate system and user messages for OpenAI

            // Extract the user query from the end
            const queryMarker = 'Current User Query: ';
            const queryIndex = prompt.lastIndexOf(queryMarker);

            let systemPrompt = prompt;
            let userQuery = '';

            if (queryIndex !== -1) {
              systemPrompt = prompt.substring(0, queryIndex).trim();
              userQuery = prompt.substring(queryIndex + queryMarker.length).trim();
              console.log('üîç [STREAMING DEBUG] Extracted user query:', userQuery);
              console.log('üîç [STREAMING DEBUG] System prompt length:', systemPrompt.length);
            } else {
              console.warn('‚ö†Ô∏è [STREAMING DEBUG] Could not find "Current User Query:" marker, using entire prompt as system');
            }

            // Build messages with MCP adapter's comprehensive system prompt + iris-chat-simple's platform instruction
            // The systemPrompt from iris-chat-simple contains: platform instruction + user context + conversation history
            // We need to PREPEND the MCP adapter's formatting rules before this
            const mcpSystemPrompt = `You are an assistant for an educational platform that can ONLY respond by using the available tools. You MUST use one or more tools to answer every user request.

üö®üö®üö® CRITICAL RESPONSE FORMATTING - READ THIS BEFORE GENERATING ANY RESPONSE üö®üö®üö®

‚ùå‚ùå‚ùå ABSOLUTELY FORBIDDEN - NEVER USE THIS SYNTAX ‚ùå‚ùå‚ùå:
(No data available)">(No data available)
(No grades available)">(No grades available)
(No quiz scores available)">(No quiz scores available)
ANY text with ")>" characters is FORBIDDEN!

‚úÖ‚úÖ‚úÖ CORRECT SYNTAX FOR EMPTY/NULL VALUES ‚úÖ‚úÖ‚úÖ:
- In table cells: Use "N/A" or "Not available"
- For empty sections: Use plain text like "No quiz scores available."
- NEVER use HTML-like syntax with ")>" characters

Example CORRECT formatting:
| Course Title | Average Quiz Score |
|--------------|-------------------|
| Test Course  | N/A               |

Example WRONG formatting (FORBIDDEN):
| Course Title | Average Quiz Score |
|--------------|-------------------|
| Test Course  | (No data)">(No data) | ‚Üê NEVER DO THIS!

üîç FINAL CHECK BEFORE RESPONDING:
- Search your entire response for ")>" characters
- If found, REPLACE with "N/A" or plain text
- This check is MANDATORY for every response!

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üóÑÔ∏è DATABASE SCHEMA REFERENCE - READ THIS FIRST!
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

‚ö†Ô∏è CRITICAL TABLE SCHEMAS - MEMORIZE THESE:

1. **profiles** table:
   - ‚ùå Does NOT have: full_name column
   - ‚úÖ DOES have: first_name, last_name (separate columns)
   - ‚úÖ To get full name: (p.first_name || ' ' || p.last_name) AS full_name
   - Other columns: email, role, grade, created_at, phone_number, avatar_url

2. **courses** table:
   - ‚ùå Does NOT have: published (boolean) column
   - ‚úÖ DOES have: status column with values ('Draft', 'Published', 'Under Review', 'Rejected')
   - ‚úÖ To filter published: WHERE c.status = 'Published'
   - Other columns: title, description, creator_id, created_at, price

3. **COURSE STRUCTURE HIERARCHY** (CRITICAL - READ THIS!):
   üö® The course structure is hierarchical: courses ‚Üí sections ‚Üí lessons ‚Üí content

   ‚ùå WRONG: course_lesson_content does NOT have course_id column directly!
   ‚úÖ CORRECT: Must join through the hierarchy to reach courses table

   **Complete join pattern to get from content to course:**
   FROM course_lesson_content clc
   JOIN course_lessons cl ON clc.lesson_id = cl.id
   JOIN course_sections cs ON cl.section_id = cs.id
   JOIN courses c ON cs.course_id = c.id

   **Table relationships:**
   - course_lesson_content has: id, lesson_id, content_type, title, due_date, etc.
   - course_lessons has: id, section_id, title, lesson_order
   - course_sections has: id, course_id, title, section_order
   - courses has: id, title, status, creator_id, description, price

   **Example: Query lessons per course:**
   SELECT c.title AS course_title, COUNT(clc.id) AS lesson_count
   FROM course_lesson_content clc
   JOIN course_lessons cl ON clc.lesson_id = cl.id
   JOIN course_sections cs ON cl.section_id = cs.id
   JOIN courses c ON cs.course_id = c.id
   GROUP BY c.id, c.title
   LIMIT 50;

   **Example: Query sections per course:**
   SELECT c.title AS course_title, COUNT(DISTINCT cs.id) AS section_count
   FROM course_sections cs
   JOIN courses c ON cs.course_id = c.id
   GROUP BY c.id, c.title
   LIMIT 50;

4. **assignments** storage:
   - ‚ùå NO standalone "assignments" table exists!
   - ‚úÖ Assignments are in: course_lesson_content WHERE content_type = 'assignment'
   - ‚úÖ Submissions are in: assignment_submissions table
   - ‚úÖ Join pattern: assignment_submissions.assignment_id ‚Üí course_lesson_content.id
   - ‚úÖ To get course from assignment: use the 4-table join pattern above

5. **quizzes** storage:
   - ‚ùå There is NO standalone "quizzes" table!
   - ‚úÖ ALL quizzes are in: course_lesson_content WHERE content_type = 'quiz'
   - ‚úÖ Quiz questions are in: quiz_questions table (has lesson_content_id, NOT quiz_id!)
   - ‚úÖ Attempts are in: quiz_attempts table (has lesson_content_id, NOT quiz_id!)
   - ‚ùå DO NOT use standalone_quiz tables (abandoned/deprecated)
   - ‚úÖ To get course from quiz: use the 4-table join pattern above

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üö®üö®üö® CRITICAL GLOBAL RULES - APPLY TO ALL QUERIES üö®üö®üö®:

‚ö†Ô∏è RULE #0: NEVER SHOW IDs OR UUIDs - ALWAYS SHOW HUMAN-READABLE NAMES!
This is the MOST IMPORTANT rule that applies to EVERY query you execute:

‚ùå NEVER show these columns in ANY table:
- user_id (UUID)
- student_id (UUID)
- teacher_id (UUID)
- creator_id (UUID)
- course_id (UUID)
- assignment_id (UUID)
- quiz_id (UUID)
- ANY column ending in "_id" that contains UUIDs

‚úÖ ALWAYS show these columns instead:
- Full Name (from CONCAT(profiles.first_name, ' ', profiles.last_name) via JOIN - NOT p.full_name!)
- Email (from profiles.email via JOIN)
- Course Title (from courses.title via JOIN)
- Assignment Title (from assignments.title via JOIN)
- Quiz Title (from quiz_questions.title via JOIN)
- Teacher Name (from CONCAT(profiles.first_name, ' ', profiles.last_name) via JOIN on creator_id/teacher_id)
- Student Name (from CONCAT(profiles.first_name, ' ', profiles.last_name) via JOIN on user_id/student_id)

üî• MANDATORY JOINS FOR ALL QUERIES:
- Any query with user_id ‚Üí JOIN profiles p ON p.id = user_id, SELECT (p.first_name || ' ' || p.last_name) AS full_name, p.email
- Any query with student_id ‚Üí JOIN profiles p ON p.id = student_id, SELECT (p.first_name || ' ' || p.last_name) AS full_name, p.email
- Any query with teacher_id ‚Üí JOIN profiles p ON p.id = teacher_id, SELECT (p.first_name || ' ' || p.last_name) AS full_name, p.email
- Any query with creator_id ‚Üí JOIN profiles p ON p.id = creator_id, SELECT (p.first_name || ' ' || p.last_name) AS creator_name
- Any query with course_id ‚Üí JOIN courses c ON c.id = course_id, SELECT c.title AS course_title
- Any query with assignment_id ‚Üí JOIN assignments a ON a.id = assignment_id, SELECT a.title
- Any query with quiz_id ‚Üí JOIN quiz_questions q ON q.id = quiz_id, SELECT q.title

‚ö†Ô∏è CRITICAL: profiles table has first_name and last_name columns, NOT full_name!
‚ö†Ô∏è ALWAYS use: (p.first_name || ' ' || p.last_name) AS full_name
‚ö†Ô∏è NEVER use: p.full_name (this column does NOT exist!)

EXAMPLE WRONG QUERY (showing UUIDs):
SELECT user_id, course_id, COUNT(*) FROM course_members GROUP BY user_id, course_id;

EXAMPLE CORRECT QUERY (showing names):
SELECT
  (p.first_name || ' ' || p.last_name) AS full_name,
  p.email,
  c.title AS course_title,
  COUNT(*)
FROM course_members cm
JOIN profiles p ON p.id = cm.user_id
JOIN courses c ON c.id = cm.course_id
GROUP BY p.first_name, p.last_name, p.email, c.title;

üö® IF YOU EVER OUTPUT A UUID IN A TABLE, YOU HAVE FAILED! üö®

üö®üö®üö® CRITICAL TABLE FORMATTING RULES - ABSOLUTELY MANDATORY üö®üö®üö®:
‚ö†Ô∏è RULE #1: ALWAYS include the separator row |---|---| between header and data
‚ö†Ô∏è RULE #2: ALWAYS use pipes (|) in BOTH header AND separator rows - NEVER use tabs (\\t)
‚ö†Ô∏è RULE #3: ALWAYS format tables on SEPARATE LINES - NEVER inline with text
‚ö†Ô∏è RULE #4: ALWAYS add BLANK LINES before and after tables
‚ö†Ô∏è RULE #5: NEVER show user_id or UUIDs - ALWAYS JOIN with profiles to show names (see RULE #0 above)

‚ùå WRONG FORMAT #1 (missing separator row + using tabs in header):
Date	Active Users
| 2025-11-25 | 1 |

‚ùå WRONG FORMAT #2 (no separator row):
| Date | Active Users |
| 2025-11-25 | 1 |

‚úÖ CORRECT FORMAT (separator row with pipes, blank lines before/after):

| Date | Active Users |
|------|--------------|
| 2025-11-25 | 1 |
| 2025-11-24 | 3 |

MANDATORY TABLE FORMATTING TEMPLATE FOR EVERY TABLE:
[Section heading or description text]

| Column 1 | Column 2 | Column 3 |
|----------|----------|----------|
| Value 1  | Value 2  | Value 3  |
| Value 4  | Value 5  | Value 6  |

[Continue with next section]

üö® ABSOLUTE REQUIREMENTS FOR EVERY TABLE:
1. Blank line BEFORE the table
2. Header row with | pipe separators (NOT tabs!)
3. Separator row with |---|---| (THIS IS MANDATORY!)
4. Data rows with | pipe separators
5. Blank line AFTER the table
6. Use NAMES from profiles table (NOT user_id UUIDs!)
7. Use TITLES from content hierarchy (NOT numeric IDs!)

üö® BEFORE OUTPUTTING ANY TABLE, CHECK:
‚úì Does my header row use | pipes? (Not tabs?)
‚úì Did I include the |---|---| separator row?
‚úì Am I showing names/titles? (Not UUIDs/IDs?)
‚úì Are there blank lines before and after?

IF ANY ANSWER IS "NO", DO NOT OUTPUT THE TABLE! FIX IT FIRST!

üö®üö®üö® CRITICAL PAGINATION RULES - ABSOLUTELY MANDATORY üö®üö®üö®:
‚ö†Ô∏è ALWAYS use LIMIT in your queries to prevent token overflow!
‚ö†Ô∏è ALWAYS add pagination message when using LIMIT!

DEFAULT PAGINATION RULES:
- List queries: LIMIT 50
- Top performers/students: LIMIT 20
- Challenging exercises: LIMIT 10
- Weekly/daily data: LIMIT 7-30 days max

MANDATORY PAGINATION MESSAGE:
When you use LIMIT in your query, you MUST end your response with:

üìÑ Showing first [N] results.
üí° **Load More**: To see more, ask 'Show next [N] results'

EXAMPLE:
[Your tables and analysis here]

üìÑ Showing first 20 results.
üí° **Load More**: To see more, ask 'Show next 20 students'

‚ö†Ô∏è WITHOUT THIS MESSAGE, USERS CANNOT ACCESS MORE DATA!

For all other rules, see the platform-specific instructions below.

---

`;

            const messages: any[] = [
              {
                role: "system",
                content: mcpSystemPrompt + systemPrompt  // MCP formatting rules + IRIS platform instructions + context + history
              },
              {
                role: "user",
                content: userQuery || prompt  // The actual user query
              }
            ];

            console.log('üîç [STREAMING DEBUG] Initial messages array:', JSON.stringify(messages.map(m => ({ role: m.role, contentLength: m.content?.length }))));


            let iteration = 0;
            const toolInvocations: any[] = [];

            // Iterative tool calling loop
            console.log(`üö® [CRITICAL DEBUG] ========== ENTERING WHILE LOOP, MAX_ITERATIONS=${MAX_ITERATIONS} ==========`);

            while (iteration < MAX_ITERATIONS) {
              iteration++;

              console.log(`üö®üö®üö® [CRITICAL DEBUG] ========== ITERATION ${iteration} STARTED ==========`);
              console.log(`üö® [CRITICAL DEBUG] Current messages array length:`, messages.length);
              console.log(`üö® [CRITICAL DEBUG] Total tool invocations so far:`, toolInvocations.length);
              console.log(`üö® [CRITICAL DEBUG] Condition check: ${iteration} < ${MAX_ITERATIONS} = ${iteration < MAX_ITERATIONS}`);

              sendEvent('iteration', { iteration, message: `Processing iteration ${iteration}...` });

              const toolChoice: any = (iteration === 1 && toolInvocations.length === 0) ? "required" : "auto";

              console.log(`üîç [STREAMING DEBUG] Iteration ${iteration} - Tool choice:`, toolChoice);
              console.log(`üîç [STREAMING DEBUG] Iteration ${iteration} - Messages count before OpenAI:`, messages.length);
              console.log(`üîç [STREAMING DEBUG] Iteration ${iteration} - Messages structure:`,
                JSON.stringify(messages.map((m, i) => ({
                  index: i,
                  role: m.role,
                  hasContent: !!m.content,
                  contentLength: m.content?.length,
                  hasToolCalls: !!m.tool_calls,
                  toolCallsCount: m.tool_calls?.length
                }))));

              // Call OpenAI WITHOUT streaming first for tool calls
              console.log(`üö® [CRITICAL DEBUG] About to call OpenAI API for iteration ${iteration}`);
              console.log(`üö® [CRITICAL DEBUG] OpenAI request params:`, {
                model: model,
                messagesCount: messages.length,
                toolsCount: tools.length,
                tool_choice: toolChoice,
                temperature: temperature,
                stream: false
              });

              const completion = await openai.chat.completions.create({
                model: model,
                messages: messages,
                tools: tools,
                tool_choice: toolChoice,
                temperature: temperature,
                stream: false // Tool calls don't stream well
              });

              console.log(`üö® [CRITICAL DEBUG] OpenAI API call completed for iteration ${iteration}`);

              const assistantMessage = completion.choices[0].message;
              const finishReason = completion.choices[0].finish_reason;

              console.log(`üîç [STREAMING DEBUG] Iteration ${iteration} - OpenAI response:`, {
                finishReason: finishReason,
                hasContent: !!assistantMessage.content,
                contentPreview: assistantMessage.content?.substring(0, 200),
                hasToolCalls: !!assistantMessage.tool_calls,
                toolCallsCount: assistantMessage.tool_calls?.length,
                toolNames: assistantMessage.tool_calls?.map((t: any) => t.function.name)
              });

              console.log(`üö® [CRITICAL DEBUG] Iteration ${iteration} - finish_reason:`, finishReason);
              console.log(`üö® [CRITICAL DEBUG] Iteration ${iteration} - Will continue?:`, !!(assistantMessage.tool_calls && assistantMessage.tool_calls.length > 0));

              // Check if assistant wants to use tools
              if (assistantMessage.tool_calls && assistantMessage.tool_calls.length > 0) {
                // Only push assistant message if it has tool calls
                messages.push(assistantMessage);

                sendEvent('tools', {
                  count: assistantMessage.tool_calls.length,
                  tools: assistantMessage.tool_calls.map((t: any) => t.function.name)
                });

                // Process each tool call
                for (const toolCall of assistantMessage.tool_calls) {
                  const toolName = toolCall.function.name;
                  const toolArgs = JSON.parse(toolCall.function.arguments || "{}");

                  sendEvent('tool_call', { tool: toolName, status: 'executing' });

                  try {
                    const toolResult = await invokeMCPTool(toolName, toolArgs);

                    console.log(`üîç [STREAMING DEBUG] Tool ${toolName} result:`, {
                      hasContent: !!toolResult.content,
                      contentLength: toolResult.content?.length,
                      contentPreview: toolResult.content?.substring(0, 300)
                    });

                    toolInvocations.push({
                      iteration,
                      tool: toolName,
                      arguments: toolArgs,
                      result: toolResult.content,
                      success: true
                    });

                    sendEvent('tool_result', { tool: toolName, status: 'success' });

                    const toolMessage = {
                      role: "tool",
                      tool_call_id: toolCall.id,
                      name: toolName,
                      content: toolResult.content || "Tool executed successfully."
                    };

                    console.log(`üîç [STREAMING DEBUG] Adding tool message to conversation:`, {
                      role: toolMessage.role,
                      name: toolMessage.name,
                      contentLength: toolMessage.content?.length
                    });

                    messages.push(toolMessage);

                    console.log(`üö® [CRITICAL DEBUG] Tool ${toolName} completed successfully, messages array now has ${messages.length} messages`);

                  } catch (toolError: any) {
                    console.error(`Error invoking tool ${toolName}:`, toolError);
                    console.error(`üîç [MCP-ADAPTER ERROR DEBUG] Tool invocation error:`, {
                      toolName: toolName,
                      errorMessage: toolError?.message || 'Unknown error',
                      errorName: toolError?.name || 'N/A',
                      errorStack: toolError?.stack || 'N/A',
                      isAbortError: toolError?.name === 'AbortError',
                      timestamp: new Date().toISOString()
                    });

                    toolInvocations.push({
                      iteration,
                      tool: toolName,
                      arguments: toolArgs,
                      error: String(toolError),
                      success: false
                    });

                    sendEvent('tool_result', { tool: toolName, status: 'error', error: String(toolError) });

                    messages.push({
                      role: "tool",
                      tool_call_id: toolCall.id,
                      name: toolName,
                      content: `Error: ${String(toolError)}`
                    });
                  }
                }

                console.log(`üö® [CRITICAL DEBUG] Iteration ${iteration} - All tools executed, about to CONTINUE to next iteration`);
                console.log(`üö® [CRITICAL DEBUG] Messages array length before continue:`, messages.length);
                console.log(`üö® [CRITICAL DEBUG] Tool invocations count:`, toolInvocations.length);

                continue; // Go to next iteration to process tool results

              } else {
                // No tools called - final response with STREAMING
                console.log(`üö® [CRITICAL DEBUG] ========== NO TOOL CALLS IN ITERATION ${iteration} ==========`);
                console.log(`üîç [STREAMING DEBUG] No tool calls in iteration ${iteration}`);
                console.log(`üîç [STREAMING DEBUG] Total tool invocations so far:`, toolInvocations.length);
                console.log(`üö® [CRITICAL DEBUG] Assistant message content:`, assistantMessage.content);
                console.log(`üö® [CRITICAL DEBUG] Assistant message finish_reason:`, finishReason);

                if (toolInvocations.length === 0) {
                  // Force tool usage
                  console.log('üö®üö®üö® [CRITICAL DEBUG] FORCING TOOL USAGE - NO TOOLS CALLED YET');
                  console.log('üîç [STREAMING DEBUG] Forcing tool usage - no tools called yet');
                  messages.push({
                    role: "user",
                    content: "You must use the available tools to answer my request. Please call the appropriate tool(s) to gather the information I need."
                  });
                  console.log(`üö® [CRITICAL DEBUG] Added force tool usage message, about to CONTINUE`);
                  continue;
                }

                // Stream the final response
                console.log('üîç [STREAMING DEBUG] Starting final streaming response');
                console.log('üîç [STREAMING DEBUG] Final messages array before streaming:',
                  JSON.stringify(messages.map((m, i) => ({
                    index: i,
                    role: m.role,
                    hasContent: !!m.content,
                    contentLength: m.content?.length,
                    contentPreview: m.role === 'tool' ? m.content?.substring(0, 100) : undefined
                  }))));

                sendEvent('response_start', { message: 'Generating response...' });

                const streamCompletion = await openai.chat.completions.create({
                  model: model,
                  messages: messages,
                  temperature: temperature,
                  stream: true // NOW we stream the final response
                });

                let fullResponse = '';
                let chunkCount = 0;

                for await (const chunk of streamCompletion) {
                  const content = chunk.choices[0]?.delta?.content;
                  if (content) {
                    chunkCount++;
                    fullResponse += content;
                    sendEvent('chunk', { content });

                    if (chunkCount === 1) {
                      console.log('üîç [STREAMING DEBUG] First chunk received:', content);
                    }
                  }
                }

                console.log('üîç [STREAMING DEBUG] Streaming complete');
                console.log('üîç [STREAMING DEBUG] Total chunks sent:', chunkCount);
                console.log('üîç [STREAMING DEBUG] Full response length:', fullResponse.length);
                console.log('üîç [STREAMING DEBUG] Full response preview (first 300 chars):', fullResponse.substring(0, 300));

                // Send completion event
                sendEvent('complete', {
                  response: fullResponse,
                  iterations: iteration,
                  toolsUsed: toolInvocations.map((t: any) => t.tool),
                  tokensUsed: messages.reduce((acc: number, msg: any) => acc + (msg.content?.length || 0), 0)
                });

                console.log(`üö® [CRITICAL DEBUG] ========== RESPONSE COMPLETE - CLOSING STREAM ==========`);
                console.log(`üö® [CRITICAL DEBUG] Total iterations:`, iteration);
                console.log(`üö® [CRITICAL DEBUG] Total tools used:`, toolInvocations.length);

                streamClosed = true;
                controller.close();
                return;
              }
            }

            // Max iterations reached
            console.log(`üö®üö®üö® [CRITICAL DEBUG] ========== EXITED WHILE LOOP ==========`);
            console.log(`üö® [CRITICAL DEBUG] Final iteration count:`, iteration);
            console.log(`üö® [CRITICAL DEBUG] MAX_ITERATIONS:`, MAX_ITERATIONS);
            console.log(`üö® [CRITICAL DEBUG] Total tool invocations:`, toolInvocations.length);
            console.log(`üö® [CRITICAL DEBUG] Reason: MAX_ITERATIONS REACHED`);

            sendEvent('error', { message: '‚è±Ô∏è This query is taking longer than expected to complete.\n\n**What happened?** Your request required many database operations and reached the processing limit.\n\n**What to do:**\n- ‚úÖ Try breaking your request into smaller, more specific queries\n- ‚úÖ Wait 1-2 minutes and try again\n- ‚úÖ Use filters to narrow down the data (e.g., \'last 30 days\', \'top 20 students\')\n- ‚úÖ Ask for summary statistics instead of detailed lists\n- üîÑ **If the conversation has grown long**, reset the chat and try again with a fresh session\n\n**Example:** Instead of \'Show all student data\', try \'Show top 20 active students from last month\'' });
            streamClosed = true;
            controller.close();

          } catch (error: any) {
            console.error('Stream error:', error);
            console.error('üîç [MCP-ADAPTER ERROR DEBUG] Stream error:', {
              errorMessage: error?.message || 'Unknown error',
              errorName: error?.name || 'N/A',
              errorStack: error?.stack || 'N/A',
              timestamp: new Date().toISOString()
            });
            // Send the actual error message, not just String(error)
            sendEvent('error', { message: error?.message || String(error) });
            streamClosed = true;
            controller.close();
          }
        }
      });

      return new Response(stream, {
        headers: {
          ...corsHeaders,
          'Content-Type': 'text/event-stream',
          'Cache-Control': 'no-cache',
          'Connection': 'keep-alive',
        },
      });
    }

    // Legacy invoke-tool endpoint
    if (path.endsWith('/invoke-tool') && req.method === 'POST') {
      const body = await req.json();
      const { name, arguments: args } = body;
      
      if (!name) {
        return new Response(JSON.stringify({ ok: false, error: "Missing 'name'." }), {
          status: 400,
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }
      
      try {
        const result = await invokeMCPTool(name, args);
        return new Response(JSON.stringify({ ok: true, content: result.content, raw: result.raw }), {
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      } catch (error) {
        console.error(error);
        // Reset the cached tools on errors to trigger reconnect next time.
        cachedTools = [];
        return new Response(JSON.stringify({ ok: false, error: String(error) }), {
          status: 500,
          headers: { ...corsHeaders, 'Content-Type': 'application/json' },
        });
      }
    }

    // Default response for unmatched routes
    return new Response(JSON.stringify({ 
      error: "Not Found",
      availableEndpoints: ["/health", "/config", "/tools", "/invoke", "/invoke-tool"]
    }), {
      status: 404,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });

  } catch (error: any) {
    console.error("Error in Edge Function:", error);
    console.error('üîç [MCP-ADAPTER ERROR DEBUG] Main catch block error:', {
      errorMessage: error?.message || 'Unknown error',
      errorName: error?.name || 'N/A',
      errorStack: error?.stack || 'N/A',
      timestamp: new Date().toISOString(),
      fullError: JSON.stringify(error, Object.getOwnPropertyNames(error))
    });
    // Reset the cached tools on errors to trigger reconnect next time.
    cachedTools = [];
    return new Response(JSON.stringify({
      ok: false,
      error: String(error),
      details: "An error occurred during processing"
    }), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });
  }
});

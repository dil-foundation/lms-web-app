import React, { useState, useEffect, useRef, useCallback } from 'react';
import { Button } from '@/components/ui/button';
import { Card, CardContent, CardHeader, CardTitle } from '@/components/ui/card';
import { Globe, Mic, X, Target, Volume2, Play, Square } from 'lucide-react';
import { Badge } from '@/components/ui/badge';
import { connectLearnSocket, sendLearnMessage, closeLearnSocket, WebSocketMessage, getSocketState, waitForWebSocketReady, isWebSocketReady } from '../../utils/websocket';
import { useAudioRecorder } from '../../hooks/useAudioRecorder';

type LearnStep = 'welcome' | 'translate' | 'conversation';
type ConversationState = 'waiting' | 'listening' | 'processing' | 'speaking' | 'playing_intro' | 'word_by_word' | 'you_said' | 'full_sentence' | 'feedback' | 'no_speech';
type LanguageMode = 'urdu' | 'english';

// Props interface for AIStudentLearn component (empty by design)
// eslint-disable-next-line @typescript-eslint/no-empty-object-type
interface AIStudentLearnProps {}

export const AIStudentLearn: React.FC<AIStudentLearnProps> = () => {
  const [step, setStep] = useState<LearnStep>('welcome');
  const [languageMode, setLanguageMode] = useState<LanguageMode>('urdu');
  const [conversationState, setConversationState] = useState<ConversationState>('waiting');
  const [currentMessage, setCurrentMessage] = useState<string>('');
  const [isConnected, setIsConnected] = useState<boolean>(false);
  const [hasPlayedGreeting, setHasPlayedGreeting] = useState<boolean>(false);
  const [hasPlayedWelcomeAudio, setHasPlayedWelcomeAudio] = useState<boolean>(false);
  const [isPlayingWelcomeAudio, setIsPlayingWelcomeAudio] = useState<boolean>(false);
  const [showManualPlayButton, setShowManualPlayButton] = useState<boolean>(false);
  const [hasTriedAutoplay, setHasTriedAutoplay] = useState<boolean>(false);
  
  // Learning flow state
  const [currentWords, setCurrentWords] = useState<string[]>([]);
  const [currentWordIndex, setCurrentWordIndex] = useState<number>(0);
  const [fullSentence, setFullSentence] = useState<string>('');
  const [userSaidText, setUserSaidText] = useState<string>('');
  const [englishSentence, setEnglishSentence] = useState<string>('');
  const [urduSentence, setUrduSentence] = useState<string>('');
  const [feedbackText, setFeedbackText] = useState<string>('');
  const [isPlayingAudio, setIsPlayingAudio] = useState<boolean>(false);
  
  // State recovery timeout refs
  const stateTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  
  const { isRecording, audioBlob, startRecording, stopRecording, error: recordingError } = useAudioRecorder();
  const [connectionError, setConnectionError] = useState<string>('');
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const sendCompletionEventRef = useRef<((eventType: 'word_by_word_complete' | 'feedback_complete' | 'you_said_complete') => void) | null>(null);

  // Helper function for translations
  const t = useCallback((en: string, ur: string): string => languageMode === 'english' ? en : ur, [languageMode]);

  // Reset learning state for next sentence
  const resetLearningState = useCallback((): void => {
    setCurrentWords([]);
    setCurrentWordIndex(0);
    setFullSentence('');
    setUserSaidText('');
    setEnglishSentence('');
    setUrduSentence('');
    setFeedbackText('');
    
    // Clear any state recovery timeouts
    if (stateTimeoutRef.current) {
      clearTimeout(stateTimeoutRef.current);
      stateTimeoutRef.current = null;
    }
  }, []);

  // State recovery mechanism - automatically recover from stuck states
  const setConversationStateWithRecovery = useCallback((newState: ConversationState): void => {
    // Clear existing timeout
    if (stateTimeoutRef.current) {
      clearTimeout(stateTimeoutRef.current);
      stateTimeoutRef.current = null;
    }
    
    // Set the new state
    setConversationState(newState);
    console.log(`ğŸ”„ State changed to: ${newState}`);
    
    // Set recovery timeout for states that might get stuck
    const recoveryTime = (() => {
      switch (newState) {
        case 'processing': return 25000;      // 25 seconds for server processing
        case 'word_by_word': return 30000;    // 30 seconds for word-by-word playback
        case 'you_said': return 8000;         // 8 seconds for "you said" display
        case 'feedback': return 12000;        // 12 seconds for feedback display
        case 'full_sentence': return 15000;   // 15 seconds for full sentence state
        case 'speaking': return 20000;        // 20 seconds for AI speaking
        default: return null; // No timeout for waiting, listening states
      }
    })();
    
    if (recoveryTime) {
      console.log(`ğŸ• Setting recovery timeout for ${newState} state: ${recoveryTime}ms`);
      stateTimeoutRef.current = setTimeout(() => {
        console.warn(`âš ï¸ State '${newState}' timeout after ${recoveryTime}ms - forcing recovery`);
        
        // Force recovery to waiting state
        setConversationState('waiting');
        setCurrentMessage(languageMode === 'english' ? 
          `Recovered from stuck state. Ready to continue.` : 
          `Ø±Ú© Ú¯Ø¦ÛŒ Ø­Ø§Ù„Øª Ø³Û’ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒÛ” Ø¬Ø§Ø±ÛŒ Ø±Ú©Ú¾Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø±Û”`
        );
        
        // Clean up any audio or learning state
        cleanupAudio();
        resetLearningState();
        
        stateTimeoutRef.current = null;
      }, recoveryTime);
    }
     }, [languageMode]);

  // General error recovery function will be defined later with cleanupAudio

  // Enhanced error recovery with retry mechanism
  const recoverFromError = useCallback((errorType: string, errorMessage?: string): void => {
    console.warn(`ğŸ”„ Recovering from error: ${errorType}`);
    console.warn(`Error message: ${errorMessage || 'Unknown error'}`);
    
    // Clear any timeouts or ongoing operations
    if (typeof window !== 'undefined' && (window as any).currentProcessingTimeout) {
      clearTimeout((window as any).currentProcessingTimeout);
      (window as any).currentProcessingTimeout = null;
    }
    
         // Clean up audio and state will be handled by individual functions
     resetLearningState();
    
    // Set appropriate recovery message
    const recoveryMessage = (() => {
      switch (errorType) {
        case 'audio_upload_failed':
          return languageMode === 'english' ? 
            'Audio upload failed. Please try speaking again.' : 
            'Ø¢ÚˆÛŒÙˆ Ø§Ù¾ Ù„ÙˆÚˆ Ù†Ø§Ú©Ø§Ù…Û” Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¯ÙˆØ¨Ø§Ø±Û Ø¨ÙˆÙ„ÛŒÚºÛ”';
        case 'processing_timeout':
          return languageMode === 'english' ? 
            'Server processing timeout. Please try again.' : 
            'Ø³Ø±ÙˆØ± Ù¾Ø±ÙˆØ³ÛŒØ³Ù†Ú¯ Ù¹Ø§Ø¦Ù… Ø¢Ø¤Ù¹Û” Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”';
        case 'connection_lost':
          return languageMode === 'english' ? 
            'Connection lost. Please check your internet.' : 
            'Ú©Ù†Ú©Ø´Ù† Ù¹ÙˆÙ¹ Ú¯ÛŒØ§Û” Ø§Ù¾Ù†Ø§ Ø§Ù†Ù¹Ø±Ù†ÛŒÙ¹ Ú†ÛŒÚ© Ú©Ø±ÛŒÚºÛ”';
        default:
          return languageMode === 'english' ? 
            'An error occurred. Ready to try again.' : 
            'Ø®Ø±Ø§Ø¨ÛŒ ÛÙˆØ¦ÛŒÛ” Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø±Û”';
      }
    })();
    
    // Reset to waiting state with recovery message
    setConversationStateWithRecovery('waiting');
    setCurrentMessage(recoveryMessage);
    
    console.log(`âœ… Recovery complete. Ready for user input.`);
     }, [languageMode, resetLearningState]);

  // Cleanup audio resources
  const cleanupAudio = useCallback((): void => {
    if (audioRef.current) {
      audioRef.current.pause();
      audioRef.current.src = '';
      audioRef.current = null;
    }
    setIsPlayingAudio(false);
  }, []);

  // Play welcome audio using pre-recorded S3 file
  const playWelcomeAudio = useCallback((isAutomatic: boolean = false): void => {
    if (isPlayingWelcomeAudio) return; // Prevent multiple plays
    
    // If this is an automatic attempt and we've already tried or user has played it, skip
    if (isAutomatic && (hasTriedAutoplay || hasPlayedWelcomeAudio)) {
      return;
    }
    
    setIsPlayingWelcomeAudio(true);
    
    // Play pre-recorded static audio from S3
    const audio = new Audio('https://dil-lms.s3.us-east-1.amazonaws.com/greeting_message_multilingual.mp3');
    
    audio.play().then(() => {
      // Audio started playing successfully
      console.log('Welcome audio started playing');
      setShowManualPlayButton(false); // Hide manual button if autoplay worked
    }).catch((error: Error) => {
      console.error('Error playing welcome audio:', error);
      setIsPlayingWelcomeAudio(false);
      
      // If this was an automatic attempt and failed, show manual button
      if (isAutomatic) {
        setShowManualPlayButton(true);
        console.log('Autoplay blocked, showing manual play button');
      }
    });
    
    audio.onended = () => {
      console.log('Welcome audio finished playing');
      setIsPlayingWelcomeAudio(false);
      setHasPlayedWelcomeAudio(true);
    };

    audio.onerror = () => {
      console.error('Error loading welcome audio');
      setIsPlayingWelcomeAudio(false);
      if (isAutomatic) {
        setShowManualPlayButton(true);
      }
    };
  }, [isPlayingWelcomeAudio, hasTriedAutoplay, hasPlayedWelcomeAudio]);

  // Handler for manual play button click
  const handleManualPlayClick = useCallback((): void => {
    playWelcomeAudio(false);
  }, [playWelcomeAudio]);

  // Always start with welcome screen
  // useEffect(() => {
  //   const hasVisited = localStorage.getItem('hasVisitedLearn');
  //   if (hasVisited === 'true') {
  //     setStep('translate');
  //   }
  // }, []);

  // Try to play welcome audio automatically when step changes to welcome
  useEffect(() => {
    if (step === 'welcome' && !hasPlayedWelcomeAudio && !hasTriedAutoplay) {
      // Try automatic playback only once, will show manual button if blocked
      const timeoutId = setTimeout(() => {
        setHasTriedAutoplay(true);
        playWelcomeAudio(true);
      }, 500); // Small delay to ensure page is fully loaded
      
      return () => clearTimeout(timeoutId);
    }
    
    // Reset autoplay attempt when leaving welcome screen
    if (step !== 'welcome') {
      setHasTriedAutoplay(false);
      setShowManualPlayButton(false);
    }
  }, [step, hasPlayedWelcomeAudio, hasTriedAutoplay, playWelcomeAudio]);

  // Handle audio upload when recording stops
  useEffect(() => {
    if (audioBlob && step === 'conversation') {
      // Check if audio blob has sufficient size (minimum 1KB to filter out empty recordings)
      if (audioBlob.size < 1000) {
        console.warn('Audio blob too small, likely empty recording:', audioBlob.size, 'bytes');
        setConversationState('waiting');
        setCurrentMessage(languageMode === 'english' ? 'Recording too short. Please hold the button and speak clearly.' : 'Ø±ÛŒÚ©Ø§Ø±ÚˆÙ†Ú¯ Ø¨ÛØª Ú†Ú¾ÙˆÙ¹ÛŒ ÛÛ’Û” Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¨Ù¹Ù† Ø¯Ø¨Ø§Ø¦ÛŒÚº Ø§ÙˆØ± ØµØ§Ù Ø¨ÙˆÙ„ÛŒÚºÛ”');
        return;
      }
      
      console.log('Processing audio blob:', audioBlob.size, 'bytes, type:', audioBlob.type);
      uploadAudio(audioBlob);
    }
  }, [audioBlob, step, languageMode]);

    // Memoized message and audio handlers - stabilized dependencies
  const handleWebSocketMessage = useCallback((data: WebSocketMessage): void => {
    console.log('ğŸ”½ ==============================================');
    console.log('ğŸ”½ WebSocket message received:', data);
    console.log('ğŸ”½ Message step:', data.step);
    console.log('ğŸ”½ Full message data:', JSON.stringify(data, null, 2));
    console.log('ğŸ”½ Current conversation state:', conversationState);
    console.log('ğŸ”½ Data keys available:', Object.keys(data || {}));
    console.log('ğŸ”½ Data type:', typeof data);
    console.log('ğŸ”½ Has step?', !!data.step);
    console.log('ğŸ”½ Has response?', !!data.response);
    console.log('ğŸ”½ Has words?', !!data.words);
    console.log('ğŸ”½ Has english_sentence?', !!data.english_sentence);
    console.log('ğŸ”½ Has urdu_sentence?', !!data.urdu_sentence);
    console.log('ğŸ”½ ==============================================');
    
    // Clear any processing timeout since we got a response
    if (typeof window !== 'undefined' && (window as any).currentProcessingTimeout) {
      clearTimeout((window as any).currentProcessingTimeout);
      (window as any).currentProcessingTimeout = null;
    }
    
    // Enhanced message format detection and handling
    if (!data.step) {
      console.log('ğŸ” No step found in message, analyzing message format...');
      console.log('ğŸ” Available properties:', Object.keys(data || {}));
      
      // Check for different possible message formats from server
      
      // Format 1: Direct response with transcription (You said format)
      if (data.response && typeof data.response === 'string') {
        console.log('ğŸ” Found direct response - treating as "you_said"');
        setConversationStateWithRecovery('you_said');
        setUserSaidText(data.response);
        if (data.english_sentence) setEnglishSentence(data.english_sentence);
        if (data.urdu_sentence) setUrduSentence(data.urdu_sentence);
        setCurrentMessage(`${languageMode === 'english' ? 'You said:' : 'Ø¢Ù¾ Ù†Û’ Ú©ÛØ§:'} ${data.response}. ${languageMode === 'english' ? 'Now repeat after me.' : 'Ø§Ø¨ Ù…ÛŒØ±Û’ Ù¾ÛŒÚ†Ú¾Û’ Ø¯ÛØ±Ø§Ø¦ÛŒÚºÛ”'}`);
        
        // Auto-progress to word_by_word after 3 seconds
        setTimeout(() => {
          sendCompletionEventRef.current?.('you_said_complete');
        }, 3000);
        return;
      }
      
      // Format 2: Word array for word-by-word learning
      if (data.words && Array.isArray(data.words) && data.words.length > 0) {
        console.log('ğŸ” Found words array - treating as "word_by_word"');
        setConversationStateWithRecovery('word_by_word');
        setCurrentWords(data.words);
        setCurrentWordIndex(0);
        if (data.english_sentence) setEnglishSentence(data.english_sentence);
        if (data.urdu_sentence) setUrduSentence(data.urdu_sentence);
        setCurrentMessage(languageMode === 'english' ? 'Repeat after me.' : 'Ù…ÛŒØ±Û’ Ù¾ÛŒÚ†Ú¾Û’ Ø¯ÛØ±Ø§Ø¦ÛŒÚºÛ”');
        playWordByWord(data.words);
        return;
      }
      
      // Format 3: English sentence for full sentence practice
      if (data.english_sentence && typeof data.english_sentence === 'string') {
        console.log('ğŸ” Found english_sentence - treating as "full_sentence"');
        setConversationStateWithRecovery('full_sentence');
        setFullSentence(data.english_sentence);
        setEnglishSentence(data.english_sentence);
        if (data.urdu_sentence) setUrduSentence(data.urdu_sentence);
        setCurrentMessage(`${languageMode === 'english' ? 'Now repeat the full sentence:' : 'Ø§Ø¨ Ù¾ÙˆØ±Ø§ Ø¬Ù…Ù„Û Ø¯ÛØ±Ø§Ø¦ÛŒÚº:'} ${data.english_sentence}.`);
        return;
      }
      
      // Format 4: Feedback or completion message
      if ((data.feedback && typeof data.feedback === 'string') || (data.message && typeof data.message === 'string')) {
        const feedbackMsg = (typeof data.feedback === 'string' ? data.feedback : '') || (typeof data.message === 'string' ? data.message : '');
        console.log('ğŸ” Found feedback/message - treating as "feedback"');
        setConversationStateWithRecovery('feedback');
        setFeedbackText(feedbackMsg);
        setCurrentMessage(feedbackMsg);
        setTimeout(() => {
          sendCompletionEventRef.current?.('feedback_complete');
          setTimeout(() => {
            setConversationStateWithRecovery('waiting');
            setCurrentMessage(languageMode === 'english' ? 'Ready for next sentence. Press and hold to speak.' : 'Ø§Ú¯Ù„Û’ Ø¬Ù…Ù„Û’ Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø±Û” Ø¨ÙˆÙ„Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø¯Ø¨Ø§Ø¦ÛŒÚº Ø§ÙˆØ± Ø±Ú©Ú¾ÛŒÚºÛ”');
            resetLearningState();
          }, 2000);
        }, 5000);
        return;
      }
      
      // Format 5: Status or error messages
      if ((data.status && typeof data.status === 'string') || (data.error && typeof data.error === 'string')) {
        const statusMsg = (typeof data.error === 'string' ? data.error : '') || (typeof data.status === 'string' ? data.status : '');
        console.log('ğŸ” Found status/error message:', statusMsg);
        
        if (statusMsg && statusMsg.toLowerCase().includes('no speech')) {
          setConversationStateWithRecovery('no_speech');
          setCurrentMessage(languageMode === 'english' ? 'No speech detected. Please try again.' : 'Ú©ÙˆØ¦ÛŒ Ø¢ÙˆØ§Ø² Ù†ÛÛŒÚº Ø³Ù†Ø§Ø¦ÛŒ Ø¯ÛŒÛ” Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”');
          setTimeout(() => {
            setConversationStateWithRecovery('waiting');
            setCurrentMessage(languageMode === 'english' ? 'Press and hold to speak' : 'Ø¨ÙˆÙ„Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø¯Ø¨Ø§Ø¦ÛŒÚº Ø§ÙˆØ± Ø±Ú©Ú¾ÛŒÚº');
          }, 3000);
        } else {
          setConversationStateWithRecovery('feedback');
          setCurrentMessage(statusMsg || 'Server response received');
        }
        return;
      }
      
      // Format 6: Unknown format - log and provide generic feedback
      console.warn('ğŸ” Unknown message format received');
      console.warn('ğŸ” Message data:', data);
      console.warn('ğŸ” Will treat as generic feedback and continue');
      
      setConversationStateWithRecovery('feedback');
      setFeedbackText('Message received from server');
      setCurrentMessage(languageMode === 'english' ? 'Processing complete. Let\'s continue!' : 'Ù¾Ø±ÙˆØ³ÛŒØ³Ù†Ú¯ Ù…Ú©Ù…Ù„Û” Ø¢Ø¦ÛŒÛ’ Ø¬Ø§Ø±ÛŒ Ø±Ú©Ú¾ØªÛ’ ÛÛŒÚº!');
      setTimeout(() => {
        sendCompletionEventRef.current?.('feedback_complete');
        setTimeout(() => {
          setConversationStateWithRecovery('waiting');
          setCurrentMessage(languageMode === 'english' ? 'Ready for next sentence. Press and hold to speak.' : 'Ø§Ú¯Ù„Û’ Ø¬Ù…Ù„Û’ Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø±Û” Ø¨ÙˆÙ„Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø¯Ø¨Ø§Ø¦ÛŒÚº Ø§ÙˆØ± Ø±Ú©Ú¾ÛŒÚºÛ”');
          resetLearningState();
        }, 2000);
      }, 3000);
      return;
    }
    
    switch (data.step) {
      case 'retry':
        setConversationStateWithRecovery('waiting');
        setCurrentMessage(languageMode === 'english' ? 'Try again' : 'Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚº');
        break;
        
      case 'you_said_audio':
        setConversationStateWithRecovery('you_said');
        setUserSaidText(data.response || '');
        if (data.english_sentence) {
          setEnglishSentence(data.english_sentence);
        }
        if (data.urdu_sentence) {
          setUrduSentence(data.urdu_sentence);
        }
        setCurrentMessage(`${languageMode === 'english' ? 'You said:' : 'Ø¢Ù¾ Ù†Û’ Ú©ÛØ§:'} ${data.response || ''}. ${languageMode === 'english' ? 'Now repeat after me.' : 'Ø§Ø¨ Ù…ÛŒØ±Û’ Ù¾ÛŒÚ†Ú¾Û’ Ø¯ÛØ±Ø§Ø¦ÛŒÚºÛ”'}`);
        // Auto-complete you_said step after a brief delay
        setTimeout(() => {
          sendCompletionEventRef.current?.('you_said_complete');
        }, 3000);
        break;
        
      case 'repeat_prompt':
      case 'word_by_word':
        setConversationStateWithRecovery('word_by_word');
        if (data.words && Array.isArray(data.words)) {
          setCurrentWords(data.words);
          setCurrentWordIndex(0);
          if (data.english_sentence) {
            setEnglishSentence(data.english_sentence);
          }
          if (data.urdu_sentence) {
            setUrduSentence(data.urdu_sentence);
          }
          setCurrentMessage(languageMode === 'english' ? 'Repeat after me.' : 'Ù…ÛŒØ±Û’ Ù¾ÛŒÚ†Ú¾Û’ Ø¯ÛØ±Ø§Ø¦ÛŒÚºÛ”');
          playWordByWord(data.words);
        }
        break;
        
      case 'full_sentence_audio':
        setConversationStateWithRecovery('full_sentence');
        if (data.english_sentence) {
          setFullSentence(data.english_sentence);
          setEnglishSentence(data.english_sentence);
        }
        if (data.urdu_sentence) {
          setUrduSentence(data.urdu_sentence);
        }
        setCurrentMessage(`${languageMode === 'english' ? 'Now repeat the full sentence:' : 'Ø§Ø¨ Ù¾ÙˆØ±Ø§ Ø¬Ù…Ù„Û Ø¯ÛØ±Ø§Ø¦ÛŒÚº:'} ${data.english_sentence || data.response || ''}.`);
        break;
        
      case 'feedback_step':
        setConversationStateWithRecovery('feedback');
        setFeedbackText(data.response || '');
        setCurrentMessage(data.response || (languageMode === 'english' ? 'Great job!' : 'Ø´Ø§Ø¨Ø§Ø´!'));
        // Auto-complete feedback step after allowing user to read it
        setTimeout(() => {
          sendCompletionEventRef.current?.('feedback_complete');
          // Reset for next sentence
          setTimeout(() => {
            setConversationStateWithRecovery('waiting');
            setCurrentMessage(languageMode === 'english' ? 'Ready for next sentence. Press and hold to speak.' : 'Ø§Ú¯Ù„Û’ Ø¬Ù…Ù„Û’ Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø±Û” Ø¨ÙˆÙ„Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø¯Ø¨Ø§Ø¦ÛŒÚº Ø§ÙˆØ± Ø±Ú©Ú¾ÛŒÚºÛ”');
            resetLearningState();
          }, 2000);
        }, 5000);
        break;
        
      case 'no_speech':
        setConversationStateWithRecovery('no_speech');
        setCurrentMessage(languageMode === 'english' ? 'No speech detected. Please try again.' : 'Ú©ÙˆØ¦ÛŒ Ø¢ÙˆØ§Ø² Ù†ÛÛŒÚº Ø³Ù†Ø§Ø¦ÛŒ Ø¯ÛŒÛ” Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”');
        setTimeout(() => {
          setConversationStateWithRecovery('waiting');
          setCurrentMessage(languageMode === 'english' ? 'Press and hold to speak' : 'Ø¨ÙˆÙ„Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø¯Ø¨Ø§Ø¦ÛŒÚº Ø§ÙˆØ± Ø±Ú©Ú¾ÛŒÚº');
        }, 3000);
        break;
        
      case 'await_next':
        setConversationStateWithRecovery('waiting');
        setCurrentMessage(data.response || (languageMode === 'english' ? 'Please continue' : 'Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¬Ø§Ø±ÛŒ Ø±Ú©Ú¾ÛŒÚº'));
        break;
        
      case 'english_input_edge_case':
        console.log('English input edge case detected:', data.response);
        setConversationState('feedback');
        setFeedbackText(data.response || '');
        setCurrentMessage(data.response || (languageMode === 'english' ? 'Please try speaking in Urdu instead.' : 'Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø§Ø±Ø¯Ùˆ Ù…ÛŒÚº Ø¨ÙˆÙ„Ù†Û’ Ú©ÛŒ Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”'));
        // Auto-complete after showing message
        setTimeout(() => {
          sendCompletionEventRef.current?.('feedback_complete');
          setTimeout(() => {
            setConversationState('waiting');
            setCurrentMessage(languageMode === 'english' ? 'Ready for next sentence. Press and hold to speak.' : 'Ø§Ú¯Ù„Û’ Ø¬Ù…Ù„Û’ Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø±Û” Ø¨ÙˆÙ„Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø¯Ø¨Ø§Ø¦ÛŒÚº Ø§ÙˆØ± Ø±Ú©Ú¾ÛŒÚºÛ”');
            resetLearningState();
          }, 2000);
        }, 4000);
        break;
        
             default:
         console.warn('Unknown message step:', data.step, 'Full data:', data);
         // If we're in processing state and get an unknown message, try to handle it as feedback
         if (conversationState === 'processing') {
           console.log('Processing state - treating unknown message as feedback');
           setConversationState('feedback');
           setFeedbackText(data.response || 'Message received');
           setCurrentMessage(data.response || 'Great job! Let\'s continue.');
                       setTimeout(() => {
              sendCompletionEventRef.current?.('feedback_complete');
              setTimeout(() => {
                setConversationState('waiting');
                setCurrentMessage(languageMode === 'english' ? 'Ready for next sentence. Press and hold to speak.' : 'Ø§Ú¯Ù„Û’ Ø¬Ù…Ù„Û’ Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø±Û” Ø¨ÙˆÙ„Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø¯Ø¨Ø§Ø¦ÛŒÚº Ø§ÙˆØ± Ø±Ú©Ú¾ÛŒÚºÛ”');
                resetLearningState();
              }, 2000);
            }, 3000);
         }
         break;
    }
  }, [languageMode, resetLearningState]);

  // Send completion events to server
  const sendCompletionEvent = useCallback((eventType: 'word_by_word_complete' | 'feedback_complete' | 'you_said_complete'): void => {
    console.log(`Attempting to send ${eventType} event`);
    
    // Check if WebSocket is connected before sending
    if (!isConnected) {
      console.error(`âŒ Cannot send ${eventType} event - WebSocket not connected`);
      return;
    }
    
    const payload = {
      type: eventType,
      language_mode: languageMode,
      timestamp: Date.now()
    };
    
    console.log(`ğŸ“¤ Sending ${eventType} event to server`);
    const success = sendLearnMessage(JSON.stringify(payload));
    
    if (!success) {
      console.error(`âŒ Failed to send ${eventType} event`);
    } else {
      console.log(`âœ… ${eventType} event sent successfully`);
    }
  }, [languageMode, isConnected]);

  // Set the completion event function ref so it can be called from handleWebSocketMessage
  useEffect(() => {
    sendCompletionEventRef.current = sendCompletionEvent;
  }, [sendCompletionEvent]);

  const handleAudioData = useCallback((audioBuffer: ArrayBuffer): void => {
    console.log('Received binary audio data:', audioBuffer.byteLength, 'bytes');
    
    // Clear any processing timeout since we got a response
    if (typeof window !== 'undefined' && (window as any).currentProcessingTimeout) {
      clearTimeout((window as any).currentProcessingTimeout);
      (window as any).currentProcessingTimeout = null;
    }
    
    const blob = new Blob([audioBuffer], { type: 'audio/mpeg' });
    const audioUrl = URL.createObjectURL(blob);
    playAudio(audioUrl);
    setConversationState('speaking');
  }, []);

  const handleConnectionClose = useCallback((): void => {
    console.warn('ğŸ”Œ WebSocket connection closed - initiating recovery');
    setIsConnected(false);
    setConversationStateWithRecovery('waiting');
    setCurrentMessage(languageMode === 'english' ? 
      'Connection lost. Attempting to reconnect...' : 
      'Ú©Ù†Ú©Ø´Ù† Ù¹ÙˆÙ¹ Ú¯ÛŒØ§Û” Ø¯ÙˆØ¨Ø§Ø±Û Ø¬Ú‘Ù†Û’ Ú©ÛŒ Ú©ÙˆØ´Ø´...');
    
    // Clear any ongoing audio or state
    cleanupAudio();
    resetLearningState();
  }, [languageMode]);

  // Handle WebSocket reconnection
  const handleReconnect = useCallback((): void => {
    console.log('WebSocket reconnected');
    setIsConnected(true);
    setConnectionError(''); // Clear error on successful connection
    setCurrentMessage(languageMode === 'english' ? 'Connected successfully! Ready to learn.' : 'Ú©Ø§Ù…ÛŒØ§Ø¨ÛŒ Ø³Û’ Ø¬Ú‘ Ú¯ÛŒØ§! Ø³ÛŒÚ©Ú¾Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø±Û”');
  }, [languageMode]);

  const handleError = useCallback((error: Event): void => {
    console.error('WebSocket error:', error);
    setConnectionError(languageMode === 'english' ? 
      'Failed to connect to learning server. Server may be unavailable.' : 
      'Ù„Ø±Ù†Ù†Ú¯ Ø³Ø±ÙˆØ± Ø³Û’ Ø±Ø§Ø¨Ø·Û Ù†Ø§Ú©Ø§Ù…Û” Ø³Ø±ÙˆØ± Ø¯Ø³ØªÛŒØ§Ø¨ Ù†ÛÛŒÚº ÛÙˆ Ø³Ú©ØªØ§Û”');
    setCurrentMessage(languageMode === 'english' ? 'Connection error. Please check server status.' : 'Ú©Ù†Ú©Ø´Ù† Ù…ÛŒÚº Ø®Ø±Ø§Ø¨ÛŒÛ” Ø³Ø±ÙˆØ± Ú©ÛŒ Ø­Ø§Ù„Øª Ú†ÛŒÚ© Ú©Ø±ÛŒÚºÛ”');
  }, [languageMode]);

  // WebSocket connection for conversation - simplified dependencies
  useEffect(() => {
    if (step === 'conversation') {
      let isCurrentConnection = true; // Flag to prevent stale connections
      
      setCurrentMessage(languageMode === 'english' ? 'Connecting...' : 'Ø±Ø§Ø¨Ø·Û Ù‚Ø§Ø¦Ù… Ú©Ø± Ø±ÛÛ’ ÛÛŒÚº...');
      
      const connectSocket = async () => {
        try {
          const connected = await connectLearnSocket(
            handleWebSocketMessage,
            handleAudioData,
            handleConnectionClose,
            handleError,
            handleReconnect
          );
          
          if (connected && isCurrentConnection) {
            setConnectionError(''); // Clear any previous connection errors
            console.log("ğŸ”Œ WebSocket connection established, verifying...");
            
            // Enhanced connection verification with immediate check
            if (isWebSocketReady()) {
              console.log("ğŸŸ¢ ==========================================");
              console.log("ğŸŸ¢ Socket already connected!");
              console.log("ğŸŸ¢ WebSocket state:", getSocketState());
              console.log("ğŸŸ¢ Ready for audio input");
              console.log("ğŸŸ¢ ==========================================");
              setIsConnected(true);
              setCurrentMessage(languageMode === 'english' ? 'Connected! Ready to learn.' : 'Ø¬Ú‘ Ú¯Ø¦Û’! Ø³ÛŒÚ©Ú¾Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø±Û”');
              
              // Play intro audio only once
              if (!hasPlayedGreeting && isCurrentConnection) {
                setTimeout(() => {
                  playIntroAudio();
                  setHasPlayedGreeting(true);
                }, 500);
              }
            } else {
              // Fallback: Wait for connection verification like mobile app
              console.log("ğŸ”„ Socket not immediately ready, waiting for verification...");
              let verificationAttempts = 0;
              const maxVerificationAttempts = 50; // 5 seconds max
              
              const verificationInterval = setInterval(() => {
                verificationAttempts++;
                
                if (isWebSocketReady()) {
                  console.log("ğŸŸ¢ ==========================================");
                  console.log(`ğŸŸ¢ Socket verified after ${verificationAttempts * 100}ms!`);
                  console.log("ğŸŸ¢ WebSocket state:", getSocketState());
                  console.log("ğŸŸ¢ Ready for audio input");
                  console.log("ğŸŸ¢ ==========================================");
                  setIsConnected(true);
                  setCurrentMessage(languageMode === 'english' ? 'Connected! Ready to learn.' : 'Ø¬Ú‘ Ú¯Ø¦Û’! Ø³ÛŒÚ©Ú¾Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø±Û”');
                  clearInterval(verificationInterval);
                  
                  // Play intro audio only once
                  if (!hasPlayedGreeting && isCurrentConnection) {
                    setTimeout(() => {
                      playIntroAudio();
                      setHasPlayedGreeting(true);
                    }, 500);
                  }
                } else if (verificationAttempts >= maxVerificationAttempts) {
                  console.warn(`âš ï¸ Connection verification timeout after ${maxVerificationAttempts * 100}ms`);
                  console.warn("WebSocket state:", getSocketState());
                  clearInterval(verificationInterval);
                  
                  // Still set as connected if WebSocket is in OPEN state
                  if (getSocketState() === 'OPEN') {
                    console.log("ğŸŸ¡ Proceeding with OPEN socket despite verification timeout");
                    setIsConnected(true);
                    setCurrentMessage(languageMode === 'english' ? 'Connected! Ready to learn.' : 'Ø¬Ú‘ Ú¯Ø¦Û’! Ø³ÛŒÚ©Ú¾Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø±Û”');
                  } else {
                    console.error("âŒ Connection verification failed");
                    setCurrentMessage(languageMode === 'english' ? 'Connection verification failed' : 'Ú©Ù†Ú©Ø´Ù† Ú©ÛŒ ØªØµØ¯ÛŒÙ‚ Ù†Ø§Ú©Ø§Ù…');
                  }
                }
              }, 100); // Check every 100ms like mobile app
            }
          }
        } catch (error) {
          console.error('Failed to connect:', error);
          if (isCurrentConnection) {
            setIsConnected(false);
            setCurrentMessage(languageMode === 'english' ? 'Failed to connect. Please try again.' : 'Ú©Ù†Ú©Ø´Ù† Ù†ÛÛŒÚº ÛÙˆ Ø³Ú©Ø§Û” Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”');
          }
        }
      };
      
      connectSocket();
      
      return () => {
        isCurrentConnection = false; // Prevent stale state updates
        closeLearnSocket();
        cleanupAudio();
      };
    }
  }, [step, languageMode, hasPlayedGreeting, handleWebSocketMessage, handleAudioData, handleConnectionClose, handleError, handleReconnect, cleanupAudio]);

  const playAudio = useCallback((audioUrl: string): void => {
    cleanupAudio();
    
    audioRef.current = new Audio(audioUrl);
    audioRef.current.play().catch((error: Error) => {
      console.error('Error playing audio:', error);
      setConversationState('waiting');
      setCurrentMessage(languageMode === 'english' ? 'Audio playback failed' : 'Ø¢ÚˆÛŒÙˆ Ú†Ù„Ø§Ù†Û’ Ù…ÛŒÚº Ø®Ø±Ø§Ø¨ÛŒ');
    });
    
    audioRef.current.onended = () => {
      setConversationState('waiting');
      setCurrentMessage(languageMode === 'english' ? 'Press and hold to speak' : 'Ø¨ÙˆÙ„Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø¯Ø¨Ø§Ø¦ÛŒÚº Ø§ÙˆØ± Ø±Ú©Ú¾ÛŒÚº');
      // Clean up the object URL to prevent memory leaks
      URL.revokeObjectURL(audioUrl);
    };

    audioRef.current.onerror = () => {
      setConversationState('waiting');
      setCurrentMessage(languageMode === 'english' ? 'Audio error occurred' : 'Ø¢ÚˆÛŒÙˆ Ù…ÛŒÚº Ø®Ø±Ø§Ø¨ÛŒ ÛÙˆØ¦ÛŒ');
      URL.revokeObjectURL(audioUrl);
    };
  }, [cleanupAudio, languageMode]);

  const playIntroAudio = useCallback((): void => {
    setConversationState('playing_intro');
    setCurrentMessage(languageMode === 'english' ? 'Welcome to your AI tutor conversation!' : 'Ø¢Ù¾ Ú©Û’ AI Ø§Ø³ØªØ§Ø¯ Ú©ÛŒ Ú¯ÙØªÚ¯Ùˆ Ù…ÛŒÚº Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯!');
    
    // Simulate intro - replace with actual intro audio if available
    setTimeout(() => {
      setConversationState('waiting');
      setCurrentMessage(languageMode === 'english' ? 'Press and hold to speak' : 'Ø¨ÙˆÙ„Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø¯Ø¨Ø§Ø¦ÛŒÚº Ø§ÙˆØ± Ø±Ú©Ú¾ÛŒÚº');
    }, 3000);
  }, [languageMode]);

  const playWordByWord = useCallback((words: string[]): void => {
    if (!words || words.length === 0) return;
    
    setIsPlayingAudio(true);
    
    const playNextWord = (index: number) => {
      if (index >= words.length) {
        // Word-by-word playback complete
        setIsPlayingAudio(false);
        setTimeout(() => {
          sendCompletionEvent('word_by_word_complete');
        }, 1000);
        return;
      }
      
      setCurrentWordIndex(index);
      const word = words[index];
      
      const utterance = new SpeechSynthesisUtterance(word);
      utterance.rate = 0.6;
      utterance.lang = 'en-US';
      
      utterance.onend = () => {
        setTimeout(() => {
          playNextWord(index + 1);
        }, 800); // Pause between words
      };
      
      utterance.onerror = (error) => {
        console.error('Speech synthesis error:', error);
        setIsPlayingAudio(false);
        setTimeout(() => {
          sendCompletionEvent('word_by_word_complete');
        }, 1000);
      };
      
      speechSynthesis.speak(utterance);
    };
    
    // Start playing words
    playNextWord(0);
  }, [sendCompletionEvent]);

  const uploadAudio = useCallback(async (blob: Blob): Promise<void> => {
    try {
      setConversationStateWithRecovery('processing');
      setCurrentMessage(languageMode === 'english' ? 'Processing your speech...' : 'Ø¢Ù¾ Ú©ÛŒ Ø¨Ø§Øª Ù¾Ø±ÙˆØ³ÛŒØ³ Ú©Ø± Ø±ÛÛ’ ÛÛŒÚº...');
      
      // Set a timeout to prevent getting stuck in processing state - reduced timeout for faster recovery
      const processingTimeout = setTimeout(() => {
        console.warn('âš ï¸ Processing timeout - no response received within 20 seconds');
        console.warn('ğŸ”„ Attempting to recover from stuck state...');
        
        // Clear any existing timeout
        if (typeof window !== 'undefined' && (window as any).currentProcessingTimeout) {
          clearTimeout((window as any).currentProcessingTimeout);
          (window as any).currentProcessingTimeout = null;
        }
        
                 // Reset to waiting state with retry message
         setConversationStateWithRecovery('waiting');
         setCurrentMessage(languageMode === 'english' ? 
           'No response received from server. Please try again or check connection.' : 
           'Ø³Ø±ÙˆØ± Ø³Û’ Ú©ÙˆØ¦ÛŒ Ø¬ÙˆØ§Ø¨ Ù†ÛÛŒÚº Ù…Ù„Ø§Û” Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚº ÛŒØ§ Ú©Ù†Ú©Ø´Ù† Ú†ÛŒÚ© Ú©Ø±ÛŒÚºÛ”'
         );
         
         // Also reset any learning state that might be stuck
         resetLearningState();
      }, 20000); // 20 second timeout (reduced from 30)
      
      // Store timeout in a ref so we can clear it when we get a response
      if (typeof window !== 'undefined') {
        (window as any).currentProcessingTimeout = processingTimeout;
      }
      
      // Check connection state before processing
      const socketState = getSocketState();
      console.log('Current socket state before upload:', socketState);
      
      if (!isConnected) {
        console.error('âŒ Cannot upload audio: WebSocket not connected');
        setConversationState('waiting');
        setCurrentMessage(languageMode === 'english' ? 'Connection lost. Please try again.' : 'Ú©Ù†Ú©Ø´Ù† Ù¹ÙˆÙ¹ Ú¯ÛŒØ§Û” Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”');
        return;
      }
      
      const reader = new FileReader();
      reader.onload = () => {
        const result = reader.result;
        if (typeof result === 'string') {
          const base64 = result.split(',')[1];
          if (base64) {
            const payload = {
              audio_base64: base64,
              filename: `recording-${Date.now()}.wav`,
              language_mode: languageMode,
            };
            
            console.log('ğŸ”¼ ==============================================');
            console.log('ğŸ”¼ Attempting to send audio message...');
            console.log('ğŸ”¼ Audio payload size:', base64.length, 'characters');
            console.log('ğŸ”¼ Language mode:', languageMode);
            console.log('ğŸ”¼ WebSocket ready state:', getSocketState());
            console.log('ğŸ”¼ Is connected:', isConnected);
            console.log('ğŸ”¼ ==============================================')
            
            // Wait for WebSocket to be ready before sending
            waitForWebSocketReady(3000).then((ready) => {
              if (!ready) {
                console.error('WebSocket not ready after waiting');
                setConversationState('waiting');
                setCurrentMessage(languageMode === 'english' ? 'Connection not ready. Please wait a moment and try again.' : 'Ú©Ù†Ú©Ø´Ù† ØªÛŒØ§Ø± Ù†ÛÛŒÚºÛ” ØªÚ¾ÙˆÚ‘Ø§ Ø§Ù†ØªØ¸Ø§Ø± Ú©Ø±ÛŒÚº Ø§ÙˆØ± Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”');
                return;
              }
              
              const success = sendLearnMessage(JSON.stringify(payload));
              
              if (!success) {
                console.error('âŒ ==========================================');
                console.error('âŒ Failed to send audio message');
                console.error('âŒ WebSocket state:', getSocketState());
                console.error('âŒ Is connected:', isConnected);
                console.error('âŒ ==========================================');
                setConversationState('waiting');
                setCurrentMessage(languageMode === 'english' ? 'Failed to send audio' : 'Ø¢ÚˆÛŒÙˆ Ø¨Ú¾ÛŒØ¬Ù†Û’ Ù…ÛŒÚº Ù†Ø§Ú©Ø§Ù…ÛŒ');
              } else {
                console.log('âœ… ==========================================');
                console.log('âœ… Audio message sent successfully');
                console.log('âœ… Now waiting for server response...');
                console.log('âœ… Conversation state set to: processing');
                console.log('âœ… ==========================================');
                
                // No mock mode - audio will be sent to real server only
                
                // Add a timeout to reset state if no response is received
                setTimeout(() => {
                  if (conversationState === 'processing') {
                    console.warn('No response received within timeout, resetting state');
                    setConversationState('waiting');
                    setCurrentMessage(languageMode === 'english' ? 'No response received. Please try again.' : 'Ú©ÙˆØ¦ÛŒ Ø¬ÙˆØ§Ø¨ Ù†ÛÛŒÚº Ù…Ù„Ø§Û” Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”');
                  }
                }, 15000); // 15 second timeout
              }
            }).catch((error) => {
              console.error('Error waiting for WebSocket:', error);
              setConversationState('waiting');
              setCurrentMessage(languageMode === 'english' ? 'Connection error. Please try again.' : 'Ú©Ù†Ú©Ø´Ù† Ù…ÛŒÚº Ø®Ø±Ø§Ø¨ÛŒÛ” Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”');
            });
          }
        }
      };
      reader.onerror = () => {
        setConversationState('waiting');
        setCurrentMessage(languageMode === 'english' ? 'Error processing audio' : 'Ø¢ÚˆÛŒÙˆ Ù¾Ø±ÙˆØ³ÛŒØ³Ù†Ú¯ Ù…ÛŒÚº Ø®Ø±Ø§Ø¨ÛŒ');
      };
      reader.readAsDataURL(blob);
    } catch (error) {
      console.error('Error uploading audio:', error);
      setConversationState('waiting');
      setCurrentMessage(languageMode === 'english' ? 'Error processing audio' : 'Ø¢ÚˆÛŒÙˆ Ù¾Ø±ÙˆØ³ÛŒØ³Ù†Ú¯ Ù…ÛŒÚº Ø®Ø±Ø§Ø¨ÛŒ');
    }
  }, [languageMode, isConnected, handleWebSocketMessage]);

  const handleMicPress = useCallback((): void => {
    console.log('ğŸ¤ ==========================================');
    console.log('ğŸ¤ Mic button pressed!');
    console.log('ğŸ¤ Current conversation state:', conversationState);
    console.log('ğŸ¤ Is connected:', isConnected);
    console.log('ğŸ¤ ==========================================');
    
    if (conversationState === 'processing' || conversationState === 'speaking') {
      console.log('ğŸ¤ Ignoring mic press - currently processing or speaking');
      return;
    }
    
    console.log('ğŸ¤ Starting audio recording...');
    setConversationState('listening');
    setCurrentMessage(languageMode === 'english' ? 'Hold the button and speak clearly...' : 'Ø¨Ù¹Ù† Ø¯Ø¨Ø§Ø¦ÛŒÚº Ø§ÙˆØ± ØµØ§Ù Ø¨ÙˆÙ„ÛŒÚº...');
    
    startRecording().catch((error: Error) => {
      console.error('âŒ Error starting recording:', error);
      setConversationState('waiting');
      setCurrentMessage(languageMode === 'english' ? 'Microphone access denied' : 'Ù…Ø§Ø¦ÛŒÚ©Ø±ÙˆÙÙˆÙ† Ú©ÛŒ Ø±Ø³Ø§Ø¦ÛŒ Ù…Ø³ØªØ±Ø¯');
    });
  }, [conversationState, startRecording, languageMode, isConnected]);

  const handleMicRelease = useCallback((): void => {
    console.log('ğŸ›‘ ==========================================');
    console.log('ğŸ›‘ Mic button released!');
    console.log('ğŸ›‘ Is currently recording:', isRecording);
    console.log('ğŸ›‘ ==========================================');
    
    if (isRecording) {
      console.log('ğŸ›‘ Stopping recording and starting processing...');
      setCurrentMessage(languageMode === 'english' ? 'Processing your recording...' : 'Ø¢Ù¾ Ú©ÛŒ Ø±ÛŒÚ©Ø§Ø±ÚˆÙ†Ú¯ Ù¾Ø±ÙˆØ³ÛŒØ³ Ú©Ø± Ø±ÛÛ’ ÛÛŒÚº...');
      stopRecording();
    } else {
      console.log('ğŸ›‘ Not currently recording, ignoring release');
    }
  }, [isRecording, stopRecording, languageMode]);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      cleanupAudio();
      closeLearnSocket();
    };
  }, [cleanupAudio]);

  const getStatusColor = (): string => {
    switch (conversationState) {
      case 'listening': return 'bg-blue-500';
      case 'processing': return 'bg-orange-500';
      case 'speaking': return 'bg-green-500';
      case 'word_by_word': return 'bg-purple-500';
      case 'you_said': return 'bg-teal-500';
      case 'full_sentence': return 'bg-indigo-500';
      case 'feedback': return 'bg-emerald-500';
      case 'no_speech': return 'bg-red-500';
      default: return 'bg-green-500';
    }
  };

  // Display recording error if any
  const displayMessage: string = recordingError || currentMessage || (languageMode === 'english' ? 'Welcome to your AI tutor conversation!' : 'Ø¢Ù¾ Ú©Û’ AI Ø§Ø³ØªØ§Ø¯ Ú©ÛŒ Ú¯ÙØªÚ¯Ùˆ Ù…ÛŒÚº Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯!');

  const WelcomeScreen = () => (
    <div className="text-center max-w-2xl mx-auto flex flex-col items-center">
      <div className="bg-primary/10 rounded-full p-4 mb-6">
        <Target className="w-12 h-12 text-primary" />
      </div>
      <h1 className="text-4xl font-bold mb-2">Welcome to Your Learning Journey</h1>
      <p className="text-muted-foreground text-lg mb-8">Let's begin your English speaking adventure</p>
      
      {/* Audio Play Button - Only show if automatic playback failed and audio hasn't been played */}
      {(showManualPlayButton && !hasPlayedWelcomeAudio) && (
        <div className="mb-6">
          <Button 
            variant="outline" 
            size="lg"
            onClick={handleManualPlayClick}
            disabled={isPlayingWelcomeAudio}
            className="flex items-center gap-2"
          >
            <Play className={`w-5 h-5 ${isPlayingWelcomeAudio ? 'animate-pulse' : ''}`} />
            {isPlayingWelcomeAudio ? 'Playing Welcome Message...' : 'Play Welcome Message'}
          </Button>
        </div>
      )}
      
      {/* Show a subtle indicator when audio is playing automatically */}
      {isPlayingWelcomeAudio && !showManualPlayButton && (
        <div className="mb-6">
          <div className="flex items-center gap-2 text-green-600">
            <Volume2 className="w-5 h-5 animate-pulse" />
            <span className="text-sm">Playing welcome message...</span>
          </div>
        </div>
      )}
      
      {/* Show success message when audio has been played */}
      {hasPlayedWelcomeAudio && !isPlayingWelcomeAudio && (
        <div className="mb-6">
          <div className="flex items-center gap-2 text-green-600">
            <Volume2 className="w-5 h-5" />
            <span className="text-sm">âœ“ Welcome message played successfully</span>
          </div>
        </div>
      )}
      
      <Card className="w-full max-w-md shadow-lg">
        <CardContent className="p-6 text-center">
          <p className="text-xl font-urdu mb-4">Ø³ÛŒÚ©Ú¾Ù†Û’ Ú©Û’ Ù¾Ù„ÛŒÙ¹ ÙØ§Ø±Ù… Ù…ÛŒÚº Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯ØŒ Ø¢Ø¦ÛŒÛ’ Ø§Ù†Ú¯Ø±ÛŒØ²ÛŒ Ø³ÛŒÚ©Ú¾ØªÛ’ ÛÛŒÚºØŸ</p>
          <p className="text-muted-foreground">Welcome to the learning platform, shall we learn English?</p>
        </CardContent>
      </Card>
      <Button 
        size="lg" 
        className="mt-8 w-full max-w-md" 
        onClick={() => {
          localStorage.setItem('hasVisitedLearn', 'true');
          setStep('translate');
        }}
      >
        Continue to Learning
        <span className="ml-2">â†’</span>
      </Button>
    </div>
  );

  const TranslateScreen = () => (
    <div className="text-center max-w-2xl mx-auto flex flex-col items-center">
      <div className="bg-primary/10 rounded-full p-4 mb-6">
        <Mic className="w-16 h-16 text-primary" />
      </div>
      <h1 className="text-4xl font-bold mb-2">Speak to Translate</h1>
      <p className="text-muted-foreground text-lg mb-8">Transform your Urdu into English</p>
      <div className="flex items-center gap-4 mb-8">
        <Button 
          variant={languageMode === 'urdu' ? 'default' : 'outline'} 
          size="lg"
          onClick={() => setLanguageMode('urdu')}
        >
          <Globe className="mr-2 h-5 w-5"/>Urdu
        </Button>
        <Button 
          variant={languageMode === 'english' ? 'default' : 'outline'} 
          size="lg"
          onClick={() => setLanguageMode('english')}
        >
          English
        </Button>
      </div>
              <Card className="w-full max-w-md shadow-lg mb-8">
          <CardContent className="p-6">
            <p className="text-center text-muted-foreground">
              {languageMode === 'english' ? 'Press the button and speak in Urdu to get started' : 'Ø´Ø±ÙˆØ¹ Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø¨Ù¹Ù† Ø¯Ø¨Ø§Ø¦ÛŒÚº Ø§ÙˆØ± Ø§Ø±Ø¯Ùˆ Ù…ÛŒÚº Ø¨ÙˆÙ„ÛŒÚº'}
            </p>
          </CardContent>
        </Card>
      <Button size="lg" className="w-full max-w-md" onClick={() => setStep('conversation')}>
        Start Real-time Conversation
        <span className="ml-2">â†’</span>
      </Button>
      <div className="flex gap-4 mt-8">
        <Card className="p-4 flex-1 text-center shadow-lg">Perfect for daily conversations</Card>
        <Card className="p-4 flex-1 text-center shadow-lg">Learn at your own pace</Card>
      </div>
    </div>
  );

  // Render different content based on conversation state
  const renderLearningContent = () => {
    switch (conversationState) {
      case 'you_said':
        return (
          <Card className="w-full max-w-lg shadow-lg mb-8">
            <CardContent className="p-6 text-center">
              <p className="text-lg mb-4">
                {currentMessage}
              </p>
            </CardContent>
          </Card>
        );
        
      case 'word_by_word':
        return (
          <Card className="w-full max-w-lg shadow-lg mb-8">
            <CardContent className="p-6 text-center">
              <div className="mb-4">
                <h3 className="text-green-500 font-medium text-lg mb-4">
                  {languageMode === 'english' ? 'Repeat after me.' : 'Ù…ÛŒØ±Û’ Ù¾ÛŒÚ†Ú¾Û’ Ø¯ÛØ±Ø§Ø¦ÛŒÚºÛ”'}
                </h3>
                
                {englishSentence && (
                  <div className="mb-3">
                    <p className="font-medium text-gray-700">English:</p>
                    <p className="text-lg font-medium">{englishSentence}</p>
                  </div>
                )}
                
                {urduSentence && (
                  <div className="mb-4">
                    <p className="font-medium text-gray-700">Urdu:</p>
                    <p className="text-lg font-urdu">{urduSentence}</p>
                  </div>
                )}
                
                {currentWords.length > 0 && (
                  <div className="bg-green-50 rounded-lg p-4">
                    <p className="text-sm text-green-600 mb-2">
                      Word {currentWordIndex + 1} of {currentWords.length}
                    </p>
                    <p className="text-2xl font-bold text-gray-800">
                      "{currentWords[currentWordIndex] || currentWords[0]}"
                    </p>
                  </div>
                )}
              </div>
            </CardContent>
          </Card>
        );
        
      case 'full_sentence':
        return (
          <Card className="w-full max-w-lg shadow-lg mb-8">
            <CardContent className="p-6 text-center">
              <p className="text-lg mb-4">
                {currentMessage}
              </p>
            </CardContent>
          </Card>
        );
        
      case 'feedback':
        return (
          <Card className="w-full max-w-lg shadow-lg mb-8">
            <CardContent className="p-6 text-center">
              <p className="text-lg text-green-600">
                {feedbackText || currentMessage}
              </p>
            </CardContent>
          </Card>
        );
        
      default:
        return (
          <Card className="w-full max-w-md shadow-lg mb-12">
            <CardContent className="p-6">
              <div className="flex items-center gap-2 mb-2">
                {(conversationState === 'speaking' || isPlayingAudio) && <Volume2 className="w-4 h-4 text-green-500 animate-pulse" />}
                <Badge variant="outline" className={`${getStatusColor()} text-white`}>
                  {conversationState.replace('_', ' ').toUpperCase()}
                </Badge>
              </div>
              <p className="text-muted-foreground">
                {displayMessage}
              </p>
            </CardContent>
          </Card>
        );
    }
  };

  const ConversationScreen = () => (
    <div className="text-center max-w-2xl mx-auto flex flex-col items-center h-full">
      <Card className="w-full max-w-3xl shadow-lg mb-8 flex items-center p-4">
        <div className="bg-primary/10 rounded-full p-3 mr-4">
          <Mic className="w-8 h-8 text-primary" />
        </div>
        <div className="flex-grow text-left">
          <h2 className="font-semibold text-lg">AI Tutor Conversation</h2>
          <p className="text-muted-foreground">Real-time learning experience</p>
        </div>
        <div className="flex items-center gap-2">
          <Badge variant="secondary" className={`h-3 w-3 p-0 ${isConnected ? 'bg-green-500' : 'bg-red-500'}`}></Badge>
          <span className="text-sm text-muted-foreground">
            {isConnected ? 'Connected' : 'Disconnected'}
          </span>
        </div>
      </Card>


      {/* Error Banner */}
      {(recordingError || connectionError || !isConnected) && (
        <Card className="w-full max-w-md shadow-lg mb-4 border-red-200 bg-red-50">
          <CardContent className="p-4">
            <div className="flex items-center gap-2 text-red-700">
              <X className="w-4 h-4" />
              <div className="flex-grow">
                <p className="text-sm font-medium">
                  {recordingError || connectionError || (languageMode === 'english' ? 'Server Connection Failed' : 'Ø³Ø±ÙˆØ± Ú©Ù†Ú©Ø´Ù† Ù†Ø§Ú©Ø§Ù…')}
                </p>
                {!isConnected && !recordingError && (
                  <div className="text-xs text-red-600 mt-2 space-y-1">
                    <p>{languageMode === 'english' ? 'â€¢ WebSocket server is not responding' : 'â€¢ ÙˆÛŒØ¨ Ø³Ø§Ú©Ù¹ Ø³Ø±ÙˆØ± Ø¬ÙˆØ§Ø¨ Ù†ÛÛŒÚº Ø¯Û’ Ø±ÛØ§'}</p>
                    <p>{languageMode === 'english' ? 'â€¢ Server may be down or endpoint missing' : 'â€¢ Ø³Ø±ÙˆØ± Ø¨Ù†Ø¯ ÛÙˆ Ø³Ú©ØªØ§ ÛÛ’ ÛŒØ§ Ø§ÛŒÙ†Úˆ Ù¾ÙˆØ§Ø¦Ù†Ù¹ ØºØ§Ø¦Ø¨'}</p>
                    <p>{languageMode === 'english' ? 'â€¢ Check network connection' : 'â€¢ Ù†ÛŒÙ¹ ÙˆØ±Ú© Ú©Ù†Ú©Ø´Ù† Ú†ÛŒÚ© Ú©Ø±ÛŒÚº'}</p>
                  </div>
                )}
              </div>
            </div>
            <Button 
              variant="outline" 
              size="sm" 
              className="mt-3 text-red-700 border-red-300 hover:bg-red-100"
              onClick={() => window.location.reload()}
            >
              {languageMode === 'english' ? 'Retry Connection' : 'Ø¯ÙˆØ¨Ø§Ø±Û Ú©Ù†Ú©Ø´Ù† Ú©ÛŒ Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚº'}
            </Button>
          </CardContent>
        </Card>
      )}
      
      {/* Enhanced Debug Information */}
      {(window.location.hostname === 'localhost' || process.env.NODE_ENV === 'development') && (
        <Card className="w-full max-w-md shadow-lg mb-4 border-gray-200 bg-gray-50">
          <CardContent className="p-4">
            <div className="text-xs text-gray-600 space-y-1">
              <p><strong>ğŸ”Œ Connection State:</strong> <span className={isConnected ? 'text-green-600 font-bold' : 'text-red-600 font-bold'}>{isConnected ? 'Connected' : 'Disconnected'}</span></p>
              <p><strong>ğŸ¯ Conversation State:</strong> <span className="font-mono font-bold text-blue-600">{conversationState}</span></p>
              <p><strong>ğŸ¤ Recording:</strong> <span className={isRecording ? 'text-red-600 font-bold' : 'text-gray-600'}>{isRecording ? 'Yes' : 'No'}</span></p>
              <p><strong>ğŸŒ WebSocket State:</strong> <span className="font-mono">{getSocketState()}</span></p>
              <p><strong>ğŸ—£ï¸ Language:</strong> {languageMode}</p>
              <p><strong>ğŸ“ Current Message:</strong> <span className="text-xs italic">{currentMessage}</span></p>
              {connectionError && (
                <p><strong>âŒ Connection Error:</strong> <span className="text-red-600 text-xs">{connectionError}</span></p>
              )}
            </div>
            
            {/* Test UI Flow Buttons */}
            <div className="mt-3 pt-3 border-t border-gray-300">
              <p className="text-xs font-semibold text-gray-700 mb-2">ğŸ§ª Test UI Flow:</p>
              <div className="flex gap-1 flex-wrap">
                <Button 
                  size="sm" 
                  variant="outline" 
                  className="text-xs px-2 py-1 h-6"
                  onClick={() => {
                    console.log('ğŸ§ª Testing You Said view');
                    setConversationStateWithRecovery('you_said');
                    setUserSaidText('Ù…ÛŒÚº Ø§Ø³Ú©ÙˆÙ„ Ø¬Ø§ Ø±ÛØ§ ÛÙˆÚº');
                    setEnglishSentence('I am going to school');
                    setUrduSentence('Ù…ÛŒÚº Ø§Ø³Ú©ÙˆÙ„ Ø¬Ø§ Ø±ÛØ§ ÛÙˆÚº');
                    setCurrentMessage('You said: Ù…ÛŒÚº Ø§Ø³Ú©ÙˆÙ„ Ø¬Ø§ Ø±ÛØ§ ÛÙˆÚº. Now repeat after me.');
                  }}
                >
                  Test You Said
                </Button>
                <Button 
                  size="sm" 
                  variant="outline" 
                  className="text-xs px-2 py-1 h-6"
                  onClick={() => {
                    console.log('ğŸ§ª Testing Word by Word view');
                    setConversationStateWithRecovery('word_by_word');
                    setCurrentWords(['I', 'am', 'going', 'to', 'school']);
                    setCurrentWordIndex(0);
                    setEnglishSentence('I am going to school');
                    setUrduSentence('Ù…ÛŒÚº Ø§Ø³Ú©ÙˆÙ„ Ø¬Ø§ Ø±ÛØ§ ÛÙˆÚº');
                    setCurrentMessage('Repeat after me.');
                  }}
                >
                  Test Word by Word
                </Button>
                <Button 
                  size="sm" 
                  variant="outline" 
                  className="text-xs px-2 py-1 h-6"
                  onClick={() => {
                    console.log('ğŸ§ª Testing Full Sentence view');
                    setConversationStateWithRecovery('full_sentence');
                    setFullSentence('I am going to school');
                    setEnglishSentence('I am going to school');
                    setUrduSentence('Ù…ÛŒÚº Ø§Ø³Ú©ÙˆÙ„ Ø¬Ø§ Ø±ÛØ§ ÛÙˆÚº');
                    setCurrentMessage('Now repeat the full sentence: I am going to school.');
                  }}
                >
                  Test Full Sentence
                </Button>
                <Button 
                  size="sm" 
                  variant="outline" 
                  className="text-xs px-2 py-1 h-6"
                  onClick={() => {
                    console.log('ğŸ§ª Testing Feedback view');
                    setConversationStateWithRecovery('feedback');
                    setFeedbackText('Excellent pronunciation! Great job!');
                    setCurrentMessage('Excellent pronunciation! Great job!');
                  }}
                >
                  Test Feedback
                </Button>
                <Button 
                  size="sm" 
                  variant="outline" 
                  className="text-xs px-2 py-1 h-6"
                  onClick={() => {
                    console.log('ğŸ§ª Resetting to waiting state');
                    setConversationStateWithRecovery('waiting');
                    setCurrentMessage('Press and hold to speak');
                    resetLearningState();
                  }}
                >
                  Reset
                </Button>
              </div>
            </div>
          </CardContent>
        </Card>
      )}
      
      {/* Dynamic Learning Content */}
      {renderLearningContent()}
      
      {/* Visual Indicator */}
      <div className="relative mb-12">
        {(conversationState === 'processing' || conversationState === 'listening') && (
          <div className={`w-64 h-64 border-4 border-dashed rounded-full flex items-center justify-center transition-all duration-300 ${
            conversationState === 'listening' ? 'border-blue-500 bg-blue-50' :
            conversationState === 'processing' ? 'border-orange-500 bg-orange-50' :
            'border-gray-300'
          }`}>
            <div className="text-center">
              <Mic className={`w-16 h-16 mx-auto mb-2 ${
                conversationState === 'listening' ? 'text-blue-500' :
                conversationState === 'processing' ? 'text-orange-500' :
                'text-gray-400'
              }`} />
              <p className="text-sm text-muted-foreground">
                {conversationState === 'listening' ? (languageMode === 'english' ? 'Listening...' : 'Ø³Ù† Ø±ÛÛ’ ÛÛŒÚº...') :
                 conversationState === 'processing' ? (languageMode === 'english' ? 'Processing...' : 'Ù¾Ø±ÙˆØ³ÛŒØ³Ù†Ú¯...') :
                 (languageMode === 'english' ? 'Ready to listen' : 'Ø³Ù†Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø±')}
              </p>
            </div>
          </div>
        )}
        
        {(conversationState === 'speaking' || conversationState === 'word_by_word' || conversationState === 'feedback') && isPlayingAudio && (
          <div className="w-64 h-64 border-4 border-dashed rounded-full flex items-center justify-center border-green-500 bg-green-50 transition-all duration-300">
            <div className="text-center">
              <div className="relative">
                <div className="w-16 h-16 mx-auto mb-2 border-4 border-green-500 border-t-transparent rounded-full animate-spin"></div>
                <Volume2 className="w-8 h-8 text-green-500 absolute inset-0 m-auto" />
              </div>
              <p className="text-sm text-green-600 font-medium">
                {conversationState === 'word_by_word' ? (languageMode === 'english' ? 'Playing words...' : 'Ø§Ù„ÙØ§Ø¸ Ú†Ù„ Ø±ÛÛ’ ÛÛŒÚº...') :
                 (languageMode === 'english' ? 'AI Speaking...' : 'AI Ø¨ÙˆÙ„ Ø±ÛØ§ ÛÛ’...')}
              </p>
            </div>
          </div>
        )}
        
        {conversationState === 'full_sentence' && !isPlayingAudio && (
          <div className="w-64 h-64 border-4 border-dashed rounded-full flex items-center justify-center border-purple-500 bg-purple-50 transition-all duration-300">
            <div className="text-center">
              <Mic className="w-16 h-16 mx-auto mb-2 text-purple-500" />
              <p className="text-sm text-purple-600 font-medium">
                {languageMode === 'english' ? 'Your turn to speak' : 'Ø¢Ù¾ Ú©ÛŒ Ø¨Ø§Ø±ÛŒ ÛÛ’'}
              </p>
            </div>
          </div>
        )}
      </div>
      
      {/* Control Buttons */}
      <div className="flex items-center gap-8">
        <Button 
          variant="outline" 
          size="icon" 
          className="w-16 h-16 rounded-full" 
          onClick={() => setStep('translate')}
          title={languageMode === 'english' ? 'Go back' : 'ÙˆØ§Ù¾Ø³ Ø¬Ø§Ø¦ÛŒÚº'}
        >
          <X className="w-8 h-8" />
        </Button>
        
        {/* Main Action Button */}
        {conversationState === 'full_sentence' && !isRecording ? (
          <Button 
            size="icon" 
            className="w-24 h-24 rounded-full transition-all duration-200 bg-green-500 hover:bg-green-600"
            onMouseDown={handleMicPress}
            onMouseUp={handleMicRelease}
            onMouseLeave={handleMicRelease}
            disabled={!isConnected || !!recordingError}
            title={languageMode === 'english' ? 'Press and hold to speak the full sentence' : 'Ù¾ÙˆØ±Ø§ Ø¬Ù…Ù„Û Ø¨ÙˆÙ„Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø¯Ø¨Ø§Ø¦ÛŒÚº Ø§ÙˆØ± Ø±Ú©Ú¾ÛŒÚº'}
          >
            <Mic className="w-12 h-12" />
          </Button>
        ) : conversationState === 'waiting' ? (
          <Button 
            size="icon" 
            className="w-24 h-24 rounded-full transition-all duration-200 bg-green-500 hover:bg-green-600"
            onMouseDown={handleMicPress}
            onMouseUp={handleMicRelease}
            onMouseLeave={handleMicRelease}
            disabled={!isConnected || !!recordingError}
            title={languageMode === 'english' ? 'Press and hold to speak' : 'Ø¨ÙˆÙ„Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø¯Ø¨Ø§Ø¦ÛŒÚº Ø§ÙˆØ± Ø±Ú©Ú¾ÛŒÚº'}
          >
            <Mic className="w-12 h-12" />
          </Button>
        ) : isRecording ? (
          <Button 
            size="icon" 
            className="w-24 h-24 rounded-full transition-all duration-200 bg-red-500 hover:bg-red-600 scale-110"
            onMouseUp={handleMicRelease}
            onMouseLeave={handleMicRelease}
            title={languageMode === 'english' ? 'Release to stop recording' : 'Ø±ÛŒÚ©Ø§Ø±ÚˆÙ†Ú¯ Ø¨Ù†Ø¯ Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ú†Ú¾ÙˆÚ‘ÛŒÚº'}
          >
            <Square className="w-12 h-12" />
          </Button>
        ) : null}
      </div>
      
      {/* Help Text */}
      <p className="text-sm text-muted-foreground mt-4 text-center max-w-md">
        {!isConnected ? (languageMode === 'english' ? 'Please wait for connection' : 'Ú©Ù†Ú©Ø´Ù† Ú©Ø§ Ø§Ù†ØªØ¸Ø§Ø± Ú©Ø±ÛŒÚº') :
         recordingError ? (languageMode === 'english' ? 'Please refresh the page' : 'Ø¨Ø±Ø§Ø¦Û’ Ú©Ø±Ù… ØµÙØ­Û ØªØ§Ø²Û Ú©Ø±ÛŒÚº') :
         conversationState === 'listening' ? (languageMode === 'english' ? 'Keep holding and speak now...' : 'Ø¨Ù¹Ù† Ø¯Ø¨Ø§Ø¦Û’ Ø±Ú©Ú¾ÛŒÚº Ø§ÙˆØ± Ø§Ø¨ Ø¨ÙˆÙ„ÛŒÚº...') :
         conversationState === 'word_by_word' ? (languageMode === 'english' ? 'Listen carefully to each word' : 'ÛØ± Ù„ÙØ¸ Ú©Ùˆ ØºÙˆØ± Ø³Û’ Ø³Ù†ÛŒÚº') :
         conversationState === 'full_sentence' ? (languageMode === 'english' ? 'Now repeat the complete sentence' : 'Ø§Ø¨ Ù…Ú©Ù…Ù„ Ø¬Ù…Ù„Û Ø¯ÛØ±Ø§Ø¦ÛŒÚº') :
         conversationState === 'feedback' ? (languageMode === 'english' ? 'Great work! Get ready for the next sentence' : 'Ø¨ÛØªØ±ÛŒÙ† Ú©Ø§Ù…! Ø§Ú¯Ù„Û’ Ø¬Ù…Ù„Û’ Ú©Û’ Ù„ÛŒÛ’ ØªÛŒØ§Ø± ÛÙˆÚº') :
         (languageMode === 'english' ? 'Press and hold the green button to speak' : 'Ø¨ÙˆÙ„Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø³Ø¨Ø² Ø¨Ù¹Ù† Ø¯Ø¨Ø§Ø¦ÛŒÚº Ø§ÙˆØ± Ø±Ú©Ú¾ÛŒÚº')}
      </p>
    </div>
  );

  const renderStep = () => {
    switch (step) {
      case 'welcome':
        return <WelcomeScreen />;
      case 'translate':
        return <TranslateScreen />;
      case 'conversation':
        return <ConversationScreen />;
      default:
        return <WelcomeScreen />;
    }
  };

  return (
    <Card className="h-full w-full max-w-4xl mx-auto">
      <CardContent className="p-8 h-full flex items-center justify-center">
        {renderStep()}
      </CardContent>
    </Card>
  );
};